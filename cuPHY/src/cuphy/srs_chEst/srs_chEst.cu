/*
 * SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "srs_chEst.hpp"
#include "goldSequenceHostSrs.cpp"
#include <cmath>
#include <cooperative_groups.h>
#include <cooperative_groups/reduce.h>
#include "math_utils.cuh"
#include "cuda_fp16.h"
#include "mma.h"
#include <assert.h>

// For wmma
using namespace nvcuda;

namespace cg = cooperative_groups;
#define USE_SRS_ATOMIC_REDUCTION 1 // flag used to choose between 2-stage cg::reduction vs using atomic combined with cg::reduction

static __device__ __constant__ __half2 d_twiddle32[31];
static __half2 twiddle32[31] = {{1.000000,0.000000},{1.000000,0.000000},{0.000000,1.000000},{1.000000,0.000000},{0.707031,0.707031},{0.000000,1.000000},{-0.707031,0.707031},{1.000000,0.000000},{0.923828,0.382568},{0.707031,0.707031},{0.382568,0.923828},{0.000000,1.000000},{-0.382568,0.923828},{-0.707031,0.707031},{-0.923828,0.382568},{1.000000,0.000000},{0.980957,0.195068},{0.923828,0.382568},{0.831543,0.555664},{0.707031,0.707031},{0.555664,0.831543},{0.382568,0.923828},{0.195068,0.980957},{0.000000,1.000000},{-0.195068,0.980957},{-0.382568,0.923828},{-0.555664,0.831543},{-0.707031,0.707031},{-0.831543,0.555664},{-0.923828,0.382568},{-0.980957,0.195068}};

static __device__ __constant__ uint8_t d_fourier32PermuteIdx[32];
static uint8_t fourier32PermuteIdx[32] = {0, 16, 8, 24, 4, 20, 12, 28, 2, 18, 10, 26, 6, 22, 14, 30, 1, 17, 9, 25, 5, 21, 13, 29, 3, 19, 11, 27, 7, 23, 15, 31};

static __device__ __constant__ uint8_t d_fourier8PermuteIdx[8];
static uint8_t fourier8PermuteIdx[8] = {0, 4, 2 , 6, 1, 5, 3, 7};

static __device__ __constant__ uint8_t d_fourier4PermuteIdx[4];
static uint8_t fourier4PermuteIdx[4] = {0, 2, 1, 3};

static __device__ __constant__ float d_rkhsEigValesNorm[32];
static float rkhsEigValesNorm[32] = {   0.528989676222192,
                                        0.089899165392360,
                                        0.002928665741491,
                                        0.133541353103824,
                                        0.022694689006289,
                                        0.000739330091847,
                                        0.005722208860047,
                                        0.000972460945538,
                                        0.000031680083388,
                                        0.137247714450270,
                                        0.023324566689475,
                                        0.000759849761680,
                                        0.034647643086324,
                                        0.005888194678046,
                                        0.000191821069279,
                                        0.001484641615801,
                                        0.000252307461122,
                                        0.000008219478062,
                                        0.007189377752561,
                                        0.001221799004210,
                                        0.000039802826545,
                                        0.001814929999973,
                                        0.000308438329852,
                                        0.000010048066254,
                                        0.000077769232412,
                                        0.000013216494388,
                                        0.000000430556771,
                                        0.0,
                                        0.0,
                                        0.0,
                                        0.0,
                                        0.0};


static __device__ __constant__ float d_rkhsEigVales[32];
  static float rkhsEigVales[32]   =  {    13808.775,
                                            2346.733,
                                            76.450,
                                            3485.971,
                                            592.423,
                                            19.300,
                                            149.373,
                                            25.385,
                                            0.827,
                                            3582.722,
                                            608.866,
                                            19.835,
                                            904.444,
                                            153.706,
                                            5.007,
                                            38.755,
                                            6.586,
                                            0.215,
                                            187.672,
                                            31.894,
                                            1.039,
                                            47.377,
                                            8.051,
                                            0.262,
                                            2.030,
                                            0.345,
                                            0.011,
                                            0,
                                            0,
                                            0,
                                            0,
                                            0};


static __device__ __constant__ float d_rkhsEigValesAntNorm[9];
  static float rkhsEigValesAntNorm[9]   =  {0.6218175,
                                            0.1569754,
                                            0.0067263,
                                            0.1613321,
                                            0.0407277,
                                            0.0017452,
                                            0.0084510,
                                            0.0021334,
                                            0.0000914};

static __device__ __constant__ __half d_hammingWindow[816];
    static __half hammingWindow[816] = {0.004444,
                                    0.004444,
                                    0.004448,
                                    0.004452,
                                    0.004456,
                                    0.004463,
                                    0.004471,
                                    0.004482,
                                    0.004494,
                                    0.004505,
                                    0.004520,
                                    0.004536,
                                    0.004555,
                                    0.004574,
                                    0.004593,
                                    0.004616,
                                    0.004639,
                                    0.004665,
                                    0.004692,
                                    0.004719,
                                    0.004749,
                                    0.004780,
                                    0.004810,
                                    0.004845,
                                    0.004883,
                                    0.004917,
                                    0.004955,
                                    0.004997,
                                    0.005039,
                                    0.005081,
                                    0.005127,
                                    0.005173,
                                    0.005219,
                                    0.005268,
                                    0.005318,
                                    0.005371,
                                    0.005424,
                                    0.005478,
                                    0.005535,
                                    0.005592,
                                    0.005650,
                                    0.005711,
                                    0.005772,
                                    0.005836,
                                    0.005901,
                                    0.005966,
                                    0.006035,
                                    0.006104,
                                    0.006176,
                                    0.006248,
                                    0.006321,
                                    0.006397,
                                    0.006474,
                                    0.006550,
                                    0.006630,
                                    0.006710,
                                    0.006790,
                                    0.006874,
                                    0.006958,
                                    0.007046,
                                    0.007130,
                                    0.007221,
                                    0.007309,
                                    0.007401,
                                    0.007492,
                                    0.007587,
                                    0.007683,
                                    0.007778,
                                    0.007881,
                                    0.007980,
                                    0.008080,
                                    0.008179,
                                    0.008286,
                                    0.008385,
                                    0.008492,
                                    0.008598,
                                    0.008705,
                                    0.008820,
                                    0.008926,
                                    0.009041,
                                    0.009155,
                                    0.009270,
                                    0.009384,
                                    0.009499,
                                    0.009621,
                                    0.009743,
                                    0.009857,
                                    0.009979,
                                    0.010109,
                                    0.010231,
                                    0.010353,
                                    0.010483,
                                    0.010612,
                                    0.010735,
                                    0.010872,
                                    0.011002,
                                    0.011131,
                                    0.011269,
                                    0.011398,
                                    0.011536,
                                    0.011673,
                                    0.011810,
                                    0.011948,
                                    0.012093,
                                    0.012230,
                                    0.012375,
                                    0.012512,
                                    0.012657,
                                    0.012802,
                                    0.012955,
                                    0.013100,
                                    0.013245,
                                    0.013397,
                                    0.013550,
                                    0.013695,
                                    0.013847,
                                    0.014000,
                                    0.014160,
                                    0.014313,
                                    0.014465,
                                    0.014626,
                                    0.014786,
                                    0.014938,
                                    0.015099,
                                    0.015259,
                                    0.015427,
                                    0.015587,
                                    0.015747,
                                    0.015915,
                                    0.016083,
                                    0.016251,
                                    0.016403,
                                    0.016571,
                                    0.016739,
                                    0.016907,
                                    0.017090,
                                    0.017258,
                                    0.017426,
                                    0.017593,
                                    0.017776,
                                    0.017944,
                                    0.018112,
                                    0.018295,
                                    0.018463,
                                    0.018646,
                                    0.018814,
                                    0.018997,
                                    0.019180,
                                    0.019348,
                                    0.019531,
                                    0.019714,
                                    0.019897,
                                    0.020081,
                                    0.020264,
                                    0.020447,
                                    0.020630,
                                    0.020813,
                                    0.020996,
                                    0.021179,
                                    0.021362,
                                    0.021545,
                                    0.021729,
                                    0.021927,
                                    0.022110,
                                    0.022293,
                                    0.022476,
                                    0.022675,
                                    0.022858,
                                    0.023056,
                                    0.023239,
                                    0.023422,
                                    0.023621,
                                    0.023804,
                                    0.024002,
                                    0.024200,
                                    0.024384,
                                    0.024582,
                                    0.024765,
                                    0.024963,
                                    0.025162,
                                    0.025345,
                                    0.025543,
                                    0.025742,
                                    0.025940,
                                    0.026123,
                                    0.026321,
                                    0.026520,
                                    0.026718,
                                    0.026917,
                                    0.027100,
                                    0.027298,
                                    0.027496,
                                    0.027695,
                                    0.027893,
                                    0.028091,
                                    0.028290,
                                    0.028473,
                                    0.028671,
                                    0.028870,
                                    0.029068,
                                    0.029266,
                                    0.029465,
                                    0.029663,
                                    0.029861,
                                    0.030060,
                                    0.030258,
                                    0.030441,
                                    0.030640,
                                    0.030838,
                                    0.031036,
                                    0.031235,
                                    0.031433,
                                    0.031616,
                                    0.031830,
                                    0.032013,
                                    0.032227,
                                    0.032410,
                                    0.032623,
                                    0.032806,
                                    0.032990,
                                    0.033203,
                                    0.033386,
                                    0.033600,
                                    0.033783,
                                    0.033966,
                                    0.034180,
                                    0.034363,
                                    0.034576,
                                    0.034760,
                                    0.034943,
                                    0.035156,
                                    0.035339,
                                    0.035522,
                                    0.035706,
                                    0.035919,
                                    0.036102,
                                    0.036285,
                                    0.036499,
                                    0.036682,
                                    0.036865,
                                    0.037048,
                                    0.037231,
                                    0.037445,
                                    0.037628,
                                    0.037811,
                                    0.037994,
                                    0.038177,
                                    0.038361,
                                    0.038544,
                                    0.038757,
                                    0.038940,
                                    0.039124,
                                    0.039307,
                                    0.039490,
                                    0.039673,
                                    0.039856,
                                    0.040039,
                                    0.040192,
                                    0.040375,
                                    0.040558,
                                    0.040741,
                                    0.040924,
                                    0.041107,
                                    0.041290,
                                    0.041443,
                                    0.041626,
                                    0.041809,
                                    0.041992,
                                    0.042145,
                                    0.042328,
                                    0.042511,
                                    0.042664,
                                    0.042847,
                                    0.042999,
                                    0.043182,
                                    0.043335,
                                    0.043518,
                                    0.043671,
                                    0.043854,
                                    0.044006,
                                    0.044189,
                                    0.044342,
                                    0.044495,
                                    0.044678,
                                    0.044830,
                                    0.044983,
                                    0.045135,
                                    0.045319,
                                    0.045471,
                                    0.045624,
                                    0.045776,
                                    0.045929,
                                    0.046082,
                                    0.046234,
                                    0.046387,
                                    0.046539,
                                    0.046692,
                                    0.046844,
                                    0.046997,
                                    0.047119,
                                    0.047272,
                                    0.047424,
                                    0.047577,
                                    0.047699,
                                    0.047852,
                                    0.048004,
                                    0.048126,
                                    0.048279,
                                    0.048401,
                                    0.048553,
                                    0.048676,
                                    0.048798,
                                    0.048950,
                                    0.049072,
                                    0.049194,
                                    0.049347,
                                    0.049469,
                                    0.049591,
                                    0.049713,
                                    0.049835,
                                    0.049957,
                                    0.050079,
                                    0.050201,
                                    0.050323,
                                    0.050446,
                                    0.050568,
                                    0.050690,
                                    0.050812,
                                    0.050903,
                                    0.051025,
                                    0.051147,
                                    0.051239,
                                    0.051361,
                                    0.051453,
                                    0.051575,
                                    0.051666,
                                    0.051788,
                                    0.051880,
                                    0.051971,
                                    0.052094,
                                    0.052185,
                                    0.052277,
                                    0.052368,
                                    0.052460,
                                    0.052551,
                                    0.052643,
                                    0.052734,
                                    0.052826,
                                    0.052917,
                                    0.053009,
                                    0.053101,
                                    0.053192,
                                    0.053253,
                                    0.053345,
                                    0.053436,
                                    0.053497,
                                    0.053589,
                                    0.053650,
                                    0.053741,
                                    0.053802,
                                    0.053864,
                                    0.053955,
                                    0.054016,
                                    0.054077,
                                    0.054138,
                                    0.054199,
                                    0.054260,
                                    0.054321,
                                    0.054382,
                                    0.054443,
                                    0.054504,
                                    0.054565,
                                    0.054626,
                                    0.054657,
                                    0.054718,
                                    0.054779,
                                    0.054810,
                                    0.054871,
                                    0.054901,
                                    0.054962,
                                    0.054993,
                                    0.055023,
                                    0.055084,
                                    0.055115,
                                    0.055145,
                                    0.055176,
                                    0.055206,
                                    0.055237,
                                    0.055267,
                                    0.055298,
                                    0.055328,
                                    0.055359,
                                    0.055389,
                                    0.055420,
                                    0.055420,
                                    0.055450,
                                    0.055450,
                                    0.055481,
                                    0.055511,
                                    0.055511,
                                    0.055511,
                                    0.055542,
                                    0.055542,
                                    0.055542,
                                    0.055542,
                                    0.055573,
                                    0.055573,
                                    0.055573,
                                    0.055573,
                                    0.055573,
                                    0.055573,
                                    0.055542,
                                    0.055542,
                                    0.055542,
                                    0.055542,
                                    0.055511,
                                    0.055511,
                                    0.055511,
                                    0.055481,
                                    0.055450,
                                    0.055450,
                                    0.055420,
                                    0.055420,
                                    0.055389,
                                    0.055359,
                                    0.055328,
                                    0.055298,
                                    0.055267,
                                    0.055237,
                                    0.055206,
                                    0.055176,
                                    0.055145,
                                    0.055115,
                                    0.055084,
                                    0.055023,
                                    0.054993,
                                    0.054962,
                                    0.054901,
                                    0.054871,
                                    0.054810,
                                    0.054779,
                                    0.054718,
                                    0.054657,
                                    0.054626,
                                    0.054565,
                                    0.054504,
                                    0.054443,
                                    0.054382,
                                    0.054321,
                                    0.054260,
                                    0.054199,
                                    0.054138,
                                    0.054077,
                                    0.054016,
                                    0.053955,
                                    0.053864,
                                    0.053802,
                                    0.053741,
                                    0.053650,
                                    0.053589,
                                    0.053497,
                                    0.053436,
                                    0.053345,
                                    0.053253,
                                    0.053192,
                                    0.053101,
                                    0.053009,
                                    0.052917,
                                    0.052826,
                                    0.052734,
                                    0.052643,
                                    0.052551,
                                    0.052460,
                                    0.052368,
                                    0.052277,
                                    0.052185,
                                    0.052094,
                                    0.051971,
                                    0.051880,
                                    0.051788,
                                    0.051666,
                                    0.051575,
                                    0.051453,
                                    0.051361,
                                    0.051239,
                                    0.051147,
                                    0.051025,
                                    0.050903,
                                    0.050812,
                                    0.050690,
                                    0.050568,
                                    0.050446,
                                    0.050323,
                                    0.050201,
                                    0.050079,
                                    0.049957,
                                    0.049835,
                                    0.049713,
                                    0.049591,
                                    0.049469,
                                    0.049347,
                                    0.049194,
                                    0.049072,
                                    0.048950,
                                    0.048798,
                                    0.048676,
                                    0.048553,
                                    0.048401,
                                    0.048279,
                                    0.048126,
                                    0.048004,
                                    0.047852,
                                    0.047699,
                                    0.047577,
                                    0.047424,
                                    0.047272,
                                    0.047119,
                                    0.046997,
                                    0.046844,
                                    0.046692,
                                    0.046539,
                                    0.046387,
                                    0.046234,
                                    0.046082,
                                    0.045929,
                                    0.045776,
                                    0.045624,
                                    0.045471,
                                    0.045319,
                                    0.045135,
                                    0.044983,
                                    0.044830,
                                    0.044678,
                                    0.044495,
                                    0.044342,
                                    0.044189,
                                    0.044006,
                                    0.043854,
                                    0.043671,
                                    0.043518,
                                    0.043335,
                                    0.043182,
                                    0.042999,
                                    0.042847,
                                    0.042664,
                                    0.042511,
                                    0.042328,
                                    0.042145,
                                    0.041992,
                                    0.041809,
                                    0.041626,
                                    0.041443,
                                    0.041290,
                                    0.041107,
                                    0.040924,
                                    0.040741,
                                    0.040558,
                                    0.040375,
                                    0.040192,
                                    0.040039,
                                    0.039856,
                                    0.039673,
                                    0.039490,
                                    0.039307,
                                    0.039124,
                                    0.038940,
                                    0.038757,
                                    0.038544,
                                    0.038361,
                                    0.038177,
                                    0.037994,
                                    0.037811,
                                    0.037628,
                                    0.037445,
                                    0.037231,
                                    0.037048,
                                    0.036865,
                                    0.036682,
                                    0.036499,
                                    0.036285,
                                    0.036102,
                                    0.035919,
                                    0.035706,
                                    0.035522,
                                    0.035339,
                                    0.035156,
                                    0.034943,
                                    0.034760,
                                    0.034576,
                                    0.034363,
                                    0.034180,
                                    0.033966,
                                    0.033783,
                                    0.033600,
                                    0.033386,
                                    0.033203,
                                    0.032990,
                                    0.032806,
                                    0.032623,
                                    0.032410,
                                    0.032227,
                                    0.032013,
                                    0.031830,
                                    0.031616,
                                    0.031433,
                                    0.031235,
                                    0.031036,
                                    0.030838,
                                    0.030640,
                                    0.030441,
                                    0.030258,
                                    0.030060,
                                    0.029861,
                                    0.029663,
                                    0.029465,
                                    0.029266,
                                    0.029068,
                                    0.028870,
                                    0.028671,
                                    0.028473,
                                    0.028290,
                                    0.028091,
                                    0.027893,
                                    0.027695,
                                    0.027496,
                                    0.027298,
                                    0.027100,
                                    0.026917,
                                    0.026718,
                                    0.026520,
                                    0.026321,
                                    0.026123,
                                    0.025940,
                                    0.025742,
                                    0.025543,
                                    0.025345,
                                    0.025162,
                                    0.024963,
                                    0.024765,
                                    0.024582,
                                    0.024384,
                                    0.024200,
                                    0.024002,
                                    0.023804,
                                    0.023621,
                                    0.023422,
                                    0.023239,
                                    0.023056,
                                    0.022858,
                                    0.022675,
                                    0.022476,
                                    0.022293,
                                    0.022110,
                                    0.021927,
                                    0.021729,
                                    0.021545,
                                    0.021362,
                                    0.021179,
                                    0.020996,
                                    0.020813,
                                    0.020630,
                                    0.020447,
                                    0.020264,
                                    0.020081,
                                    0.019897,
                                    0.019714,
                                    0.019531,
                                    0.019348,
                                    0.019180,
                                    0.018997,
                                    0.018814,
                                    0.018646,
                                    0.018463,
                                    0.018295,
                                    0.018112,
                                    0.017944,
                                    0.017776,
                                    0.017593,
                                    0.017426,
                                    0.017258,
                                    0.017090,
                                    0.016907,
                                    0.016739,
                                    0.016571,
                                    0.016403,
                                    0.016251,
                                    0.016083,
                                    0.015915,
                                    0.015747,
                                    0.015587,
                                    0.015427,
                                    0.015259,
                                    0.015099,
                                    0.014938,
                                    0.014786,
                                    0.014626,
                                    0.014465,
                                    0.014313,
                                    0.014160,
                                    0.014000,
                                    0.013847,
                                    0.013695,
                                    0.013550,
                                    0.013397,
                                    0.013245,
                                    0.013100,
                                    0.012955,
                                    0.012802,
                                    0.012657,
                                    0.012512,
                                    0.012375,
                                    0.012230,
                                    0.012093,
                                    0.011948,
                                    0.011810,
                                    0.011673,
                                    0.011536,
                                    0.011398,
                                    0.011269,
                                    0.011131,
                                    0.011002,
                                    0.010872,
                                    0.010735,
                                    0.010612,
                                    0.010483,
                                    0.010353,
                                    0.010231,
                                    0.010109,
                                    0.009979,
                                    0.009857,
                                    0.009743,
                                    0.009621,
                                    0.009499,
                                    0.009384,
                                    0.009270,
                                    0.009155,
                                    0.009041,
                                    0.008926,
                                    0.008820,
                                    0.008705,
                                    0.008598,
                                    0.008492,
                                    0.008385,
                                    0.008286,
                                    0.008179,
                                    0.008080,
                                    0.007980,
                                    0.007881,
                                    0.007778,
                                    0.007683,
                                    0.007587,
                                    0.007492,
                                    0.007401,
                                    0.007309,
                                    0.007221,
                                    0.007130,
                                    0.007046,
                                    0.006958,
                                    0.006874,
                                    0.006790,
                                    0.006710,
                                    0.006630,
                                    0.006550,
                                    0.006474,
                                    0.006397,
                                    0.006321,
                                    0.006248,
                                    0.006176,
                                    0.006104,
                                    0.006035,
                                    0.005966,
                                    0.005901,
                                    0.005836,
                                    0.005772,
                                    0.005711,
                                    0.005650,
                                    0.005592,
                                    0.005535,
                                    0.005478,
                                    0.005424,
                                    0.005371,
                                    0.005318,
                                    0.005268,
                                    0.005219,
                                    0.005173,
                                    0.005127,
                                    0.005081,
                                    0.005039,
                                    0.004997,
                                    0.004955,
                                    0.004917,
                                    0.004883,
                                    0.004845,
                                    0.004810,
                                    0.004780,
                                    0.004749,
                                    0.004719,
                                    0.004692,
                                    0.004665,
                                    0.004639,
                                    0.004616,
                                    0.004593,
                                    0.004574,
                                    0.004555,
                                    0.004536,
                                    0.004520,
                                    0.004505,
                                    0.004494,
                                    0.004482,
                                    0.004471,
                                    0.004463,
                                    0.004456,
                                    0.004452,
                                    0.004448,
                                    0.004444,
                                    0.004444};

static constexpr uint32_t LOWER_BYTE_BMSK = 255;

constexpr uint16_t PRIMES_TABLE[303] =
   {2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,503,509,521,523,541,547,557,563,569,571,577,587,593,599,601,607,613,617,619,631,641,643,647,653,659,661,673,677,683,691,701,709,719,727,733,739,743,751,757,761,769,773,787,797,809,811,821,823,827,829,839,853,857,859,863,877,881,883,887,907,911,919,929,937,941,947,953,967,971,977,983,991,997,1009,1013,1019,1021,1031,1033,1039,1049,1051,1061,1063,1069,1087,1091,1093,1097,1103,1109,1117,1123,1129,1151,1153,1163,1171,1181,1187,1193,1201,1213,1217,1223,1229,1231,1237,1249,1259,1277,1279,1283,1289,1291,1297,1301,1303,1307,1319,1321,1327,1361,1367,1373,1381,1399,1409,1423,1427,1429,1433,1439,1447,1451,1453,1459,1471,1481,1483,1487,1489,1493,1499,1511,1523,1531,1543,1549,1553,1559,1567,1571,1579,1583,1597,1601,1607,1609,1613,1619,1621,1627,1637,1657,1663,1667,1669,1693,1697,1699,1709,1721,1723,1733,1741,1747,1753,1759,1777,1783,1787,1789,1801,1811,1823,1831,1847,1861,1867,1871,1873,1877,1879,1889,1901,1907,1913,1931,1933,1949,1951,1973,1979,1987,1993,1997,1999};

constexpr uint16_t SRS_BW_TABLE[64][8] =
   {{4,1,4,1,4,1,4,1},
    {8,1,4,2,4,1,4,1},
    {12,1,4,3,4,1,4,1},
    {16,1,4,4,4,1,4,1},
    {16,1,8,2,4,2,4,1},
    {20,1,4,5,4,1,4,1},
    {24,1,4,6,4,1,4,1},
    {24,1,12,2,4,3,4,1},
    {28,1,4,7,4,1,4,1},
    {32,1,16,2,8,2,4,2},
    {36,1,12,3,4,3,4,1},
    {40,1,20,2,4,5,4,1},
    {48,1,16,3,8,2,4,2},
    {48,1,24,2,12,2,4,3},
    {52,1,4,13,4,1,4,1},
    {56,1,28,2,4,7,4,1},
    {60,1,20,3,4,5,4,1},
    {64,1,32,2,16,2,4,4},
    {72,1,24,3,12,2,4,3},
    {72,1,36,2,12,3,4,3},
    {76,1,4,19,4,1,4,1},
    {80,1,40,2,20,2,4,5},
    {88,1,44,2,4,11,4,1},
    {96,1,32,3,16,2,4,4},
    {96,1,48,2,24,2,4,6},
    {104,1,52,2,4,13,4,1},
    {112,1,56,2,28,2,4,7},
    {120,1,60,2,20,3,4,5},
    {120,1,40,3,8,5,4,2},
    {120,1,24,5,12,2,4,3},
    {128,1,64,2,32,2,4,8},
    {128,1,64,2,16,4,4,4},
    {128,1,16,8,8,2,4,2},
    {132,1,44,3,4,11,4,1},
    {136,1,68,2,4,17,4,1},
    {144,1,72,2,36,2,4,9},
    {144,1,48,3,24,2,12,2},
    {144,1,48,3,16,3,4,4},
    {144,1,16,9,8,2,4,2},
    {152,1,76,2,4,19,4,1},
    {160,1,80,2,40,2,4,10},
    {160,1,80,2,20,4,4,5},
    {160,1,32,5,16,2,4,4},
    {168,1,84,2,28,3,4,7},
    {176,1,88,2,44,2,4,11},
    {184,1,92,2,4,23,4,1},
    {192,1,96,2,48,2,4,12},
    {192,1,96,2,24,4,4,6},
    {192,1,64,3,16,4,4,4},
    {192,1,24,8,8,3,4,2},
    {208,1,104,2,52,2,4,13},
    {216,1,108,2,36,3,4,9},
    {224,1,112,2,56,2,4,14},
    {240,1,120,2,60,2,4,15},
    {240,1,80,3,20,4,4,5},
    {240,1,48,5,16,3,8,2},
    {240,1,24,10,12,2,4,3},
    {256,1,128,2,64,2,4,16},
    {256,1,128,2,32,4,4,8},
    {256,1,16,16,8,2,4,2},
    {264,1,132,2,44,3,4,11},
    {272,1,136,2,68,2,4,17},
    {272,1,68,4,4,17,4,1},
    {272,1,16,17,8,2,4,2}};

#define LOW_PAPR_TABLE_0_N_ROWS 30
#define LOW_PAPR_TABLE_0_N_COLS 12
static __device__ __constant__  int8_t LOW_PAPR_TABLE_0[LOW_PAPR_TABLE_0_N_ROWS][LOW_PAPR_TABLE_0_N_COLS] =
   {{-3,1,-3,-3,-3,3,-3,-1,1,1,1,-3},
    {-3,3,1,-3,1,3,-1,-1,1,3,3,3},
    {-3,3,3,1,-3,3,-1,1,3,-3,3,-3},
    {-3,-3,-1,3,3,3,-3,3,-3,1,-1,-3},
    {-3,-1,-1,1,3,1,1,-1,1,-1,-3,1},
    {-3,-3,3,1,-3,-3,-3,-1,3,-1,1,3},
    {1,-1,3,-1,-1,-1,-3,-1,1,1,1,-3},
    {-1,-3,3,-1,-3,-3,-3,-1,1,-1,1,-3},
    {-3,-1,3,1,-3,-1,-3,3,1,3,3,1},
    {-3,-1,-1,-3,-3,-1,-3,3,1,3,-1,-3},
    {-3,3,-3,3,3,-3,-1,-1,3,3,1,-3},
    {-3,-1,-3,-1,-1,-3,3,3,-1,-1,1,-3},
    {-3,-1,3,-3,-3,-1,-3,1,-1,-3,3,3},
    {-3,1,-1,-1,3,3,-3,-1,-1,-3,-1,-3},
    {1,3,-3,1,3,3,3,1,-1,1,-1,3},
    {-3,1,3,-1,-1,-3,-3,-1,-1,3,1,-3},
    {-1,-1,-1,-1,1,-3,-1,3,3,-1,-3,1},
    {-1,1,1,-1,1,3,3,-1,-1,-3,1,-3},
    {-3,1,3,3,-1,-1,-3,3,3,-3,3,-3},
    {-3,-3,3,-3,-1,3,3,3,-1,-3,1,-3},
    {3,1,3,1,3,-3,-1,1,3,1,-1,-3},
    {-3,3,1,3,-3,1,1,1,1,3,-3,3},
    {-3,3,3,3,-1,-3,-3,-1,-3,1,3,-3},
    {3,-1,-3,3,-3,-1,3,3,3,-3,-1,-3},
    {-3,-1,1,-3,1,3,3,3,-1,-3,3,3},
    {-3,3,1,-1,3,3,-3,1,-1,1,-1,1},
    {-1,1,3,-3,1,-1,1,-1,-1,-3,1,-1},
    {-3,-3,3,3,3,-3,-1,1,-3,3,1,-3},
    {1,-1,3,1,1,-1,-1,-1,1,3,-3,1},
    {-3,3,-3,3,-3,-3,3,-1,-1,1,3,-3}};

#define LOW_PAPR_TABLE_1_N_ROWS 30
#define LOW_PAPR_TABLE_1_N_COLS 24
static __device__ __constant__  int8_t LOW_PAPR_TABLE_1[LOW_PAPR_TABLE_1_N_ROWS][LOW_PAPR_TABLE_1_N_COLS] =
   {{-1,-3,3,-1,3,1,3,-1,1,-3,-1,-3,-1,1,3,-3,-1,-3,3,3,3,-3,-3,-3},
    {-1,-3,3,1,1,-3,1,-3,-3,1,-3,-1,-1,3,-3,3,3,3,-3,1,3,3,-3,-3},
    {-1,-3,-3,1,-1,-1,-3,1,3,-1,-3,-1,-1,-3,1,1,3,1,-3,-1,-1,3,-3,-3},
    {1,-3,3,-1,-3,-1,3,3,1,-1,1,1,3,-3,-1,-3,-3,-3,-1,3,-3,-1,-3,-3},
    {-1,3,-3,-3,-1,3,-1,-1,1,3,1,3,-1,-1,-3,1,3,1,-1,-3,1,-1,-3,-3},
    {-3,-1,1,-3,-3,1,1,-3,3,-1,-1,-3,1,3,1,-1,-3,-1,-3,1,-3,-3,-3,-3},
    {-3,3,1,3,-1,1,-3,1,-3,1,-1,-3,-1,-3,-3,-3,-3,-1,-1,-1,1,1,-3,-3},
    {-3,1,3,-1,1,-1,3,-3,3,-1,-3,-1,-3,3,-1,-1,-1,-3,-1,-1,-3,3,3,-3},
    {-3,1,-3,3,-1,-1,-1,-3,3,1,-1,-3,-1,1,3,-1,1,-1,1,-3,-3,-3,-3,-3},
    {1,1,-1,-3,-1,1,1,-3,1,-1,1,-3,3,-3,-3,3,-1,-3,1,3,-3,1,-3,-3},
    {-3,-3,-3,-1,3,-3,3,1,3,1,-3,-1,-1,-3,1,1,3,1,-1,-3,3,1,3,-3},
    {-3,3,-1,3,1,-1,-1,-1,3,3,1,1,1,3,3,1,-3,-3,-1,1,-3,1,3,-3},
    {3,-3,3,-1,-3,1,3,1,-1,-1,-3,-1,3,-3,3,-1,-1,3,3,-3,-3,3,-3,-3},
    {-3,3,-1,3,-1,3,3,1,1,-3,1,3,-3,3,-3,-3,-1,1,3,-3,-1,-1,-3,-3},
    {-3,1,-3,-1,-1,3,1,3,-3,1,-1,3,3,-1,-3,3,-3,-1,-1,-3,-3,-3,3,-3},
    {-3,-1,-1,-3,1,-3,-3,-1,-1,3,-1,1,-1,3,1,-3,-1,3,1,1,-1,-1,-3,-3},
    {-3,-3,1,-1,3,3,-3,-1,1,-1,-1,1,1,-1,-1,3,-3,1,-3,1,-1,-1,-1,-3},
    {3,-1,3,-1,1,-3,1,1,-3,-3,3,-3,-1,-1,-1,-1,-1,-3,-3,-1,1,1,-3,-3},
    {-3,1,-3,1,-3,-3,1,-3,1,-3,-3,-3,-3,-3,1,-3,-3,1,1,-3,1,1,-3,-3},
    {-3,-3,3,3,1,-1,-1,-1,1,-3,-1,1,-1,3,-3,-1,-3,-1,-1,1,-3,3,-1,-3},
    {-3,-3,-1,-1,-1,-3,1,-1,-3,-1,3,-3,1,-3,3,-3,3,3,1,-1,-1,1,-3,-3},
    {3,-1,1,-1,3,-3,1,1,3,-1,-3,3,1,-3,3,-1,-1,-1,-1,1,-3,-3,-3,-3},
    {-3,1,-3,3,-3,1,-3,3,1,-1,-3,-1,-3,-3,-3,-3,1,3,-1,1,3,3,3,-3},
    {-3,-1,1,-3,-1,-1,1,1,1,3,3,-1,1,-1,1,-1,-1,-3,-3,-3,3,1,-1,-3},
    {-3,3,-1,-3,-1,-1,-1,3,-1,-1,3,-3,-1,3,-3,3,-3,-1,3,1,1,-1,-3,-3},
    {-3,1,-1,-3,-3,-1,1,-3,-1,-3,1,1,-1,1,1,3,3,3,-1,1,-1,1,-1,-3},
    {-1,3,-1,-1,3,3,-1,-1,-1,3,-1,-3,1,3,1,1,-3,-3,-3,-1,-3,-1,-3,-3},
    {3,-3,-3,-1,3,3,-3,-1,3,1,1,1,3,-1,3,-3,-1,3,-1,3,1,-1,-3,-3},
    {-3,1,-3,1,-3,1,1,3,1,-3,-3,-1,1,3,-1,-3,3,1,-1,-3,-3,-3,-3,-3},
    {3,-3,-1,1,3,-1,-1,-3,-1,3,-1,-3,-1,-3,3,-1,3,1,1,-3,3,-3,-3,-3}};

// NOTE: not sure how to make C_FP16 constant table, so for now fOCC_table read in static descriptors. (Probably better as a constant table)
// static __device__ __constant__  __half2 FOCC_TABLE[4][4] =
// {{{1.000000,0.000000},{1.000000,0.000000},{1.000000,0.000000},{1.000000,0.000000}},
// {{1.000000,0.000000},{0.000000,-1.000000},{-1.000000,0.000000},{0.000000,1.000000}},
// {{1.000000,0.000000},{-1.000000,0.000000},{1.000000,0.000000},{-1.000000,0.000000}},
// {{1.000000,0.000000},{0.000000,1.000000},{-1.000000,0.000000},{0.000000,-1.000000}}};

#define RKHS_NUM_EIGS_PER_DIM (3)
#define RKHS_NUM_VER_ANTS (4)
#define RKHS_NUM_HOR_ANTS (8)
#define RKHS_NUM_CP_INTS (230)
#define RKHS_NUM_EIGS (27)
#define RKHS_NOISE_REGION_OFFSET (200)
#define RKHS_NOISE_REGION_LENGTH (40)

 template <typename TElem>
 struct kernel_tensor
 {
     TElem*     pAddr;
     const int* strides;

     CUDA_BOTH
     kernel_tensor(void* pAddr, const int* pStrides) :
         pAddr(static_cast<TElem*>(pAddr)),
         strides(pStrides)
     {
     }
     CUDA_BOTH int offset(int i0) const
     {
         return (strides[0] * i0);
     }
     CUDA_BOTH int offset(int i0, int i1) const
     {
         return (strides[0] * i0) + (strides[1] * i1);
     }
     CUDA_BOTH int offset(int i0, int i1, int i2) const
     {
         return (strides[0] * i0) + (strides[1] * i1) + (strides[2] * i2);
     };
     CUDA_BOTH int offset(int i0, int i1, int i2, int i3) const
     {
         return (strides[0] * i0) + (strides[1] * i1) + (strides[2] * i2) + (strides[3] * i3);
     };
     CUDA_BOTH int offset(int i0, int i1, int i2, int i3, int i4) const
     {
         return (strides[0] * i0) + (strides[1] * i1) + (strides[2] * i2) + (strides[3] * i3) + (strides[4] * i4);
     };
     CUDA_BOTH TElem* trace(int i1)
     {
        return pAddr + offset(0, i1);
     };

     // clang-format off
     CUDA_BOTH TElem&       operator()(int i0)                                       { return *(pAddr + offset(i0));                 }
     CUDA_BOTH TElem&       operator()(int i0, int i1)                               { return *(pAddr + offset(i0, i1));             }
     CUDA_BOTH TElem&       operator()(int i0, int i1, int i2)                       { return *(pAddr + offset(i0, i1, i2));         }
     CUDA_BOTH TElem&       operator()(int i0, int i1, int i2, int i3)               { return *(pAddr + offset(i0, i1, i2, i3));     }
     CUDA_BOTH TElem&       operator()(int i0, int i1, int i2, int i3, int i4)       { return *(pAddr + offset(i0, i1, i2, i3, i4)); }

     CUDA_BOTH const TElem& operator()(int i0) const                                 { return *(pAddr + offset(i0));                 }
     CUDA_BOTH const TElem& operator()(int i0, int i1) const                         { return *(pAddr + offset(i0, i1));             }
     CUDA_BOTH const TElem& operator()(int i0, int i1, int i2) const                 { return *(pAddr + offset(i0, i1, i2));         }
     CUDA_BOTH const TElem& operator()(int i0, int i1, int i2, int i3) const         { return *(pAddr + offset(i0, i1, i2, i3));     }
     CUDA_BOTH const TElem& operator()(int i0, int i1, int i2, int i3, int i4) const { return *(pAddr + offset(i0, i1, i2, i3, i4)); }
     // clang-format on
 };



template <int nSrsScBlock, int nAntPorts, uint8_t FOCC_LENGTH, uint8_t correctDelayOffsetFlag, uint8_t combSize>
inline __device__ void srsFilterMultiply(
   __half2 *sh_Hest,
   const __half2 *sh_rxSrs,
   const __half2 *sh_W_matrix,
   const __half2 *sh_focc_table,
   const uint8_t(&portToFoccMap)[MAX_N_ANT_PORTS_PER_COMB],
   cg::thread_block &block,
   cg::thread_block_tile<32> &tile,
   int tid,
   int nRxAntSrs,
   float* sh_phaseRamp,
   __half2*  sh_phaseLUT,
   uint16_t*  pPortToUeIdxWithinBlock)
{
//    // We currently only use tensor cores with nSrsScBlock == 24 and nRxAntSrs divisible
//    // by 16. This is because we then do not need to zero-pad either the columns or the
//    // rows when using the tensor cores. The values are complex, so nSrsScBlock == 24
//    // takes 48 half entries, which corresponds to 3 tiles for tensor core MMA dimensions
//    // where the dot products lengths are 16 (i.e., k=16).
//    if (nSrsScBlock == 24 && nRxAntSrs % 16 == 0) {
//       // For the largest case with nSrsScBlock == 24 and nPortsPerComb == 4, we
//       // split the problem into two sub-carrier groups, each with half of the
//       // sub-carriers.
//       constexpr int nSrsScGroups = (nSrsScBlock == 24 && nPortsPerComb == 4) ? 2 : 1;
//       constexpr int nSrsScPerGroup = nSrsScBlock / nSrsScGroups;
//       const int warp_id = tile.meta_group_rank();
//       const int num_warps = tile.meta_group_size();
//       const int m = 16;
//       const int n = 16;
//       const int k = 16;
//       for (int scGroup = 0; scGroup < nSrsScGroups; scGroup++) {
//          const int num_matmuls = (nRxAntSrs/m) * ((2 * nPortsPerComb * nSrsScPerGroup) / n);

//          // The A matrices contain rx antennas in rows. Each row is interleaved
//          // (real, imag) components for the complex values.
//          // The B matrices are written to shared memory in row-major order with the
//          // rows as the rows of W. These will be read in column-major order in the
//          // load_matrix_sync calls below because B is on the right-hand wide in this
//          // formulation. The rows of B (columns after transposition during load)
//          // are the rows of B with FOCC applied for each port, with the port in the
//          // fastest changing dimension.
//          // Finally, each row of W maps to two rows of B. The first row will yield
//          // the real component and the second will yield the imaginary component
//          // after A * B. Storing the data in this way means that it can be written
//          // directly to sh_Hest and interpreted as before by the remainder of the kernel
//          // (i.e. in the right order as __half2 values representing complex values).
//          for (int i = block.size()-1-tid; i < nPortsPerComb*nSrsScBlock*nSrsScPerGroup; i += block.size()) {
//             const int col = i % nSrsScBlock;
//             const int portIdx = (i / nSrsScBlock) % nPortsPerComb;
//             const int scIdx = i / (nPortsPerComb * nSrsScBlock);
//             const int out_row = 2*(scIdx*nPortsPerComb + portIdx);
//             const int foccIdx = portToFoccMap[portIdx];
//             const __half2 focc = sh_focc_table[foccIdx*(FOCC_LENGTH+1) + col%FOCC_LENGTH];
//             const int globalScIdx = scGroup*nSrsScPerGroup + scIdx;
//             const __half2 x = complex_conjmul(sh_W_matrix[globalScIdx*nSrsScBlock+col], focc);
//             // The rows below yield the real and imaginary components of A*B, respectively.
//             sh_B_fragments[out_row*nSrsScBlock+col] = __half2{x.x, -x.y};
//             sh_B_fragments[(out_row+1)*nSrsScBlock+col] = __half2{x.y, x.x};
//          }

//          __syncthreads();

//          for (int i = warp_id; i < num_matmuls; i += num_warps) {

//             // The extra 2 in the ldm stride is because this is measured in __half elements,
//             // but the data is stored as __half2. For num_total_B_cols, the 2 is because
//             // we need a column for each of the real and imaginary components.
//             constexpr unsigned load_ldm = 2 * nSrsScBlock;
//             constexpr int num_total_B_cols = 2 * nPortsPerComb * nSrsScPerGroup;
//             constexpr int num_total_B_col_frags = num_total_B_cols / n;

//             const int A_ind = i / num_total_B_col_frags;
//             const int B_ind = i % num_total_B_col_frags;

//             wmma::fragment<wmma::matrix_a, m, n, k, half, wmma::row_major> a_frag;
//             wmma::fragment<wmma::matrix_b, m, n, k, half, wmma::col_major> b_frag;
//             wmma::fragment<wmma::accumulator, m, n, k, half> c_frag;

//             const half *A_start = reinterpret_cast<const half *>(&sh_rxSrs[A_ind*m*nSrsScBlock]);
//             const half *B_start = reinterpret_cast<half *>(&sh_B_fragments[B_ind*m*nSrsScBlock]);

//             wmma::fill_fragment(c_frag, 0);

//             constexpr int num_mma_iters = nSrsScBlock * 2 / k;
//             for (int iter = 0; iter < num_mma_iters; iter++) {
//                wmma::load_matrix_sync(a_frag, A_start + iter*k, load_ldm);
//                wmma::load_matrix_sync(b_frag, B_start + iter*k, load_ldm);

//                wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);
//             }

//             // sh_Hest is in order [nRxAntSrs, nSrsScBlock, nPortsPerComb]. Each
//             half * const store_addr = reinterpret_cast<half *>(
//                sh_Hest +
//                // Each nRxAntSrs index has nSrsScBlock*nPortsPerComb elements and
//                // each A fragment covers m antenna indices (i.e. has m rows)
//                A_ind * m * nSrsScBlock * nPortsPerComb +
//                // Each B fragment covers k/2 elements of nSrsScBlock*nPortsPerComb
//                // (/2 because we need a column for each of real and imag component)
//                (scGroup*num_total_B_col_frags + B_ind) * (k/2));
//             // Factor of 2 due to storing as half instead of half2
//             constexpr unsigned store_ldm = 2*nPortsPerComb*nSrsScBlock;
//             wmma::store_matrix_sync(store_addr, c_frag, store_ldm, wmma::mem_row_major);
//          }
//          if (scGroup < nSrsScGroups-1) {
//             __syncthreads();
//          }
//       }
//    } else {

    const int max_loop_iters = nRxAntSrs * nSrsScBlock * nAntPorts;

    if(correctDelayOffsetFlag == 1)
    {
        // precompute phase rotation once and reuse nRxAntSrs times
        for(int i = tid; i < nAntPorts  * nSrsScBlock; i += block.size())
        {
            int inputScIdx = i / nAntPorts;
            int portIdx    = i % nAntPorts;
            const float phaseRamp = sh_phaseRamp[pPortToUeIdxWithinBlock[portIdx]];
            float sinv, cosv;
            __sincosf(-phaseRamp * inputScIdx * combSize, &sinv, &cosv);
            int padded_idx = portIdx * (nSrsScBlock + 1) + inputScIdx;
            sh_phaseLUT[padded_idx] = __half2(__float2half(cosv), __float2half(sinv));
        }
        __syncthreads();
    }

    for(int i = tid; i < max_loop_iters; i += block.size())
    {
        const int portIdx = i % nAntPorts;
        const int scIdx   = (i / nAntPorts) % nSrsScBlock;
        const int antIdx  = i / (nAntPorts * nSrsScBlock);
        const int foccIdx = portToFoccMap[portIdx];

        const __half2 *srs = sh_rxSrs + antIdx * nSrsScBlock;
        const __half2 *w = sh_W_matrix + scIdx*nSrsScBlock;
        const __half2* foccBase = sh_focc_table + foccIdx * (FOCC_LENGTH + 1);

        auto est  = half2{0, 0};
        //#pragma unroll
        for(int inputScIdx = 0; inputScIdx < nSrsScBlock; inputScIdx++)
        {
            __half2 inputSignal = *srs;
            if(correctDelayOffsetFlag == 1)
            {
                __half2 phase_conj = sh_phaseLUT[portIdx * (nSrsScBlock + 1) + inputScIdx];
                inputSignal = complex_mul(phase_conj, inputSignal);
            }

            const auto focc = foccBase[inputScIdx % FOCC_LENGTH];
            est = __hcmadd(complex_conjmul(*w, focc), inputSignal, est);//__hadd2(est, complex_mul(complex_conjmul(*w, focc), inputSignal));
            w++;
            srs++;
        }
        sh_Hest[i] = est;
    }
}


 template <int combSize, int nAntPorts>
__device__ __forceinline__ void srsChEstKernelInner(srsChEstStatDescr_t* pStatDescr, srsChEstDynDescr_t* pDynDescr)
{
   cg::thread_block thisThrdBlk = cg::this_thread_block();
   int              tid         = thisThrdBlk.thread_rank();
   constexpr int WARP_SIZE      = 32;
   cg::thread_block_tile<32> tile = cg::tiled_partition<WARP_SIZE>(thisThrdBlk);

   // filter parameters:
  // tensor_ref_any<CUPHY_C_16F>& tFocc_table       = pStatDescr->tFocc_table;
   tensor_ref_any<CUPHY_C_16F>& tFocc_comb2_table = pStatDescr->tFocc_comb2_table;
   tensor_ref_any<CUPHY_C_16F>& tFocc_comb4_table = pStatDescr->tFocc_comb4_table;

   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts1_wide = pStatDescr->tW_comb2_nPorts1_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts2_wide = pStatDescr->tW_comb2_nPorts2_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts4_wide = pStatDescr->tW_comb2_nPorts4_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts8_wide = pStatDescr->tW_comb2_nPorts8_wide;

   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts1_wide = pStatDescr->tW_comb4_nPorts1_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts2_wide = pStatDescr->tW_comb4_nPorts2_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts4_wide = pStatDescr->tW_comb4_nPorts4_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts6_wide = pStatDescr->tW_comb4_nPorts6_wide;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts12_wide = pStatDescr->tW_comb4_nPorts12_wide;

   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts1_narrow = pStatDescr->tW_comb2_nPorts1_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts2_narrow = pStatDescr->tW_comb2_nPorts2_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts4_narrow = pStatDescr->tW_comb2_nPorts4_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb2_nPorts8_narrow = pStatDescr->tW_comb2_nPorts8_narrow;

   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts1_narrow = pStatDescr->tW_comb4_nPorts1_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts2_narrow = pStatDescr->tW_comb4_nPorts2_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts4_narrow = pStatDescr->tW_comb4_nPorts4_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts6_narrow = pStatDescr->tW_comb4_nPorts6_narrow;
   tensor_ref_any<CUPHY_C_16F>& tW_comb4_nPorts12_narrow = pStatDescr->tW_comb4_nPorts12_narrow;

   float& noisEstDebias_comb2_nPorts1 = pStatDescr->noisEstDebias_comb2_nPorts1;
   float& noisEstDebias_comb2_nPorts2 = pStatDescr->noisEstDebias_comb2_nPorts2;
   float& noisEstDebias_comb2_nPorts4 = pStatDescr->noisEstDebias_comb2_nPorts4;
   float& noisEstDebias_comb2_nPorts8 = pStatDescr->noisEstDebias_comb2_nPorts8;

   float& noisEstDebias_comb4_nPorts1 = pStatDescr->noisEstDebias_comb4_nPorts1;
   float& noisEstDebias_comb4_nPorts2 = pStatDescr->noisEstDebias_comb4_nPorts2;
   float& noisEstDebias_comb4_nPorts4 = pStatDescr->noisEstDebias_comb4_nPorts4;
   float& noisEstDebias_comb4_nPorts6 = pStatDescr->noisEstDebias_comb4_nPorts6;
   float& noisEstDebias_comb4_nPorts12 = pStatDescr->noisEstDebias_comb4_nPorts12;

   uint8_t chEstToL2NormalizationAlgo = pStatDescr->chEstToL2NormalizationAlgo;
#ifndef ASIM_CUPHY_SRS_OUTPUT_FP32
   float   chEstToL2ConstantScaler = pStatDescr->chEstToL2ConstantScaler;
#endif
   uint8_t enableDelayOffsetCorrection = pStatDescr->enableDelayOffsetCorrection;

    // compute block parameters:
    const uint32_t    compBlockIdx   = blockIdx.x;
    compBlockDescr_t& compBlockDescr = pDynDescr->compBlockDescrs[compBlockIdx];
    const uint16_t    ueGroupIdx     = compBlockDescr.ueGroupIdx;
    const uint16_t    blockStartPrb  = compBlockDescr.blockStartPrb;
    const uint16_t    nRxAntSrs      = compBlockDescr.nRxAntSrs;
    const uint16_t    blockStartAnt  = compBlockDescr.blockStartAnt;

   // ue group parameters:
    ueGroupDescr_t&  ueGroupDescr          = pDynDescr->ueGroupDescrs[ueGroupIdx];
    uint16_t         nUes                  = ueGroupDescr.nUes;
    uint16_t         firstUeInBlockIdx     = ueGroupDescr.ueIdxs[0];
    uint8_t          firstUeInBlockCombIdx = ueGroupDescr.ueCombIdxs[0];
    uint8_t          firstUeInBlockHopIdx  = ueGroupDescr.ueHopIdxs[0];

   // parameters common to users in compute block:
   ueDescr_t& ueDescrFirst                           = pDynDescr->ueDescrs[firstUeInBlockIdx];
   uint8_t(&repSymIdxs)[MAX_N_REPS]                  = ueDescrFirst.repSymIdxs[firstUeInBlockHopIdx];
   uint8_t ueStartSym                                = ueDescrFirst.repSymIdxs[0][0];
   uint16_t hopStartPrb                              = ueDescrFirst.hopStartPrbs[firstUeInBlockHopIdx];
   uint8_t  nRepPerHop                               = ueDescrFirst.nRepPerHop[firstUeInBlockHopIdx];
   uint8_t(&u)[MAX_N_SYM]                            = ueDescrFirst.u;
   float(&q)[MAX_N_SYM]                              = ueDescrFirst.q;
   float    alphaCommon                              = ueDescrFirst.alphaCommon;
   uint8_t  n_SRS_cs_max                             = ueDescrFirst.n_SRS_cs_max;
   uint8_t  lowPaprTableIdx                          = ueDescrFirst.lowPaprTableIdx;
   uint16_t lowPaprPrime                             = ueDescrFirst.lowPaprPrime;
   uint8_t combOffset                                = ueDescrFirst.combOffsets[firstUeInBlockCombIdx];
   constexpr uint8_t nCombScPerPrb                   = (combSize == 2) ? 6 : 3;
   uint8_t              cellIdx                      = ueDescrFirst.cellIdx;
   uint8_t              prgSize                      = ueDescrFirst.prgSize;

   // cell parameters:
   cellDescr_t&                cellDescr = pDynDescr->cellDescrs[cellIdx];
   uint8_t                     mu        = cellDescr.mu;
   tensor_ref_any<CUPHY_C_16F> tDataRx   = cellDescr.tDataRx;

   // Setup: pick ChEst filter
   tensor_ref_any<CUPHY_C_16F>* pW_wide        = nullptr;
   tensor_ref_any<CUPHY_C_16F>* pW_narrow      = nullptr;
   tensor_ref_any<CUPHY_C_16F>* pFocc          = nullptr;
   float                        noiseEstDebias = 0;
    constexpr uint8_t FOCC_LENGTH  = (combSize == 2) ? 8 : 12;
   if constexpr (combSize == 2)
   {
        pFocc = &tFocc_comb2_table;
       if constexpr (nAntPorts == 1)
       {
           pW_wide        = &tW_comb2_nPorts1_wide;
           pW_narrow      = &tW_comb2_nPorts1_narrow;
           noiseEstDebias = noisEstDebias_comb2_nPorts1;
       }
       else if constexpr (nAntPorts == 2)
       {
           pW_wide        = &tW_comb2_nPorts2_wide;
           pW_narrow      = &tW_comb2_nPorts2_narrow;
           noiseEstDebias = noisEstDebias_comb2_nPorts2;
       }
       else if constexpr (nAntPorts <= 4)
       {
           pW_wide        = &tW_comb2_nPorts4_wide;
           pW_narrow      = &tW_comb2_nPorts4_narrow;
           noiseEstDebias = noisEstDebias_comb2_nPorts4;
       }
        else
       {
           pW_wide        = &tW_comb2_nPorts8_wide;
           pW_narrow      = &tW_comb2_nPorts8_narrow;
           noiseEstDebias = noisEstDebias_comb2_nPorts8;
       }
   }
   else if constexpr (combSize == 4)
   {
        pFocc = &tFocc_comb4_table;
       if constexpr (nAntPorts == 1)
       {
           pW_wide        = &tW_comb4_nPorts1_wide;
           pW_narrow      = &tW_comb4_nPorts1_narrow;
           noiseEstDebias = noisEstDebias_comb4_nPorts1;
       }
       else if constexpr (nAntPorts == 2)
       {
           pW_wide        = &tW_comb4_nPorts2_wide;
           pW_narrow      = &tW_comb4_nPorts2_narrow;
           noiseEstDebias = noisEstDebias_comb4_nPorts2;
       }
       else if constexpr (nAntPorts <= 4)
       {
           pW_wide        = &tW_comb4_nPorts4_wide;
           pW_narrow      = &tW_comb4_nPorts4_narrow;
           noiseEstDebias = noisEstDebias_comb4_nPorts4;
       }
       else if constexpr (nAntPorts <= 6)
       {
           pW_wide        = &tW_comb4_nPorts6_wide;
           pW_narrow      = &tW_comb4_nPorts6_narrow;
           noiseEstDebias = noisEstDebias_comb4_nPorts6;
       }
       else
       {
           pW_wide        = &tW_comb4_nPorts12_wide;
           pW_narrow      = &tW_comb4_nPorts12_narrow;
           noiseEstDebias = noisEstDebias_comb4_nPorts12;
       }
   }

   constexpr uint8_t nSrsScBlock = combSize == 4 ? 12 : 24;

   // shared memory assignments: temporary storage for srs computation
   __shared__ extern __half2 sh_buff[];
   __half2* sh_rxSrs      = sh_buff;                                            // size [nRxAntSrs * nSrsScBlock]
   __half2* sh_Hest       = &sh_rxSrs[nRxAntSrs * nSrsScBlock];                 // size [nRxAntSrs * nSrsScBlock * nAntPorts]
   __half2* sh_W_matrix_w = &sh_Hest[nRxAntSrs * nSrsScBlock * nAntPorts];      // size [nSrsScBlock * nSrsScBlock]
   __half2* sh_W_matrix_n = &sh_W_matrix_w[nSrsScBlock * nSrsScBlock];          // size [nSrsScBlock * nSrsScBlock]
   //other shared memory arrays
   float*   sh_phaseRamp                             = reinterpret_cast<float*>(&sh_W_matrix_n[nSrsScBlock * nSrsScBlock]);         // size [nAntPorts]
   __half2* sh_avgScCorr                             = reinterpret_cast<__half2*>(&sh_phaseRamp[nAntPorts]);                        // size [nAntPorts]
   __half2* sh_focc_table                            = &sh_avgScCorr[nAntPorts];                                                    // actual size [(FOCC_LENGTH+1) * FOCC_LENGTH], allocated size is upper limit [13*12]
   float(*sh_avgSignalEnergyPrb)[N_PRB_PER_COMP_BLK] = reinterpret_cast<float(*)[N_PRB_PER_COMP_BLK]>(&sh_focc_table[13 * 12]);     // size [nAntPorts][N_PRB_PER_COMP_BLK]
   float(*sh_avgSignalEnergySc)[nSrsScBlock]         = reinterpret_cast<float(*)[nSrsScBlock]>(&sh_avgSignalEnergyPrb[nAntPorts]);  // size [nAntPorts][nSrsScBlock]
   float*           sh_avgSignalEnergy               = reinterpret_cast<float*>(&sh_avgSignalEnergySc[nAntPorts]);                  // size [nAntPorts]
   uint32_t*        sh_ueBlockCntr                   = reinterpret_cast<uint32_t*>(&sh_avgSignalEnergy[nAntPorts]);                 // size [nAntPorts]
   __half2*         sh_tile_avgScCorr                = reinterpret_cast<__half2*>(&sh_ueBlockCntr[nAntPorts]);                      // size [number_of_warps_in_CTA*nAntPorts]
   __half2*         sh_phaseTable                    = &sh_tile_avgScCorr[tile.meta_group_size() * nAntPorts];                      // actual size [n_SRS_cs_max * nSrsScBlock], allocated size [13 * nSrsScBlock]
   __shared__ float sh_avgNoiseEnergy;
   __shared__ float sh_tmpWidebandCsCorrNotUse;
   __shared__ uint16_t csIdx2UeIdxLut[12]; // 12 >= n_SRS_cs_max

   // initialize
   for (int i = tid; i < nAntPorts; i += thisThrdBlk.size()) {
      sh_avgScCorr[i] = __float2half2_rn(0.f);
      sh_phaseRamp[i] = 0;
   }

   constexpr uint16_t INVALID_UE_IDX = 0xFFFF;
   for (int i = tid; i < n_SRS_cs_max; i += thisThrdBlk.size()) {
       csIdx2UeIdxLut[i] = INVALID_UE_IDX;  //initialize with invalid UE index
   }

  //static_assert(BLOCK_SIZE > N_PRB_PER_COMP_BLK, "Block size must be larger than N_PRB_PER_COMP_BLK");

   int max_loop_iters = nAntPorts * nSrsScBlock;
   for (int i = tid; i < nSrsScBlock; i += thisThrdBlk.size()) {
      int antPortIdx = i % nAntPorts;
      int scIdx      = i / nAntPorts;
      sh_avgSignalEnergySc[antPortIdx][scIdx] = 0.0f;
    //   sh_avgSignalEnergyPrb is initialized below by the thread
    //   responsible for accumulating sh_avgSignalEnergySc entries into sh_avgSignalEnergyPrb
   }

   if (tid == 0) { // initialize noise and signal energy for wideband SNR
       sh_avgNoiseEnergy          = 0.0f;
       sh_tmpWidebandCsCorrNotUse = 0.0f;
      for(int i = 0; i < nAntPorts; ++i)
      {
          sh_avgSignalEnergy[i] = 0.0f;
      }
   }

   for (int i = thisThrdBlk.size()-1-tid; i < FOCC_LENGTH*FOCC_LENGTH; i += thisThrdBlk.size()) {
      const int row = i / FOCC_LENGTH;
      const int col = i - row * FOCC_LENGTH; // = i % FOCC_LENGTH
      int padded_idx = row * (FOCC_LENGTH + 1) + col;
      if(combSize == 2)
      {
            sh_focc_table[padded_idx] = tFocc_comb2_table({row, col});
      }else
      {
            sh_focc_table[padded_idx] = tFocc_comb4_table({row, col});
      }
   }

//    thisThrdBlk.sync(); // this can be commented since before using the initialized shared mem above, there is another block sync barrier
//    ------------------------------------------------------------------------------------------------------------------------

//    STEP 1: Load Rx SRS subcarriers, remove ZC cover-code, average repetitions
//    flatten nested loop over nRxAntSrs -> nSrsScBlocks
   max_loop_iters = nRxAntSrs * nSrsScBlock;
   for(int i = tid; i < max_loop_iters; i += thisThrdBlk.size())
   {
       int scIdx  = i % nSrsScBlock;
       int antIdx = i / nSrsScBlock;
       __half2 srs = half2(0,0);

       int ZcScIdx   = scIdx + nCombScPerPrb * (blockStartPrb - hopStartPrb);
       int loadScIdx = N_SC_PER_PRB * blockStartPrb + scIdx * combSize + combOffset;

       for(int repIdx = 0; repIdx < nRepPerHop; repIdx++)
       {
           int symIdx = repSymIdxs[repIdx];

           // extract subcarrier for this repetition:
           __half2 y = tDataRx({loadScIdx, symIdx, blockStartAnt + antIdx});

           // compute subcarrier ZC coverCode for this repetition:
           float2 r = {0, 0}; //ToDo: check impact of sincospif instead of __sincosf on perf, if not significant use that instead
           if(lowPaprTableIdx == 0)
           {
               auto u_repIdx = u[symIdx - ueStartSym];
               __sincosf(((M_PI * LOW_PAPR_TABLE_0[u_repIdx][ZcScIdx]) / 4.0f + alphaCommon * scIdx), &r.y, &r.x);
           }
           else if(lowPaprTableIdx == 1)
           {
               auto u_repIdx = u[symIdx - ueStartSym];
               __sincosf(((M_PI * LOW_PAPR_TABLE_1[u_repIdx][ZcScIdx]) / 4.0f + alphaCommon * scIdx), &r.y, &r.x);
           }
           else
           {
              // to improve precision with large args, we use the following block to compute:
              //  __sincosf(((-M_PI * q_repIdx * m * (m + 1)) / static_cast<float>(lowPaprPrime) + alphaCommon * scIdx), &r.y, &r.x);
               uint32_t q_repIdx = static_cast<uint32_t>(q[symIdx - ueStartSym]);
               uint32_t m        =  ZcScIdx % lowPaprPrime;

               uint32_t primeRemainder = (q_repIdx * m * (m + 1)) % lowPaprPrime;
               uint32_t primeDivisor   = (q_repIdx * m * (m + 1)) / lowPaprPrime;

               float halfCycleFlag = 0;
               if((primeDivisor % 2) == 1)
               {
                   halfCycleFlag = 1;
               }

               __sincosf(-M_PI * (static_cast<float>(primeRemainder) / static_cast<float>(lowPaprPrime) + halfCycleFlag) + alphaCommon * scIdx, &r.y, &r.x);
           }

           // remove ZC coverCode and add :
           srs = __hadd2(srs, complex_conjmul(y, __float22half2_rn(r)));
       }
       // normalize :
       sh_rxSrs[i].x = srs.x / static_cast<__half>(nRepPerHop);
       sh_rxSrs[i].y = srs.y / static_cast<__half>(nRepPerHop);
   }

//    STEP 2: remove cyclic shifts and apply wide filter to estimate channel

   for (int i = thisThrdBlk.size()-1-tid; i < nSrsScBlock*nSrsScBlock; i += thisThrdBlk.size()) {
       const int row = i / nSrsScBlock;
       const int col = i - row*nSrsScBlock;
       sh_W_matrix_w[i] = (*pW_wide)({row, col});
       sh_W_matrix_n[i] = (*pW_narrow)({row, col});
   }
   __syncthreads();

   srsFilterMultiply<nSrsScBlock, nAntPorts, FOCC_LENGTH, 0, combSize>(
       sh_Hest,
       sh_rxSrs,
       sh_W_matrix_w,
       sh_focc_table,
       ueGroupDescr.portToFoccMap,
       thisThrdBlk,
       tile,
       tid,
       nRxAntSrs,
       sh_phaseRamp,
       sh_phaseTable,
       ueGroupDescr.portToUeIdxWithinBlock);
   __syncthreads();

   //=============================================================================
   // STEP 3: estimate delay phase ramp
   __half2 sumScCorr[nAntPorts];
   for(int antPortIdx = 0; antPortIdx < nAntPorts; ++antPortIdx)
   {
        sumScCorr[antPortIdx] = __float2half2_rn(0.f);
   }

   max_loop_iters = nRxAntSrs * (nSrsScBlock - 1);
   for(int i = tid; i < max_loop_iters; i += thisThrdBlk.size())
   {
       int  scIdx   = i % (nSrsScBlock - 1);
       int  antIdx  = i / (nSrsScBlock - 1);

       for(int portIdx = 0; portIdx < nAntPorts; ++portIdx)
       {
            auto est0          = sh_Hest[portIdx + nAntPorts * scIdx + nAntPorts * nSrsScBlock * antIdx];
            auto est1          = sh_Hest[portIdx + nAntPorts * (scIdx + 1) + nAntPorts * nSrsScBlock * antIdx];
            sumScCorr[portIdx] = __hadd2(sumScCorr[portIdx], complex_conjmul(est1, est0));
       }
   }

   __half2* tile_avgScCorr = sh_tile_avgScCorr + (tile.meta_group_rank() * nAntPorts);
   __half2  invScale       = __half2half2(__float2half(__frcp_rn(float(nRxAntSrs * (nSrsScBlock - 1)))));
   for(int portIdx = 0; portIdx < nAntPorts; ++portIdx)
   {
       auto tmp = cg::reduce(tile, sumScCorr[portIdx], cg::plus<__half2>());
       if(tile.thread_rank() == 0)
       {
           tile_avgScCorr[portIdx] = __hmul2(tmp, invScale);
       }
   }

   if (tile.thread_rank() == 0)
   {
       uint8_t portIdx = 0;
       for(int i = 0; i < nUes; ++i)
       {
           uint16_t ueIdx       = ueGroupDescr.ueIdxs[i];
           uint8_t  nUePorts    = pDynDescr->ueDescrs[ueIdx].nPortsPerComb;
           __half2  ueAvgScCorr = {0, 0};
           invScale             = __half2half2(__float2half(__frcp_rn(float(nUePorts))));

           // average SC corr for ports belonging to this user:
           for(int uePortIdx = 0; uePortIdx < nUePorts; ++uePortIdx)
           {
               ueAvgScCorr += tile_avgScCorr[portIdx];
               portIdx++;
           }
           ueAvgScCorr = __hmul2(ueAvgScCorr, invScale);

           atomicAdd(&sh_avgScCorr[i], ueAvgScCorr);
       }
   }
    __syncthreads();

    if(tid < nUes)
    {
        __half2 avgScCorr = sh_avgScCorr[tid];
        float   phaseRamp = atanf(__half2float(avgScCorr.y) / __half2float(avgScCorr.x)) / combSize;
        sh_phaseRamp[tid] = phaseRamp;
    }
    __syncthreads();

//===================================================================================
//    STEP 5: remove cyclic shifts and apply narrow filter to estimate channel
    if(enableDelayOffsetCorrection==1)
    {
        srsFilterMultiply<nSrsScBlock, nAntPorts, FOCC_LENGTH, 1, combSize>(
            sh_Hest,
            sh_rxSrs,
            sh_W_matrix_n,
            sh_focc_table,
            ueGroupDescr.portToFoccMap,
            thisThrdBlk,
            tile,
            tid,
            nRxAntSrs,
            sh_phaseRamp,
            sh_phaseTable,
            ueGroupDescr.portToUeIdxWithinBlock);
    }
    else
    {
        srsFilterMultiply<nSrsScBlock, nAntPorts, FOCC_LENGTH, 0, combSize>(
            sh_Hest,
            sh_rxSrs,
            sh_W_matrix_n,
            sh_focc_table,
            ueGroupDescr.portToFoccMap,
            thisThrdBlk,
            tile,
            tid,
            nRxAntSrs,
            sh_phaseRamp,
            sh_phaseTable,
            ueGroupDescr.portToUeIdxWithinBlock);
    }
    __syncthreads();

    //===================================================================================
   // STEP 6: Average estimates. Estimate energy and noise
   float noiseEnergy = 0.0f;
   float sigEnergy[nAntPorts] = {0.f};

   //if(tid==0 && blockIdx.x==0) printf(">>>> nRxAntSrs %d, nSrsScBlock %d, nAntPorts %d, n_SRS_cs_max %d\n", nRxAntSrs, nSrsScBlock, nAntPorts, n_SRS_cs_max);

   if (tid < thisThrdBlk.size() - WARP_SIZE) {
      // All but the last warp run the following two loops to compute noise/signal
      // levels and average est values.
      max_loop_iters = nRxAntSrs * nSrsScBlock;
      for(int i = tid; i < max_loop_iters; i += thisThrdBlk.size() - WARP_SIZE)
      {
         int scIdx  = i % nSrsScBlock;
         int antIdx = i / nSrsScBlock;

         const int scIdxModFoccLength = scIdx % FOCC_LENGTH;
         __half2   scRxEst{0, 0};
         uint8_t   portIdx = 0;

         for(int j = 0; j < nUes; ++j)
         {
            uint16_t ueIdx    = ueGroupDescr.ueIdxs[j];
            uint8_t  nUePorts = pDynDescr->ueDescrs[ueIdx].nPortsPerComb;
            float    sigy     = 0.f;

            int    scIdx_global = scIdx * combSize;
            float2 phase = {1.f, 0.f};
            if(enableDelayOffsetCorrection == 1)
            {
                __sincosf(sh_phaseRamp[j] * scIdx_global, &phase.y, &phase.x);
            }
            __half2 phase_half = __float22half2_rn(phase);

            for(int uePortIdx = 0; uePortIdx < nUePorts; ++uePortIdx)
            {
                auto       foccIdx = ueGroupDescr.portToFoccMap[portIdx];
                const auto focc    = sh_focc_table[foccIdx * (FOCC_LENGTH + 1) + scIdxModFoccLength];
                auto       est     = sh_Hest[portIdx + nAntPorts * scIdx + nAntPorts * nSrsScBlock * antIdx];
                auto       est2    = __hmul2(est, est);
                sigy              += __half2float(est2.x + est2.y);

                est     = complex_mul(phase_half, est);
                scRxEst = __hcmadd(focc, est, scRxEst); //__hadd2(scRxEst, complex_mul(focc, est));
                portIdx++;
            }
            sigEnergy[j] += sigy;
         }
         __half2 noise  = __hsub2(scRxEst, sh_rxSrs[i]);
         noiseEnergy   += static_cast<float>(noise.x * noise.x + noise.y * noise.y);
      }

      int numGroups = nSrsScBlock / (prgSize * nCombScPerPrb);
      max_loop_iters = nRxAntSrs * nAntPorts * numGroups;
      for (int i = tid; i < max_loop_iters; i += thisThrdBlk.size() - WARP_SIZE) {

         const int portIdx     = i % nAntPorts;
         const int antIdx      = i / (numGroups * nAntPorts);
         const int grpIdx      = (i / nAntPorts) % numGroups;
         const int scIdxOffset = grpIdx * prgSize * nCombScPerPrb;

         __half2 accum { 0, 0 };
         const __half2 *est = sh_Hest + portIdx + nAntPorts * scIdxOffset + nAntPorts * nSrsScBlock * antIdx;
         for (int scIdx = 0; scIdx < prgSize * nCombScPerPrb; scIdx++) {
               accum = __hadd2(accum, *est);
               est += nAntPorts;
         }

         const int  ueIdxWithinBlock = ueGroupDescr.portToUeIdxWithinBlock[portIdx];
         const int  ueIdx            = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
         const int  hopIdx           = ueGroupDescr.ueHopIdxs[ueIdxWithinBlock];
         const int  combIdx          = ueGroupDescr.ueCombIdxs[ueIdxWithinBlock];
         const int  uePortIdx        = ueGroupDescr.blockPortToUePortMap[portIdx];
         ueDescr_t&  ueDesc          = pDynDescr->ueDescrs[ueIdx];

         const auto  chEstBuffOffset = blockStartPrb / prgSize - ueDesc.chEstBuffStartPrbGrp;
         const auto  chEstToL2Offset = (blockStartPrb - hopStartPrb) / prgSize + (ueDesc.nPrbsPerHop / prgSize) * hopIdx;
         float2      avgH{__half22float2(accum)};

          const float estNormalizerInv = __frcp_rn(static_cast<float>(nCombScPerPrb * prgSize));
          avgH.x *= estNormalizerInv;
          avgH.y *= estNormalizerInv;
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
         tensor_ref_any<CUPHY_C_32F>& tChEstBuff        = ueDesc.tChEstBuff;
#else
         tensor_ref_any<CUPHY_C_16F>& tChEstBuff        = ueDesc.tChEstBuff;
#endif
         uint8_t(&portToUeAntMap)[MAX_N_ANT_PORTS]      = ueDesc.portToUeAntMap[combIdx];
         uint8_t(&portToL2OutUeAntMap)[MAX_N_ANT_PORTS] = ueDesc.portToL2OutUeAntMap[combIdx];
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
         tChEstBuff({chEstBuffOffset + grpIdx, blockStartAnt + antIdx, portToUeAntMap[uePortIdx]}) = avgH;
#else
         tChEstBuff({chEstBuffOffset + grpIdx, blockStartAnt + antIdx, portToUeAntMap[uePortIdx]}) = __float22half2_rn(avgH);
#endif
        

         if(chEstToL2NormalizationAlgo==0)
         {
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
             tensor_ref_any<CUPHY_C_32F>& tChEstToL2        = ueDesc.tChEstToL2;
             tChEstToL2({chEstToL2Offset + grpIdx, blockStartAnt + antIdx, portToL2OutUeAntMap[uePortIdx]}) = avgH;
#else
             tensor_ref_any<CUPHY_C_16I>& tChEstToL2 = ueDesc.tChEstToL2;
             short2 out;
             out.x = static_cast<int16_t>(avgH.x*chEstToL2ConstantScaler);
	         out.y = static_cast<int16_t>(avgH.y*chEstToL2ConstantScaler);
             tChEstToL2({chEstToL2Offset + grpIdx, blockStartAnt + antIdx, portToL2OutUeAntMap[uePortIdx]}) = out;
#endif
         }
         else if(chEstToL2NormalizationAlgo==1)
         {
             uint16_t (&prgIdxMappingL2)[CUPHY_SRS_MAX_N_PRGS_SUPPORTED] = ueDesc.prgIdxMappingL2;
             prgIdxMappingL2[chEstToL2Offset + grpIdx] = chEstBuffOffset + grpIdx;
             // as (i < nAntPorts) covers all values for uePortIdx, limit redundant writing to gmem using the following if statement
             if (i < nAntPorts)
             {
                 uint8_t (&portIdxMappingL2)[MAX_N_ANT_PORTS] = ueDesc.portIdxMappingL2;
                 portIdxMappingL2[portToL2OutUeAntMap[uePortIdx]] = portToUeAntMap[uePortIdx];
             }
         }
      }
   } else {
        // Last warp handles average signal energy accumulations.
        uint8_t antPortOffset = 0;
        for (int k = 0; k < nUes; ++k){
            uint16_t ueIdx       = ueGroupDescr.ueIdxs[k];
            uint8_t  nUePorts    = pDynDescr->ueDescrs[ueIdx].nPortsPerComb;
            float    energyAccum = 0.0f;

            for (int i = thisThrdBlk.size()-1-tid; i < nSrsScBlock; i += WARP_SIZE) {
                for(int ueAntPortIdx = 0; ueAntPortIdx < nUePorts; ++ueAntPortIdx){
                    for (int j = 0; j < nRxAntSrs; j++) {
                        const __half2 est  = sh_Hest[antPortOffset + ueAntPortIdx + nAntPorts * i + nAntPorts * nSrsScBlock * j];
                        energyAccum       += static_cast<float>(est.x * est.x + est.y * est.y);
                    }
                }
                sh_avgSignalEnergySc[k][i] = energyAccum;
            }
            antPortOffset += nUePorts;
        }
    }
   __syncthreads();

   constexpr int numPrbs = nSrsScBlock / nCombScPerPrb;
   // The reduction below uses the first thread in each warp and, for the warp-based
   // reduction, the first full warp. Thus, start from the end of the last warp for
   // this energy reduction.
   for(int ueIdxWithinBlock = 0; ueIdxWithinBlock < nUes; ++ueIdxWithinBlock)
   {
        for (int i = thisThrdBlk.size()-1-tid; i < numPrbs; i += thisThrdBlk.size()) {
            float accum = sh_avgSignalEnergySc[ueIdxWithinBlock][i*nCombScPerPrb];
            for (int j = 1; j < nCombScPerPrb; j++) {
                accum += sh_avgSignalEnergySc[ueIdxWithinBlock][i*nCombScPerPrb+j];
            }
            sh_avgSignalEnergyPrb[ueIdxWithinBlock][i] = accum;
        }
   }

   // No explicit block sync here because there is another block sync below
   // before sh_avgSignalEnergyPrb is used

    // since sum of signal energies in rare occasions might exceed the range covered by FP16, we use float instead of __half
    float warpSum_noiseEnergy = cg::reduce(tile, noiseEnergy, cg::plus<float>());
    if(tile.thread_rank() == 0)
    {
        atomicAdd(&sh_avgNoiseEnergy, warpSum_noiseEnergy);
    }

    for(int ueIdxWithinBlock = 0; ueIdxWithinBlock < nUes; ++ueIdxWithinBlock)
    {
        float warpSum_sigEnergy = cg::reduce(tile,  sigEnergy[ueIdxWithinBlock], cg::plus<float>());
        if(tile.thread_rank() == 0)
        {
            atomicAdd(&sh_avgSignalEnergy[ueIdxWithinBlock], warpSum_sigEnergy);
        }
    }
   __syncthreads();


   // STEP 7: calculate correlation w.r.t. cyclic shift in use and not use: sum over, PRB, antenna, cyclic shift
   // Use L2 norm to sum over antennas and compute blocks to reduce dependencies

   // precompute phase rotation once and reuse nRxAntSrs times
   for(int i = tid; i < n_SRS_cs_max * nSrsScBlock; i += thisThrdBlk.size())
   {
       int   csIdx =  i / nSrsScBlock;
       int   scIdx =  i % nSrsScBlock;
       float ang = -2.0f * M_PI * csIdx * scIdx / n_SRS_cs_max;
       float sinv, cosv;
       __sincosf(ang, &sinv, &cosv);
       int padded_idx = csIdx * (nSrsScBlock + 1) + scIdx;
       sh_phaseTable[padded_idx] = __half2(__float2half(cosv), __float2half(sinv));
   }
   if(tid < nAntPorts)
   {
       uint8_t csIdx            = ueGroupDescr.portToFoccMap[tid];          // 0  n_SRS_cs_max1
       uint8_t ueIdxWithinBlock = ueGroupDescr.portToUeIdxWithinBlock[tid]; // 0  nUes1
       // Each antenna port should have a unique csIdx for correct channel estimation.
       // But atomicCAS is used if L2 misconfigures and duplicates occur, results may be invalid in these cases.
       //csIdx2UeIdxLut[csIdx]    = ueIdxWithinBlock;                       // overwrite
       atomicCAS(&csIdx2UeIdxLut[csIdx],INVALID_UE_IDX, ueIdxWithinBlock);
   }
   __syncthreads();

   // calculate correlation over cyclic shifts, sum over PRBs
   for(int i = tid; i < nRxAntSrs * n_SRS_cs_max; i += thisThrdBlk.size())
   {
       uint8_t antIdx = i / n_SRS_cs_max;
       uint8_t csIdx  = i % n_SRS_cs_max;
       __half2 accSumRxCs {0, 0};

//#pragma unroll
       for(int scIdx = 0; scIdx < nSrsScBlock; scIdx ++)
       {
           __half2 phase_rotation = sh_phaseTable[csIdx * (nSrsScBlock + 1) + scIdx];
           __half2 rxSrs  = sh_rxSrs[antIdx * nSrsScBlock + scIdx];
           accSumRxCs = __hcmadd(rxSrs, phase_rotation, accSumRxCs);
       }
       float2 accSumRxCsFloat = __half22float2(accSumRxCs);
       float  accSumRxCsAbs2  = accSumRxCsFloat.x * accSumRxCsFloat.x + accSumRxCsFloat.y * accSumRxCsFloat.y;

       // sum over antennas and separate cyclic shifts in use and not used
        uint16_t ueIdxWithinBlock = csIdx2UeIdxLut[csIdx];

        if(ueIdxWithinBlock == INVALID_UE_IDX)
        {
            atomicAdd(&sh_tmpWidebandCsCorrNotUse, accSumRxCsAbs2 / ((n_SRS_cs_max - nAntPorts) * nSrsScBlock * nRxAntSrs));
        }else
        {
            uint16_t         ueIdx                = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
            uint8_t          nUePorts             = pDynDescr->ueDescrs[ueIdx].nPortsPerComb;
            volatile float&  tmpWidebandCsCorrUse = pDynDescr->ueDescrs[ueIdx].tmpWidebandCsCorrUse;

            atomicAdd((float*)(&tmpWidebandCsCorrUse), accSumRxCsAbs2 / (nUePorts * nSrsScBlock * nRxAntSrs));
        }
    }

   if(tid == 0)
   {
       sh_avgNoiseEnergy = (noiseEstDebias * nRepPerHop * sh_avgNoiseEnergy) / (nRxAntSrs * nSrsScBlock);

       float avgSigAllUes = 0.0f;
       for(int ueIdxWithinBlock = 0; ueIdxWithinBlock < nUes; ++ueIdxWithinBlock)
       {
            uint16_t ueIdx    = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
            uint8_t  nUePorts = pDynDescr->ueDescrs[ueIdx].nPortsPerComb;

            sh_avgSignalEnergy[ueIdxWithinBlock] /= (nRxAntSrs * nUePorts * nSrsScBlock);
            avgSigAllUes                      += sh_avgSignalEnergy[ueIdxWithinBlock];
       }
       avgSigAllUes /= nUes;

       if(((nAntPorts != 1) && (combSize == 4)) || ((nAntPorts == 4) && (combSize == 2)))
       {
           sh_avgNoiseEnergy = max(MIN_NOISE_ENERGY, sh_avgNoiseEnergy - avgSigAllUes * POINT_ONE_PERCENT); // use lower bound MIN_NOISE_ENERGY to avoid negative sh_avgNoiseEnergy
       }
   }
   __syncthreads();

   //=============================================================================

   // STEP 8: save output to buffers
   // avg ests are saved during the second branch in STEP 6

    // Compute and save per-prb SNR
   if(blockStartAnt == 0)
   {
       for(int ueIdxWithinBlock = 0; ueIdxWithinBlock < nUes; ++ueIdxWithinBlock)
       {
           uint16_t ueIdx    = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
           uint8_t  combIdx  = ueGroupDescr.ueCombIdxs[ueIdxWithinBlock];

           if(combIdx == 0)
           {
               uint8_t   hopIdx                 = ueGroupDescr.ueHopIdxs[ueIdxWithinBlock];
               ueDescr_t& ueDesc                = pDynDescr->ueDescrs[ueIdx];
               uint8_t   nUePorts               = ueDesc.nPortsPerComb;
               float*    pUeRbSnr               = ueDesc.pUeRbSnr;
               uint16_t  nPrbsPerHop            = ueDesc.nPrbsPerHop;
               auto      signalEnergyNormalizer = __frcp_rn(nRxAntSrs * nCombScPerPrb * nUePorts);
               for (int i = thisThrdBlk.size()-1-tid; i < N_PRB_PER_COMP_BLK; i += thisThrdBlk.size())
               {
                   sh_avgSignalEnergyPrb[ueIdxWithinBlock][i]                       = sh_avgSignalEnergyPrb[ueIdxWithinBlock][i] * signalEnergyNormalizer;
                   float rbSnr                                                      = 10.f * log10f(sh_avgSignalEnergyPrb[ueIdxWithinBlock][i] / sh_avgNoiseEnergy);
                   pUeRbSnr[nPrbsPerHop * hopIdx + blockStartPrb - hopStartPrb + i] = rbSnr;
               }
           }
       }
   }

    if(tid < nUes)
    {
       uint16_t    ueIdxWithinBlock = tid;
       uint16_t    ueIdx            = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
       ueDescr_t&  ueDesc           = pDynDescr->ueDescrs[ueIdx];

       atomicAdd((float*)(&ueDesc.tmpWidebandNoiseEnergy)  , sh_avgNoiseEnergy);
       atomicAdd((float*)(&ueDesc.tmpWidebandSignalEnergy) , sh_avgSignalEnergy[ueIdxWithinBlock]);
       atomicAdd((float*)(&ueDesc.tmpWidebandCsCorrNotUse) , sh_tmpWidebandCsCorrNotUse);
       atomicAdd((__half2*)(&ueDesc.tmpWidebandScCorr)     , sh_avgScCorr[ueIdxWithinBlock]);
       __threadfence();
       // for finalization step
        sh_ueBlockCntr[ueIdxWithinBlock] = atomicAdd(&ueDesc.ueBlockCntr, 1) + 1;
    }
    __syncthreads();

   //=============================================================================

   // FINALIZATION
   // in kernelSelect, we set grid dimension gridDim.x equal to nCompBlocks
   // the last thread-block to reach here will perform the finalization step
   if(tid < nUes)
   {
        uint16_t    ueIdxWithinBlock = tid;
        uint16_t    ueIdx            = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
        ueDescr_t&  ueDesc           = pDynDescr->ueDescrs[ueIdx];

        cuphySrsReport_t*&   pUeSrsReport                 = ueDesc.pUeSrsReport;
        float&               widebandSnr                  = pUeSrsReport->widebandSnr;
        float&               toEstMicroSec                = pUeSrsReport->toEstMicroSec;
        float&               widebandNoiseEnergy          = pUeSrsReport->widebandNoiseEnergy;
        float&               widebandSignalEnergy         = pUeSrsReport->widebandSignalEnergy;
        __half2&             widebandScCorr               = pUeSrsReport->widebandScCorr;
        float&               widebandCsCorrRatioDb        = pUeSrsReport->widebandCsCorrRatioDb;
        float&               widebandCsCorrUse            = pUeSrsReport->widebandCsCorrUse;
        float&               widebandCsCorrNotUse         = pUeSrsReport->widebandCsCorrNotUse;
        uint8_t&             highDensityAntPortFlag       = pUeSrsReport->highDensityAntPortFlag;

        if(sh_ueBlockCntr[ueIdxWithinBlock] == ueDesc.ueNumBlocks)
        {
            //printf("nUes %d  ,tid %d, compIdx %d\n", nUes, tid, compBlockIdx);

            highDensityAntPortFlag = (nAntPorts > 4);
            // wideband signal and noise:
            widebandSnr          = 10.f * log10f(ueDesc.tmpWidebandSignalEnergy / ueDesc.tmpWidebandNoiseEnergy);
            widebandSignalEnergy = ueDesc.tmpWidebandSignalEnergy;
            widebandNoiseEnergy  = ueDesc.tmpWidebandNoiseEnergy;

            // timing advance:
            uint32_t scs  = (1 << mu) * 15000; //2^mu * 15*10^3
            toEstMicroSec = float(-1.0e6) * atanf(__half2float(ueDesc.tmpWidebandScCorr.y) / __half2float(ueDesc.tmpWidebandScCorr.x)) / static_cast<float>(2 * M_PI * scs * combSize);

            // wideband SC correlation:
            widebandScCorr.x = ueDesc.tmpWidebandScCorr.x;
            widebandScCorr.y = ueDesc.tmpWidebandScCorr.y;

            // cyclic correlation ratio:
            widebandCsCorrUse     = ueDesc.tmpWidebandCsCorrUse;
            widebandCsCorrNotUse  = ueDesc.tmpWidebandCsCorrNotUse;
            widebandCsCorrRatioDb = 10.f * log10f(ueDesc.tmpWidebandCsCorrUse / ueDesc.tmpWidebandCsCorrNotUse);
        }
    }
}

template<uint8_t fourierTranSize, uint8_t log2FourierTranSize>
static inline __device__ void warpFourierTransform(const uint32_t THREAD_IDX, __half2& sigValue, uint8_t* pFourierPermuteIdxs)
{
    __half2* pTwiddleFactors = d_twiddle32;

    // tile:
    cg::thread_block_tile<fourierTranSize> tile = cg::tiled_partition<fourierTranSize>(cg::this_thread_block());

    // byte-reverse permute the inputs:
    uint8_t fourierBlockIdx       = THREAD_IDX % fourierTranSize;
    uint8_t idxWithinFourierBlock = 0;
    uint8_t fourierBlockSize      = 1;

    // signal index:
    uint8_t sigIdx  = THREAD_IDX % fourierTranSize;

    // Byte-reverse permute the signal:
    uint8_t inputIdx = pFourierPermuteIdxs[sigIdx];
    sigValue.x       = tile.shfl(sigValue.x, inputIdx);
    sigValue.y       = tile.shfl(sigValue.y, inputIdx);

    for(uint8_t fourierStage = 1;  fourierStage <= log2FourierTranSize; fourierStage++)
    {
        // Determine if Fourier block even or odd:
        uint8_t oddFlag = fourierBlockIdx % 2;

        // If odd Fourier block, multiply by the twiddle factor.
        // Determine butterfly input idx.
        // Determine butterfly sign:
        uint8_t butterflyInputIdx = sigIdx + fourierBlockSize;
        __half2 butterflySgn       = {static_cast<__half>(1), static_cast<__half>(1)};
        __half2 sigValueBefore     = sigValue;
        if(oddFlag)
        {
            __half2 twiddleValue = pTwiddleFactors[idxWithinFourierBlock];
            sigValue           = complex_mul(sigValue, pTwiddleFactors[idxWithinFourierBlock]);
            butterflyInputIdx -= 2*fourierBlockSize;
            butterflySgn       = {static_cast<__half>(-1), static_cast<__half>(-1)};
        }

        // load butterfly input:
        __half2 butterflyInput;
        butterflyInput.x = tile.shfl(sigValue.x, butterflyInputIdx);
        butterflyInput.y = tile.shfl(sigValue.y, butterflyInputIdx);

        // butterfly operation:
        sigValue = __hfma2(butterflySgn, sigValue, butterflyInput);

        // update twiddle buffer:
        pTwiddleFactors += fourierBlockSize;

        // update Fourier block indidices:
        idxWithinFourierBlock += fourierBlockSize * (fourierBlockIdx % 2);
        fourierBlockIdx        = fourierBlockIdx / 2;

        // update Fourier block size:
        fourierBlockSize *= 2;
    }
}


template<uint8_t log2SecondStageFourierSize>
static inline __device__ void twoStageFourierTransform(const uint32_t THREAD_IDX, __half2& sigValue, tensor_ref_any<CUPHY_C_16F>& tSecondStageTwiddleFactors, uint8_t* pSecondStageFourierPerm, __half2* sh_fourierWorkspace, __half2* pOutputBuffer, uint16_t outputOffset, uint16_t nOutputs)
{
    // Cooley-Tukey Fourier transform with two stages. First stage consists of FFTs of size 32,
    // second stage consists of FFTs of size nZpDmrs / 32 (denoted secondStageFourierSize)
    constexpr uint8_t firstStageFourierSize     = 32;
    constexpr uint8_t log2FirstStageFourierSize = 5;

    if(log2SecondStageFourierSize == 0) // if second stage size is only 1, no need to perform it.
    {
        warpFourierTransform<firstStageFourierSize, log2FirstStageFourierSize>(THREAD_IDX, sigValue, d_fourier32PermuteIdx);
        sh_fourierWorkspace[THREAD_IDX] = sigValue;
        __syncthreads();
    }else
    {
        constexpr uint8_t secondStageFourierSize = (static_cast<uint8_t>(1) << log2SecondStageFourierSize);

        // First determine thread's location within the 32-blocks:
        uint8_t idxWithinFirstStageFourierBlock = THREAD_IDX % firstStageFourierSize;
        uint8_t firstStageBlockIdx              = THREAD_IDX / firstStageFourierSize;

        // permute the signal secondStageFourierSize x firstStageFourierSize --> firstStageFourierSize x secondStageFourierSize
        sh_fourierWorkspace[THREAD_IDX] = sigValue;
        __syncthreads();
        sigValue = sh_fourierWorkspace[firstStageBlockIdx + idxWithinFirstStageFourierBlock * secondStageFourierSize];

        // Perform first stage 32-FFTs:
        warpFourierTransform<firstStageFourierSize, log2FirstStageFourierSize>(THREAD_IDX, sigValue, d_fourier32PermuteIdx);

        // Multiply by twiddle factors:
        sigValue = complex_mul(sigValue, tSecondStageTwiddleFactors({idxWithinFirstStageFourierBlock, firstStageBlockIdx}));

        // permute the signal firstStageFourierSize x secondStageFourierSize --> secondStageFourierSize x firstStageFourierSize
        sh_fourierWorkspace[firstStageBlockIdx + idxWithinFirstStageFourierBlock * secondStageFourierSize] = sigValue;
        __syncthreads();
        sigValue = sh_fourierWorkspace[THREAD_IDX];

        // Perform second stage FFTs:
        warpFourierTransform<secondStageFourierSize, log2SecondStageFourierSize>(THREAD_IDX, sigValue, pSecondStageFourierPerm);

        // permute the signal secondStageFourierSize x firstStageFourierSize --> firstStageFourierSize x secondStageFourierSize
        uint8_t secondStageBlockIdx              = THREAD_IDX / secondStageFourierSize;
        uint8_t idxWithinSecondStageFourierBlock = THREAD_IDX % secondStageFourierSize;

        // store in result in output buffer:
        uint16_t outputIdx = secondStageBlockIdx + idxWithinSecondStageFourierBlock * firstStageFourierSize;
        if((outputOffset <= outputIdx) && (outputIdx < (outputOffset + nOutputs)))
        {
            pOutputBuffer[outputIdx - outputOffset] = sigValue;
        }

      //  sh_fourierWorkspace[secondStageBlockIdx + idxWithinSecondStageFourierBlock * firstStageFourierSize] = sigValue;
        __syncthreads();
    }
}


__global__ void srsChEstNormalizationKernel(srsChEstDynDescr_t* pDynDescr)
{
    constexpr int WARP_SIZE   = 32;
    auto          thisThrdBlk = cg::this_thread_block();
    auto          tile        = cg::tiled_partition<WARP_SIZE>(thisThrdBlk);
    int           tid         = thisThrdBlk.thread_rank();

    ueDescr_t&  ueDesc          = pDynDescr->ueDescrs[blockIdx.x];
    //printf("I am in the normalization kernel for UE[%d] with PRG[%d]Ant[%d]Port[%d]!\n", blockIdx.x, ueDesc.nPrbGrpsL2, ueDesc.nRxAntSrsL2, ueDesc.nAntPortsL2);
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
    tensor_ref_any<CUPHY_C_32F>& tChEstBuff        = ueDesc.tChEstBuff;
    tensor_ref_any<CUPHY_C_32F>& tChEstToL2        = ueDesc.tChEstToL2;
#else
    tensor_ref_any<CUPHY_C_16F>& tChEstBuff        = ueDesc.tChEstBuff;
    tensor_ref_any<CUPHY_C_16I>& tChEstToL2        = ueDesc.tChEstToL2;
#endif

    uint16_t (&prgIdxMappingL2)[CUPHY_SRS_MAX_N_PRGS_SUPPORTED] = ueDesc.prgIdxMappingL2;
    uint8_t (&portIdxMappingL2)[MAX_N_ANT_PORTS] = ueDesc.portIdxMappingL2;

    int nPrbGrpsL2  = ueDesc.nPrbGrpsL2;
    int nRxAntSrsL2 = ueDesc.nRxAntSrsL2;
    int nAntPortsL2 = ueDesc.nAntPortsL2;

    __shared__ int peakValint;
    if(tid == 0) peakValint = 0;
    __syncthreads();

    // find peak value (squared)
    float localPeak2 = 0.f;
    for(int prgIdx = tid; prgIdx < nPrbGrpsL2; prgIdx += thisThrdBlk.size())
    {
        for(int antIdx = 0; antIdx < nRxAntSrsL2; antIdx++)
        {
            for(int portIdx = 0; portIdx < nAntPortsL2; portIdx++)
            {
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
                float2 tmp = tChEstBuff({prgIdxMappingL2[prgIdx], antIdx, portIdxMappingL2[portIdx]});
#else
                float2 tmp = __half22float2(tChEstBuff({prgIdxMappingL2[prgIdx], antIdx,portIdxMappingL2[portIdx]}));

#endif
                float mag2 = tmp.x * tmp.x + tmp.y * tmp.y;
                localPeak2 = fmaxf(localPeak2, mag2);
            }
        }
    }

    float blockPeak2 = cg::reduce(tile, localPeak2, cg::greater<float>());
    int blockPeak2int = __float_as_int(blockPeak2);

    if (tile.thread_rank() == 0)
    {
        // since blockPeak2 is positive, it is safe to assume finding the thread with max blockPeak2int is equivalent to finding the thread with max blockPeak2
        atomicMax(&peakValint, blockPeak2int);
    }
    __syncthreads();
    float peakValInv = rsqrtf(__int_as_float(peakValint));
    constexpr float fixed_scale = 32768.0f;
    float scale = fixed_scale * peakValInv;

    for(int prgIdx = tid; prgIdx < nPrbGrpsL2; prgIdx += thisThrdBlk.size())
    {
        uint16_t prgIdxMapped = prgIdxMappingL2[prgIdx];
        for(int antIdx = 0; antIdx < nRxAntSrsL2; antIdx++)
        {
            for(int portIdx = 0; portIdx < nAntPortsL2; portIdx++)
            {
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
                float2 tmp = tChEstBuff({prgIdxMapped, antIdx, portIdxMappingL2[portIdx]});
                float2 res;
                res.x = scale * tmp.x;
                res.y = scale * tmp.y;
                tChEstToL2({prgIdx, antIdx, portIdx}) = res;
#else
                float2 tmp = __half22float2(tChEstBuff({prgIdxMapped, antIdx,portIdxMappingL2[portIdx]}));
                short2 res;
                res.x = static_cast<int16_t>(scale * tmp.x);
                res.y = static_cast<int16_t>(scale * tmp.y);
                tChEstToL2({prgIdx, antIdx, portIdx}) = res;
#endif
            }
        }
    }
}

__launch_bounds__(1024, 1)
__global__ void srsRkhsChEstKernel(srsChEstStatDescr_t* pStatDescr, srsChEstDynDescr_t* pDynDescr)
{
    // thread/warp indicies:
    uint16_t THREAD_IDX = threadIdx.x;
    uint16_t BLOCK_IDX  = blockIdx.x;
    uint8_t  WARP_IDX   = THREAD_IDX / 32;
    uint8_t  LANE_IDX   = THREAD_IDX % 32;

    // warp parameters:
    cg::thread_block thisThrdBlk   = cg::this_thread_block();
    constexpr int WARP_SIZE        = 32;
    cg::thread_block_tile<32> tile = cg::tiled_partition<WARP_SIZE>(thisThrdBlk);

    // compute block descriptor:
    rkhsCompBlockDescriptor_t& compBlock = pDynDescr->rkhsCompBlockDescrs[BLOCK_IDX];

    uint16_t ueIdx   = compBlock.ueIdx;
    uint8_t  combIdx = compBlock.combIdx;
    uint8_t  portIdx = compBlock.portIdx;
    uint8_t  polIdx  = compBlock.polIdx;

    // fixed parameters (TODO: make flexible)
    constexpr uint8_t  hopIdx       = 0;
    constexpr uint8_t  combSize     = 4;
    constexpr uint8_t  nVerAnt      = 4;
    constexpr uint8_t  nHorAnt      = 8;
//    constexpr uint8_t  nAnt         = nVerAnt * nHorAnt;
    constexpr uint8_t  nPol         = 2;
    constexpr uint16_t nSrsSc       = 816;
    constexpr uint16_t nSrsScZp     = 1024;
    constexpr uint8_t  nEigsPerDim  = 3;
    constexpr uint16_t nCpInts      = RKHS_NUM_CP_INTS;

    constexpr uint16_t nMeasurments = nVerAnt * nHorAnt * nSrsSc;

    // eigenvector indicies:
    uint8_t FREQ_EIG_IDX    = LANE_IDX % nEigsPerDim;
    uint8_t VER_ANT_EIG_IDX = (LANE_IDX /  nEigsPerDim) % nEigsPerDim;
    uint8_t HOR_ANT_EIG_IDX = (LANE_IDX / (nEigsPerDim * nEigsPerDim)) % nEigsPerDim;
    uint8_t EIG_IDX         = LANE_IDX;
    uint8_t EIG_FLAG        = (LANE_IDX < 27) ? 1 : 0;

    // box sizes:
    constexpr uint16_t     maxNumBoxesPerThread     = 20;
    constexpr uint16_t     maxNumBoxes              = maxNumBoxesPerThread * 32;
    constexpr uint16_t     maxNumEqBoxes            = 256;
    uint8_t                nBoxesStoredByThisThread = 0;

    // freqProj and HammingProj coeff buffers:
    tensor_ref<CUPHY_C_16F, 4>& tFreqProjCoeffs    = compBlock.tFreqProjCoeffs;
    tensor_ref<CUPHY_C_16F, 3>& tHammingProjCoeffs = compBlock.tHammingProjCoeffs;

    // Fourier workspace:
    __shared__ __half2  sh_FourierWorkspace[nSrsScZp];
    __shared__ float    sh_noiseEnergy;
    __shared__ float    sh_sigEnergy;

    // FOCC coefficents:
    tensor_ref_any<CUPHY_C_16F>& tFocc_comb4_table = pStatDescr->tFocc_comb4_table;
    constexpr uint8_t FOCC_LENGTH = 12;
    __shared__ __half2 sh_focc_table[FOCC_LENGTH*FOCC_LENGTH];

    if(THREAD_IDX < FOCC_LENGTH * FOCC_LENGTH)
    {
        const int row = THREAD_IDX / FOCC_LENGTH;
        const int col = THREAD_IDX - row * FOCC_LENGTH;

        sh_focc_table[THREAD_IDX] = tFocc_comb4_table({row, col});
    }
    __syncthreads();

    // antenna projection coefficents:
    constexpr uint16_t antProjCoeffSize = maxNumEqBoxes * nEigsPerDim * nEigsPerDim * nEigsPerDim;
    __shared__ __half2 sh_antProjCoeffs[antProjCoeffSize];

    // vert antenna proj coeff tensor:
    constexpr int verProj_s0 = 1;
    constexpr int verProj_s1 = nHorAnt;
    constexpr int verProj_s2 = nHorAnt * nVerAnt;
    constexpr int verProj_s3 = nHorAnt * nVerAnt * nEigsPerDim;
    const int verProj_strides[4] = {verProj_s0, verProj_s1, verProj_s2, verProj_s3};
    kernel_tensor<__half2> sh_tVertAntProjCoeffs(sh_antProjCoeffs, verProj_strides); // nHorAnt x nVerAnt x freqEigs x verAntEigs

    // hor/ver proj coeff tensor:
    constexpr int antProj_s0 = 1;
    constexpr int antProj_s1 = nEigsPerDim;
    constexpr int antProj_s2 = nEigsPerDim * nEigsPerDim;
    constexpr int antProj_s3 = nEigsPerDim * nEigsPerDim * nEigsPerDim;
    const int antProj_strides[4] = {antProj_s0, antProj_s1, antProj_s2, antProj_s3};
    kernel_tensor<__half2> sh_tAntProjCoeffs(sh_antProjCoeffs, antProj_strides); // freqEigs x verAntEigs x horAntEigs x nAnt

    // freq eig corr:
    constexpr int freqCorrSize = nCpInts * nEigsPerDim * nEigsPerDim;
    __shared__ __half2 sh_freqCorr[freqCorrSize];
    kernel_tensor<__half2> sh_tFreqCorr(sh_freqCorr, antProj_strides);

    // verAnt corr:
    constexpr int verAntCorrSize = nVerAnt * nEigsPerDim * nEigsPerDim;
    __shared__ __half2 sh_verAntCorr[verAntCorrSize];
    kernel_tensor<__half2> sh_tVerAntCorr(sh_verAntCorr, antProj_strides);

    // horAnt corr:
    constexpr int horAntCorrSize = nHorAnt * nEigsPerDim * nEigsPerDim;
    __shared__ __half2 sh_horAntCorr[horAntCorrSize];
    kernel_tensor<__half2> sh_tHorAntCorr(sh_horAntCorr, antProj_strides);

    // eq coeff tensor:
    kernel_tensor<__half2> sh_tEqCoeffs(sh_antProjCoeffs, antProj_strides);

    // box energy:
    __shared__ uint16_t sh_eqCoeffFreqIntIdx[maxNumEqBoxes];
    __shared__ uint8_t  sh_eqCoeffVerAntIntIdx[maxNumEqBoxes];
    __shared__ uint8_t  sh_eqCoeffHorAntIntIdx[maxNumEqBoxes];

    // indicies:
    __shared__ float sh_boxEnergy[32];
    __shared__ float sh_antNoiseEnergy[32];

    // thread buffers:
    __half2   threadProjCoeffs[maxNumBoxesPerThread];
    uint16_t  threadFreqIntIdxs[maxNumBoxesPerThread];
    uint8_t   threadVerAntIntIdxs[maxNumBoxesPerThread];
    uint8_t   threadHorAntIntIdxs[maxNumBoxesPerThread];

    // Freq eigenvectors:
    tensor_ref_any<CUPHY_R_16F>& tFreqEigVecs               = pStatDescr->rkhsGridDescs[2].tEigenVecs;
    tensor_ref_any<CUPHY_C_16F>& tFreqEigCorr               = pStatDescr->rkhsGridDescs[2].tEigenCorr;
    tensor_ref_any<CUPHY_R_8U>&  tSecondStageFourierPerm    = pStatDescr->rkhsGridDescs[2].tSecondStageFourierPerm;
    tensor_ref_any<CUPHY_C_16F>& tSecondStageTwiddleFactors = pStatDescr->rkhsGridDescs[2].tSecondStageTwiddleFactors;

    // horizantal antenna eigenvectors:
    tensor_ref_any<CUPHY_R_16F>& tHorAntEigVecs = pStatDescr->rkhsGridDescs[1].tEigenVecs;
    tensor_ref_any<CUPHY_C_16F>& tHorAntEigCorr = pStatDescr->rkhsGridDescs[1].tEigenCorr;

    // vertical antenna eigenvectors:
    tensor_ref_any<CUPHY_R_16F>& tVerAntEigVecs = pStatDescr->rkhsGridDescs[0].tEigenVecs;
    tensor_ref_any<CUPHY_C_16F>& tVerAntEigCorr = pStatDescr->rkhsGridDescs[0].tEigenCorr;

    // user descriptor:
   ueDescr_t& ueDescr                                = pDynDescr->ueDescrs[ueIdx];
   uint8_t(&repSymIdxs)[MAX_N_REPS]                  = ueDescr.repSymIdxs[hopIdx];
   uint8_t ueStartSym                                = ueDescr.repSymIdxs[0][0];
//   uint16_t hopStartPrb                              = ueDescr.hopStartPrbs[hopIdx];
   uint8_t  nRepPerHop                               = ueDescr.nRepPerHop[hopIdx];
//   uint16_t nPrbsPerHop                              = ueDescr.nPrbsPerHop;
   uint8_t(&u)[MAX_N_SYM]                            = ueDescr.u;
   float(&q)[MAX_N_SYM]                              = ueDescr.q;
   float    alphaCommon                              = ueDescr.alphaCommon;
//   uint8_t  n_SRS_cs_max                             = ueDescr.n_SRS_cs_max;
   uint8_t  lowPaprTableIdx                          = ueDescr.lowPaprTableIdx;
   uint16_t lowPaprPrime                             = ueDescr.lowPaprPrime;
//   uint8_t  nPorts                                   = ueDescr.nPorts;
   uint8_t(&portToFoccMap)[MAX_N_ANT_PORTS]          = ueDescr.portToFoccMap[combIdx];
   uint8_t combOffset                                = ueDescr.combOffsets[combIdx];
//   constexpr uint8_t nCombScPerPrb                   = (combSize == 2) ? 6 : 3;
   uint8_t(&portToUeAntMap)[MAX_N_ANT_PORTS]         = ueDescr.portToUeAntMap[combIdx];
//   uint8_t(&portToL2OutUeAntMap)[MAX_N_ANT_PORTS]    = ueDescr.portToL2OutUeAntMap[combIdx];
//   float*               pUeRbSnr                     = ueDescr.pUeRbSnr;
   uint8_t              cellIdx                      = ueDescr.cellIdx;
   uint8_t              prgSize                      = ueDescr.prgSize;
//    cuphySrsReport_t*&   pUeSrsReport                 = ueDescr.pUeSrsReport;
//    float&               widebandSnr                  = pUeSrsReport->widebandSnr;
//    float&               toEstMicroSec                = pUeSrsReport->toEstMicroSec;
//    float&               widebandNoiseEnergy          = pUeSrsReport->widebandNoiseEnergy;
//    float&               widebandSignalEnergy         = pUeSrsReport->widebandSignalEnergy;
//    __half2&             widebandScCorr               = pUeSrsReport->widebandScCorr;
//    float&               widebandCsCorrRatioDb        = pUeSrsReport->widebandCsCorrRatioDb;
//    float&               widebandCsCorrUse            = pUeSrsReport->widebandCsCorrUse;
//    float&               widebandCsCorrNotUse         = pUeSrsReport->widebandCsCorrNotUse;
//   volatile float&      tmpWidebandNoiseEnergy       = ueDescr.tmpWidebandNoiseEnergy;
//   volatile float&      tmpWidebandSignalEnergy      = ueDescr.tmpWidebandSignalEnergy;
//   volatile float&      tmpWidebandCsCorrUse         = ueDescr.tmpWidebandCsCorrUse;
//   volatile float&      tmpWidebandCsCorrNotUse      = ueDescr.tmpWidebandCsCorrNotUse;
//   volatile __half2&    tmpWidebandScCorr            = ueDescr.tmpWidebandScCorr;
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
   tensor_ref_any<CUPHY_C_32F>& tChEstBuff           = ueDescr.tChEstBuff;
#else
   tensor_ref_any<CUPHY_C_16F>& tChEstBuff           = ueDescr.tChEstBuff;
#endif
//   uint16_t                     chEstBuffStartPrbGrp = ueDescr.chEstBuffStartPrbGrp;
//   tensor_ref_any<CUPHY_C_16F>& tChEstToL2           = ueDescr.tChEstToL2;

    // outputs:
    uint16_t nOutSc   = 272 / prgSize;
    uint16_t nOutputs = nOutSc * nVerAnt * nHorAnt;

    // cell parameters:
   cellDescr_t&                cellDescr = pDynDescr->cellDescrs[cellIdx];
   tensor_ref_any<CUPHY_C_16F> tDataRx   = cellDescr.tDataRx;

   if(THREAD_IDX == 0)
   {
        sh_noiseEnergy = 0.0f;
        sh_sigEnergy   = 0.0f;
   }

   if(THREAD_IDX < 32)
   {
        sh_antNoiseEnergy[THREAD_IDX] = 0.0f;
   }

   ////////////////////////////////////////////////////////////////
   // STEP 1: remove cover codes / freq proj

    uint16_t scIdx              = THREAD_IDX * combSize + combOffset;
    uint16_t ZcScIdx            = THREAD_IDX;
    __half2* pFreqProjCoeffs    = static_cast<__half2*>(tFreqProjCoeffs.addr());
    __half2* pHammingProjCoeffs = static_cast<__half2*>(tHammingProjCoeffs.addr());


    // correlate with modulated frequency eigenvectors:
    for(int horAntIdx = 0; horAntIdx < nHorAnt; ++horAntIdx)
    {
        for(int verAntIdx = 0; verAntIdx < nVerAnt; ++verAntIdx)
        {
            __half2 srs = half2(0,0);

            if(THREAD_IDX < nSrsSc)
            {
                uint8_t antIdx = horAntIdx * nVerAnt * nPol + verAntIdx * nPol + polIdx;
                for(int repIdx = 0; repIdx < nRepPerHop; repIdx++)
                {
                    int symIdx = repSymIdxs[repIdx];

                    // extract subcarrier for this repetition:
                    __half2 y = tDataRx({scIdx, symIdx, antIdx});

                    // compute subcarrier ZC coverCode for this repetition:
                    float2 r = {0, 0}; //ToDo: check impact of sincospif instead of __sincosf on perf, if not significant use that instead

                    if(lowPaprTableIdx == 0)
                    {
                        auto u_repIdx = u[symIdx - ueStartSym];
                        __sincosf(((M_PI * LOW_PAPR_TABLE_0[u_repIdx][ZcScIdx]) / 4.0f + alphaCommon * scIdx), &r.y, &r.x);
                    }
                    else if(lowPaprTableIdx == 1)
                    {
                        auto u_repIdx = u[symIdx - ueStartSym];
                        __sincosf(((M_PI * LOW_PAPR_TABLE_1[u_repIdx][ZcScIdx]) / 4.0f + alphaCommon * scIdx), &r.y, &r.x);
                    }
                    else
                    {
                        // to improve precision with large args, we use the following block to compute:
                        //__sincosf(((-M_PI * q_repIdx * m * (m + 1)) / static_cast<float>(lowPaprPrime) + alphaCommon * scIdx), &r.y, &r.x);
                        uint32_t q_repIdx = static_cast<uint32_t>(q[symIdx - ueStartSym]);
                        uint32_t m        =  ZcScIdx % lowPaprPrime;

                        uint32_t primeRemainder = (q_repIdx * m * (m + 1)) % lowPaprPrime;
                        uint32_t primeDivisor   = (q_repIdx * m * (m + 1)) / lowPaprPrime;

                        float halfCycleFlag = 0;
                        if((primeDivisor % 2) == 1)
                        {
                            halfCycleFlag = 1;
                        }

                        __sincosf(-M_PI * (static_cast<float>(primeRemainder) / static_cast<float>(lowPaprPrime) + halfCycleFlag) + alphaCommon * scIdx, &r.y, &r.x);
                    }

                    // remove ZC coverCode :
                    y = complex_conjmul(y, __float22half2_rn(r));

                    // remove cylcic shift :
                    uint8_t foccIdx      = portToFoccMap[portIdx];
                    uint8_t foccTableIdx = (ZcScIdx % FOCC_LENGTH) + foccIdx * FOCC_LENGTH;
                    __half2 cs           = sh_focc_table[foccTableIdx];
                    y = complex_conjmul(y, cs);

                    // accumulate :
                    srs = __hadd2(srs, y);
                }
            }

            // correlate with modulated Hamming window:
            __half2 corrVal = half2(0,0);
            if(THREAD_IDX < nSrsSc)
            {
                corrVal.x = srs.x * d_hammingWindow[THREAD_IDX];
                corrVal.y = srs.y * d_hammingWindow[THREAD_IDX];
            }

            // twoStageFourierTransform
            constexpr uint8_t log2SecondStageFourierSize = 5;
            uint8_t* pPermute = tSecondStageFourierPerm.addr();

            __syncthreads();
            twoStageFourierTransform<log2SecondStageFourierSize>(THREAD_IDX, corrVal, tSecondStageTwiddleFactors, tSecondStageFourierPerm.addr(), sh_FourierWorkspace, pHammingProjCoeffs, RKHS_NOISE_REGION_OFFSET, RKHS_NOISE_REGION_LENGTH);
            pHammingProjCoeffs += RKHS_NOISE_REGION_LENGTH;

            for(int eigIdx = 0; eigIdx < nEigsPerDim; ++eigIdx)
            {

                __half2 corrVal = half2(0,0);
                if(THREAD_IDX < nSrsSc)
                {
                    __half  eigVecVal = tFreqEigVecs({THREAD_IDX, eigIdx});

                    corrVal.x = srs.x * eigVecVal;
                    corrVal.y = srs.y * eigVecVal;
                }

                // twoStageFourierTransform
                uint16_t nCpIntervals = RKHS_NUM_CP_INTS;
                __syncthreads();
                twoStageFourierTransform<log2SecondStageFourierSize>(THREAD_IDX, corrVal, tSecondStageTwiddleFactors, tSecondStageFourierPerm.addr(), sh_FourierWorkspace, pFreqProjCoeffs, 0, nCpIntervals);
                pFreqProjCoeffs += RKHS_NUM_CP_INTS;
            }
        }
    }

   ////////////////////////////////////////////////////////////////
   // STEP 2: noise + interference estimation


    for(int noiseIntIdx = 0; noiseIntIdx < RKHS_NOISE_REGION_LENGTH; ++noiseIntIdx)
    {
        // correlate with modulated vertAnt eigenvectors:
        {
            __half2 corrVal = half2(0,0);

            // verAnt porjection tensor: (nVerAnt x nHorAnt x verAntEigVec)
            uint16_t tensorSize = nVerAnt * nHorAnt * nEigsPerDim;

            // compute tensor indicies for this thread:
            int verAntIdx    = THREAD_IDX % nVerAnt;
            int horAntIdx    = (THREAD_IDX / nVerAnt) % nHorAnt;
            int verAntEigIdx = (THREAD_IDX / (nHorAnt * nVerAnt)) % nEigsPerDim;

            // check if thread in tensor:
            if(THREAD_IDX < tensorSize)
            {
                // compute correlation with verAnt eigvector:
                __half  eigVecVal      = tVerAntEigVecs({verAntIdx, verAntEigIdx});
                __half2 hammingProjVal = tHammingProjCoeffs({noiseIntIdx, verAntIdx, horAntIdx});

                corrVal.x = hammingProjVal.x * eigVecVal;
                corrVal.y = hammingProjVal.y * eigVecVal;
            }

            // perform FFT across the vertical antennas:
            warpFourierTransform<4,2>(THREAD_IDX, corrVal, d_fourier4PermuteIdx);

            // store verAnt projection coefficents in shared memory:
            if(THREAD_IDX < tensorSize)
            {
                sh_tVertAntProjCoeffs(horAntIdx, verAntIdx, verAntEigIdx, 0) = corrVal;
            }
            __syncthreads();
        }

        // correlate with modulated horAnt eigenvectors:
        {
            __half2 corrVal = half2(0,0);

            // horAnt porjection tensor: (nHorAnt x nVerAnt x verAntEigVec x horAntEigVec)
            uint16_t tensorSize = nHorAnt * nVerAnt * nEigsPerDim * nEigsPerDim;

            // compute tensor indicies for this thread:
            int horAntIdx    = THREAD_IDX % nHorAnt;
            int verAntIdx    = (THREAD_IDX / nHorAnt) % nVerAnt;
            int verAntEigIdx = (THREAD_IDX / (nHorAnt * nVerAnt)) % nEigsPerDim;
            int horAntEigIdx = (THREAD_IDX / (nHorAnt * nVerAnt * nEigsPerDim)) % nEigsPerDim;

            // check if thread in tensor:
            if(THREAD_IDX < tensorSize)
            {
                // compute correlation with horAnt eigvector:
                __half  eigVecVal     = tHorAntEigVecs({horAntIdx, horAntEigIdx});
                __half2 verAntProjVal = sh_tVertAntProjCoeffs(horAntIdx, verAntIdx, verAntEigIdx, 0);

                corrVal.x = verAntProjVal.x * eigVecVal;
                corrVal.y = verAntProjVal.y * eigVecVal;
            }

            // perform FFT across the horizantal antennas:
            warpFourierTransform<8,3>(THREAD_IDX, corrVal, d_fourier8PermuteIdx);

            // store verAnt projection coefficents in shared memory:
            if(THREAD_IDX < tensorSize)
            {
                uint8_t antIdx = verAntIdx + horAntIdx * nVerAnt;
                sh_tAntProjCoeffs(verAntEigIdx, horAntEigIdx, 0, antIdx) = corrVal;
            }
            __syncthreads();
        }

        // compute box energy:
        {
            float boxEnergy = 0;

            // coefficent energy normalized by eigenvalue:
            if(LANE_IDX < (RKHS_NUM_EIGS_PER_DIM * RKHS_NUM_EIGS_PER_DIM))
            {
                uint16_t verAntEigIdx = LANE_IDX % RKHS_NUM_EIGS_PER_DIM;
                uint16_t hotAntEigIdx = LANE_IDX / RKHS_NUM_EIGS_PER_DIM;

                __half2 projCoeff       = sh_tAntProjCoeffs(verAntEigIdx, hotAntEigIdx, 0, WARP_IDX);
                float2  projCoeff_float = __half22float2(projCoeff);
                boxEnergy               = d_rkhsEigValesAntNorm[LANE_IDX] * (projCoeff_float.x * projCoeff_float.x + projCoeff_float.y * projCoeff_float.y);
            }

            // warp reduction:
            for(int reduceStage = 16; reduceStage > 0; reduceStage /= 2)
            {
                boxEnergy += tile.shfl_down(boxEnergy, reduceStage);
            }

            // store box energy in shared memory:
            if(LANE_IDX == 0)
            {
                float totNoiseEnergy = sh_antNoiseEnergy[WARP_IDX];
                totNoiseEnergy += boxEnergy / static_cast<float>(RKHS_NOISE_REGION_LENGTH);
                sh_antNoiseEnergy[WARP_IDX] = totNoiseEnergy;
            }
            __syncthreads();
        }
    }

    // first warp computes average noise energy:
    if(WARP_IDX == 0)
    {
        float avgAntNoiseEnergy = sh_antNoiseEnergy[LANE_IDX];

        for(int reduceStage = 16; reduceStage > 0; reduceStage /= 2)
        {
            avgAntNoiseEnergy += tile.shfl_down(avgAntNoiseEnergy, reduceStage);
        }

        if(LANE_IDX == 0)
        {
            avgAntNoiseEnergy = avgAntNoiseEnergy / static_cast<float>(32);
            sh_noiseEnergy    = avgAntNoiseEnergy;
        }
    }
    __syncthreads();

    float N0 = sh_noiseEnergy;


   ////////////////////////////////////////////////////////////////
   // STEP 3: identify boxes above noise floor

    float    noiseFloor   = 6 * N0;
    uint16_t nActiveBoxes = 0;
    uint16_t nTries       = 0;
    uint16_t maxNumTries  = 20;

    while(nTries < maxNumTries)
    {
        for(int freqIntIdx = 0; freqIntIdx < nCpInts; ++freqIntIdx)
        {
            // correlate with modulated vertAnt eigenvectors:
            {
                __half2 corrVal = half2(0,0);

                // verAnt porjection tensor: (nVerAnt x nHorAnt x freqEigVec x verAntEigVec)
                uint16_t tensorSize = nVerAnt * nHorAnt * nEigsPerDim * nEigsPerDim;

                // compute tensor indicies for this thread:
                int verAntIdx    = THREAD_IDX % nVerAnt;
                int horAntIdx    = (THREAD_IDX / nVerAnt) % nHorAnt;
                int freqEigIdx   = (THREAD_IDX / (nHorAnt * nVerAnt)) % nEigsPerDim;
                int verAntEigIdx = THREAD_IDX / (nHorAnt * nVerAnt * nEigsPerDim);

                // check if thread in tensor:
                if(THREAD_IDX < tensorSize)
                {
                    // compute correlation with verAnt eigvector:
                    __half eigVecVal    = tVerAntEigVecs({verAntIdx, verAntEigIdx});
                    __half2 freqProjVal = tFreqProjCoeffs({freqIntIdx, freqEigIdx, verAntIdx, horAntIdx});

                    corrVal.x = freqProjVal.x * eigVecVal;
                    corrVal.y = freqProjVal.y * eigVecVal;
                }

                // perform FFT across the vertical antennas:
                warpFourierTransform<4,2>(THREAD_IDX, corrVal, d_fourier4PermuteIdx);

                // store verAnt projection coefficents in shared memory:
                if(THREAD_IDX < tensorSize)
                {
                    sh_tVertAntProjCoeffs(horAntIdx, verAntIdx, freqEigIdx, verAntEigIdx) = corrVal;
                }
                __syncthreads();
            }

            // correlate with modulated horAnt eigenvectors:
            {
                __half2 corrVal = half2(0,0);

                // horAnt porjection tensor: (nHorAnt x nVerAnt x freqEigVec x verAntEigVec x horAntEigVec)
                uint16_t tensorSize = nHorAnt * nVerAnt * nEigsPerDim * nEigsPerDim * nEigsPerDim;

                // compute tensor indicies for this thread:
                int horAntIdx    = THREAD_IDX % nHorAnt;
                int verAntIdx    = (THREAD_IDX / nHorAnt) % nVerAnt;
                int freqEigIdx   = (THREAD_IDX / (nHorAnt * nVerAnt)) % nEigsPerDim;
                int verAntEigIdx = (THREAD_IDX / (nHorAnt * nVerAnt * nEigsPerDim)) % nEigsPerDim;
                int horAntEigIdx = THREAD_IDX / (nHorAnt * nVerAnt * nEigsPerDim * nEigsPerDim);

                // check if thread in tensor:
                if(THREAD_IDX < tensorSize)
                {
                    // compute correlation with horAnt eigvector:
                    __half  eigVecVal     = tHorAntEigVecs({horAntIdx, horAntEigIdx});
                    __half2 verAntProjVal = sh_tVertAntProjCoeffs(horAntIdx, verAntIdx, freqEigIdx, verAntEigIdx);

                    corrVal.x = verAntProjVal.x * eigVecVal;
                    corrVal.y = verAntProjVal.y * eigVecVal;
                }

                // perform FFT across the horizantal antennas:
                warpFourierTransform<8,3>(THREAD_IDX, corrVal, d_fourier8PermuteIdx);

                // store verAnt projection coefficents in shared memory:
                if(THREAD_IDX < tensorSize)
                {
                    uint8_t antIdx = verAntIdx + horAntIdx * nVerAnt;
                    sh_tAntProjCoeffs(freqEigIdx, verAntEigIdx, horAntEigIdx, antIdx) = corrVal;
                }
                __syncthreads();
            }

            // compute box energy:
            {
                float boxEnergy = 0;

                // coefficent energy normalized by eigenvalue:
                if(EIG_FLAG == 1)
                {
                    __half2 projCoeff       = sh_tAntProjCoeffs(FREQ_EIG_IDX, VER_ANT_EIG_IDX, HOR_ANT_EIG_IDX, WARP_IDX);
                    float2  projCoeff_float = __half22float2(projCoeff);
                    boxEnergy               = d_rkhsEigValesNorm[EIG_IDX] * (projCoeff_float.x * projCoeff_float.x + projCoeff_float.y * projCoeff_float.y);
                }

                // warp reduction:
                for(int reduceStage = 16; reduceStage > 0; reduceStage /= 2)
                {
                    boxEnergy += tile.shfl_down(boxEnergy, reduceStage);
                }

                // store box energy in shared memory:
                if(LANE_IDX == 0)
                {
                    sh_boxEnergy[WARP_IDX] = boxEnergy - sh_antNoiseEnergy[WARP_IDX];
                }
                __syncthreads();
            }

            // save projection cofficents which rise above the noise floor:
            {

                // priorty which warp used to save projection coefficents:
                uint16_t firstPriorityWarp = nActiveBoxes % 32;
                uint16_t savePriority      = 0;

                if(WARP_IDX < firstPriorityWarp)
                {
                    savePriority = 32 + WARP_IDX - firstPriorityWarp;
                }else
                {
                    savePriority = WARP_IDX - firstPriorityWarp;
                }

                // check how many boxes above noise floor:
                uint16_t nBoxesAboveNoiseFloor = 0;
                for(int i = 0; i < 32; ++i)
                {
                    if(sh_boxEnergy[i] > noiseFloor)
                    {
                        if(nBoxesAboveNoiseFloor == savePriority)
                        {
                            threadFreqIntIdxs[nBoxesStoredByThisThread]   = freqIntIdx;
                            threadVerAntIntIdxs[nBoxesStoredByThisThread] = i % nVerAnt;
                            threadHorAntIntIdxs[nBoxesStoredByThisThread] = i / nVerAnt;

                            if(EIG_FLAG == 1)
                            {
                                threadProjCoeffs[nBoxesStoredByThisThread] = sh_tAntProjCoeffs(FREQ_EIG_IDX, VER_ANT_EIG_IDX, HOR_ANT_EIG_IDX, i);
                            }
                            nBoxesStoredByThisThread += 1;
                        }
                        nBoxesAboveNoiseFloor += 1;
                    }
                }
                nActiveBoxes += nBoxesAboveNoiseFloor;
                if(nActiveBoxes > (maxNumBoxes - 32))
                {
                    break;
                }
            }
        }
        __syncthreads();

        if(nActiveBoxes == 0)
        {
            noiseFloor /= 2;  // No boxes found, lower noise floor.
        }else if(nActiveBoxes >= (maxNumBoxes - 32))
        {
            noiseFloor *= 2; // Too many boxes found, raise noise floor.
            nBoxesStoredByThisThread = 0;
            nActiveBoxes = 0;
        }else
        {
            break;
        }
        nTries++;
    }

    ////////////////////////////////////////////////////
    // STEP 4: MATCHING PURSUIT

    // load correlation coefficents into shared memory:
    uint16_t corrMatrixSize = RKHS_NUM_CP_INTS * nEigsPerDim * nEigsPerDim;
    for(uint16_t corrMatrixIdx = THREAD_IDX; corrMatrixIdx < corrMatrixSize; corrMatrixIdx += 1024)
    {
        uint8_t  eigIdx0 = corrMatrixIdx % nEigsPerDim;
        uint8_t  eigIdx1 = (corrMatrixIdx / nEigsPerDim) % nEigsPerDim;
        uint16_t corrIdx = corrMatrixIdx / (nEigsPerDim * nEigsPerDim);

        sh_tFreqCorr(eigIdx0, eigIdx1, corrIdx) = tFreqEigCorr({eigIdx0, eigIdx1, corrIdx});

        if(corrIdx < nVerAnt){
            sh_tVerAntCorr(eigIdx0, eigIdx1, corrIdx) = tVerAntEigCorr({eigIdx0, eigIdx1, corrIdx});
        }

        if(corrIdx < nHorAnt){
            sh_tHorAntCorr(eigIdx0, eigIdx1, corrIdx) = tHorAntEigCorr({eigIdx0, eigIdx1, corrIdx});
        }
    }
    __syncthreads();

    float    mpExitThreshold = 3*N0;
    uint16_t nEqBoxes        = 0;

    for( int mpIdx = 0; mpIdx < maxNumEqBoxes; ++mpIdx)
    {
        // find max PSD within warp:
        float   PSD                  = 0;
        float   maxPSD_withinWarp    = 0;
        uint8_t maxBoxIdx_withinWarp = 0;

        for(int boxIdx = 0; boxIdx < nBoxesStoredByThisThread; ++boxIdx)
        {
            // coefficent PSD:
            float2  projCoeff_float = __half22float2(threadProjCoeffs[boxIdx]);
            PSD                     = d_rkhsEigValesNorm[EIG_IDX] * (projCoeff_float.x * projCoeff_float.x + projCoeff_float.y * projCoeff_float.y);

            // warp reduction:
            for(int reduceStage = 16; reduceStage > 0; reduceStage /= 2)
            {
                PSD += tile.shfl_down(PSD, reduceStage);
            }

            uint16_t antIdx = threadVerAntIntIdxs[boxIdx] + nVerAnt * threadHorAntIntIdxs[boxIdx];
            PSD -= sh_antNoiseEnergy[antIdx];

            // update max PSD:
            if(PSD > maxPSD_withinWarp)
            {
                maxPSD_withinWarp    = PSD;
                maxBoxIdx_withinWarp = boxIdx;
            }
        }

        // Broadcast max box:
        maxPSD_withinWarp    = tile.shfl(maxPSD_withinWarp, 0);
        maxBoxIdx_withinWarp = tile.shfl(maxBoxIdx_withinWarp, 0);

        // save max box energy into shared memory:
        if(LANE_IDX == 0)
        {
            sh_boxEnergy[WARP_IDX] = maxPSD_withinWarp;
        }
        __syncthreads();

        // determine max box energy in thread block:
        float   maxTbBoxEnergy      = sh_boxEnergy[LANE_IDX];
        uint8_t maxTbWarpIdx        = LANE_IDX;

        for(int reduceStage = 16; reduceStage > 0; reduceStage /= 2)
        {
            float   prop_maxTbBoxEnergy = tile.shfl_down(maxTbBoxEnergy, reduceStage);
            uint8_t prop_maxTbWarpIdx   = tile.shfl_down(maxTbWarpIdx  , reduceStage);

            if(prop_maxTbBoxEnergy > maxTbBoxEnergy)
            {
                maxTbBoxEnergy = prop_maxTbBoxEnergy;
                maxTbWarpIdx   = prop_maxTbWarpIdx;
            }
        }

        // Broadcast max box in thread block:
        maxTbBoxEnergy = tile.shfl(maxTbBoxEnergy, 0);
        maxTbWarpIdx   = tile.shfl(maxTbWarpIdx, 0);

        // check for exit:
        if((maxTbBoxEnergy < mpExitThreshold) && (mpIdx > 0))
        {
            break;
        }

        // Compute equalization coefficents for max box:
        if((maxTbWarpIdx == WARP_IDX) && (EIG_FLAG == 1))
        {

            uint16_t antIdx = threadVerAntIntIdxs[maxBoxIdx_withinWarp] + nVerAnt * threadHorAntIntIdxs[maxBoxIdx_withinWarp];
            float    antN0  = sh_antNoiseEnergy[antIdx];

            // compute mmse regularizer:
            maxPSD_withinWarp         = maxPSD_withinWarp / static_cast<float>(nMeasurments);
            float  energyNormEigValue = maxPSD_withinWarp * d_rkhsEigVales[EIG_IDX];
            float  lambda             = energyNormEigValue / (energyNormEigValue + antN0);

            // compute equalization coeff:
            float2  eqCoeff;
            float2  projCoeff_float = __half22float2(threadProjCoeffs[maxBoxIdx_withinWarp]);

            eqCoeff.x = lambda * projCoeff_float.x;
            eqCoeff.y = lambda * projCoeff_float.y;

            // save equalization coeff into shared memory:
            sh_tEqCoeffs(FREQ_EIG_IDX, VER_ANT_EIG_IDX, HOR_ANT_EIG_IDX, mpIdx) = __float22half2_rn(eqCoeff);

            // save eq box int indicies:
            if(LANE_IDX == 0)
            {
                sh_eqCoeffFreqIntIdx[mpIdx]   = threadFreqIntIdxs[maxBoxIdx_withinWarp];
                sh_eqCoeffVerAntIntIdx[mpIdx] = threadVerAntIntIdxs[maxBoxIdx_withinWarp];
                sh_eqCoeffHorAntIntIdx[mpIdx] = threadHorAntIntIdxs[maxBoxIdx_withinWarp];
            }
        }
        __syncthreads();

        // load new equalization coefficents:
        __half2  eqCoeff;
        if(EIG_FLAG == 1)
        {
            eqCoeff = sh_tEqCoeffs(FREQ_EIG_IDX, VER_ANT_EIG_IDX, HOR_ANT_EIG_IDX, mpIdx);
        }

        // update warps proj coeffs:
        for(int boxIdx = 0; boxIdx < nBoxesStoredByThisThread; ++boxIdx)
        {
            // freq contribution to deltaProj:
            __half2  deltaProj0   = half2(0,0);
            int      deltaFreqIdx = threadFreqIntIdxs[boxIdx] - sh_eqCoeffFreqIntIdx[mpIdx];
            bool     freqConjFlag = (deltaFreqIdx < 0) ? true : false;

            for(int inputFreqEigIdx = 0; inputFreqEigIdx < nEigsPerDim; ++inputFreqEigIdx)
            {
                __half2 freqCorr = sh_tFreqCorr(FREQ_EIG_IDX, inputFreqEigIdx, abs(deltaFreqIdx));
                if(freqConjFlag){
                    freqCorr.y = -freqCorr.y;
                }
                uint16_t inputBufferIdx  = nEigsPerDim * nEigsPerDim * HOR_ANT_EIG_IDX +  nEigsPerDim * VER_ANT_EIG_IDX + inputFreqEigIdx;
                __half2 inputCoeff       = tile.shfl(eqCoeff, inputBufferIdx);
                deltaProj0              += complex_mul(inputCoeff, freqCorr);
            }

            // verAnt contribution to deltaProj:
            __half2  deltaProj1    = half2(0,0);
            int     deltaVerAntIdx = threadVerAntIntIdxs[boxIdx] - sh_eqCoeffVerAntIntIdx[mpIdx];
            bool    verAntConjFlag = (deltaVerAntIdx < 0) ? true : false;

            for(int inputVerAntEigIdx = 0; inputVerAntEigIdx < nEigsPerDim; ++inputVerAntEigIdx)
            {
                __half2 verAntCorr = sh_tVerAntCorr(VER_ANT_EIG_IDX, inputVerAntEigIdx, abs(deltaVerAntIdx));
                if(verAntConjFlag){
                    verAntCorr.y = -verAntCorr.y;
                }
                uint16_t inputBufferIdx = FREQ_EIG_IDX + nEigsPerDim * inputVerAntEigIdx + nEigsPerDim * nEigsPerDim * HOR_ANT_EIG_IDX;
                __half2  inputCoeff     = tile.shfl(deltaProj0, inputBufferIdx);
                deltaProj1             += complex_mul(inputCoeff, verAntCorr);
            }

            // horAnt contribution to deltaProj:
            deltaProj0.x           = static_cast<__half>(0);
            deltaProj0.y           = static_cast<__half>(0);
            int     deltaHorAntIdx = threadHorAntIntIdxs[boxIdx] - sh_eqCoeffHorAntIntIdx[mpIdx];
            bool    horAntConjFlag = (deltaHorAntIdx < 0) ? true : false;

            for(int inputHorAntEigIdx = 0; inputHorAntEigIdx < nEigsPerDim; ++inputHorAntEigIdx)
            {
                __half2 horAntCorr = sh_tHorAntCorr(HOR_ANT_EIG_IDX, inputHorAntEigIdx, abs(deltaHorAntIdx));
                if(horAntConjFlag){
                    horAntCorr.y = -horAntCorr.y;
                }

                uint16_t inputBufferIdx = FREQ_EIG_IDX + nEigsPerDim * VER_ANT_EIG_IDX + nEigsPerDim * nEigsPerDim * inputHorAntEigIdx;
                __half2  inputCoeff     = tile.shfl(deltaProj1, inputBufferIdx);
                deltaProj0             += complex_mul(inputCoeff, horAntCorr);
            }

            // update projection coefficents:
            threadProjCoeffs[boxIdx].x -= deltaProj0.x;
            threadProjCoeffs[boxIdx].y -= deltaProj0.y;
        }
        nEqBoxes++;
        __syncthreads();
    }

    ////////////////////////////////////////////////////////
    // STEP 5: Channel Reconstruction

    float threadSigEnergy = 0.0f;
    int nSrsScPerPrbGrp   = prgSize * 3;
    int srsScOffset       = std::round(static_cast<float>(prgSize * 6 - combOffset) / 4.0);

    for(int outputIdx = THREAD_IDX; outputIdx < nOutputs; outputIdx += 1024)
    {
        // compute measurment indicies:
        uint16_t scOutIdx  = outputIdx % nOutSc;
        uint16_t scIdx     = srsScOffset + nSrsScPerPrbGrp * scOutIdx;
        uint8_t  verAntIdx = (outputIdx / nOutSc) % nVerAnt;
        uint8_t  horAntIdx = outputIdx / (nOutSc * nVerAnt);
        uint16_t gnbAntIdx = 2 * (verAntIdx + nVerAnt * horAntIdx) + polIdx;
        __half2  hEst      = half2(0,0);

        for(int boxIdx = 0; boxIdx < nEqBoxes; ++boxIdx)
        {
            // compute box phase:
            float phase  =  static_cast<float>(scIdx * sh_eqCoeffFreqIntIdx[boxIdx]) / static_cast<float>(nSrsScZp);
            phase       +=  static_cast<float>(verAntIdx * sh_eqCoeffVerAntIntIdx[boxIdx]) / static_cast<float>(nVerAnt);
            phase       +=  static_cast<float>(horAntIdx * sh_eqCoeffHorAntIntIdx[boxIdx]) / static_cast<float>(nHorAnt);
            phase       *=  -static_cast<float>(6.2831855);

            // compute box wave:
            float2 waveFloat;
            __sincosf(phase, &waveFloat.y, &waveFloat.x);
            __half2 wave = {static_cast<__half>(waveFloat.x), static_cast<__half>(waveFloat.y)};

            // apply eigenvectors:
            for(int eigIdx = 0; eigIdx < RKHS_NUM_EIGS; ++eigIdx)
            {
                // compute eigenvector indicies:
                uint8_t freqEigIdx   = eigIdx % nEigsPerDim;
                uint8_t verAntEigIdx = (eigIdx / nEigsPerDim) % nEigsPerDim;
                uint8_t horAntEigIdx = eigIdx / (nEigsPerDim * nEigsPerDim);

                // compute eigenvector:
                __half eigVecVal  =  tFreqEigVecs({scIdx, freqEigIdx});
                eigVecVal        *=  tVerAntEigVecs({verAntIdx, verAntEigIdx});
                eigVecVal        *=  tHorAntEigVecs({horAntIdx, horAntEigIdx});

                // add box contribution to channel estimate:
                __half2 value  = complex_mul(wave, sh_tEqCoeffs(freqEigIdx, verAntEigIdx, horAntEigIdx, boxIdx));
                hEst.x        += eigVecVal * value.x;
                hEst.y        += eigVecVal * value.y;
            }
        }
        threadSigEnergy += static_cast<float>(hEst.x * hEst.x + hEst.y * hEst.y);

        // save estimate to output buffer:
        uint8_t ueAntIdx = portToUeAntMap[portIdx];
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
        tChEstBuff({scOutIdx, gnbAntIdx, ueAntIdx}) = __half22float2(hEst);
#else
        tChEstBuff({scOutIdx, gnbAntIdx, ueAntIdx}) = hEst;
#endif
    }
    __syncthreads();

    // warp reduction of signal energy:
    float warpSigEnergy = threadSigEnergy;
    for(int reduceStage = 16; reduceStage > 0; reduceStage /= 2)
    {
        warpSigEnergy += tile.shfl_down(warpSigEnergy, reduceStage);
    }

    // store box energy in shared memory:
    if(LANE_IDX == 0)
    {
        atomicAdd(&sh_sigEnergy, warpSigEnergy);
    }
    __syncthreads();

    __shared__ uint32_t sh_ueBlockCntr;
    if(THREAD_IDX == 0)
    {
        float avgSigEnergy = sh_sigEnergy / static_cast<float>(nOutputs);
        atomicAdd((float*)(&ueDescr.tmpWidebandNoiseEnergy)  , N0);
        atomicAdd((float*)(&ueDescr.tmpWidebandSignalEnergy) , avgSigEnergy);
       __threadfence();

       // for finalization step
       sh_ueBlockCntr = atomicAdd(&ueDescr.ueBlockCntr, 1) + 1;
    }
    __syncthreads();

    if(THREAD_IDX == 0)
    {
        cuphySrsReport_t*&   pUeSrsReport         = ueDescr.pUeSrsReport;
        float&               widebandSnr          = pUeSrsReport->widebandSnr;
        float&               widebandNoiseEnergy  = pUeSrsReport->widebandNoiseEnergy;
        float&               widebandSignalEnergy = pUeSrsReport->widebandSignalEnergy;

        if(sh_ueBlockCntr == ueDescr.ueNumBlocks)
        {
            widebandSnr          = 10.f * log10f(ueDescr.tmpWidebandSignalEnergy / ueDescr.tmpWidebandNoiseEnergy);
            widebandSignalEnergy = ueDescr.tmpWidebandSignalEnergy / static_cast<float>(ueDescr.ueNumBlocks);
            widebandNoiseEnergy  = ueDescr.tmpWidebandNoiseEnergy / static_cast<float>(ueDescr.ueNumBlocks);
        }
    }
}

//FIXME the following launch bound needs to take dynamic shared memory into account
#if __CUDA_ARCH__ >= 900
__launch_bounds__(SRS_CHEST_BLOCK_SZ, (9*128)/SRS_CHEST_BLOCK_SZ)
#elif __CUDA_ARCH__ >= 800
__launch_bounds__(SRS_CHEST_BLOCK_SZ, (7*128)/SRS_CHEST_BLOCK_SZ)
#endif
__global__ void srsChEstKernel(srsChEstStatDescr_t* pStatDescr, srsChEstDynDescr_t* pDynDescr)
{
   const uint32_t    compBlockIdx      = blockIdx.x;
   compBlockDescr_t& compBlockDescr    = pDynDescr->compBlockDescrs[compBlockIdx];
   uint16_t          ueGroupIdx        = compBlockDescr.ueGroupIdx;
   ueGroupDescr_t&   ueGroupDescr      = pDynDescr->ueGroupDescrs[ueGroupIdx];
   uint16_t          firstUeInBlockIdx = ueGroupDescr.ueIdxs[0];
   uint8_t           combSize          = pDynDescr->ueDescrs[firstUeInBlockIdx].combSize;
   uint8_t           nAntPorts         = ueGroupDescr.nAntPorts;

   if (combSize == 2) {
      if (nAntPorts == 1) {
         srsChEstKernelInner<2,1>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 2) {
         srsChEstKernelInner<2,2>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 3) {
         srsChEstKernelInner<2,3>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 4) {
         srsChEstKernelInner<2,4>(pStatDescr, pDynDescr);
       } else if (nAntPorts == 5) {
         srsChEstKernelInner<2,5>(pStatDescr, pDynDescr);
       } else if (nAntPorts == 6) {
         srsChEstKernelInner<2,6>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 7) {
         srsChEstKernelInner<2,7>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 8) {
         srsChEstKernelInner<2,8>(pStatDescr, pDynDescr);
      }else {
         return;
      }
   } else { // combSize == 4
      if (nAntPorts == 1) {
         srsChEstKernelInner<4,1>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 2) {
         srsChEstKernelInner<4,2>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 3) {
         srsChEstKernelInner<4,3>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 4) {
         srsChEstKernelInner<4,4>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 5) {
         srsChEstKernelInner<4,5>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 6) {
         srsChEstKernelInner<4,6>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 7) {
         srsChEstKernelInner<4,7>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 8) {
         srsChEstKernelInner<4,8>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 9) {
         srsChEstKernelInner<4,9>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 10) {
         srsChEstKernelInner<4,10>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 11) {
         srsChEstKernelInner<4,11>(pStatDescr, pDynDescr);
      } else if (nAntPorts == 12) {
         srsChEstKernelInner<4,12>(pStatDescr, pDynDescr);
      } else {
         return;
      }
   }
}


srsChEst::srsChEst()
{}



void srsChEst::getDescrInfo(size_t& statDescrSizeBytes, size_t& statDescrAlignBytes, size_t& dynDescrSizeBytes, size_t& dynDescrAlignBytes)
{
   statDescrSizeBytes  = sizeof(srsChEstStatDescr_t);
   statDescrAlignBytes = alignof(srsChEstStatDescr_t);

   dynDescrSizeBytes  = sizeof(srsChEstDynDescr_t);
   dynDescrAlignBytes = alignof(srsChEstDynDescr_t);
}

void  srsChEst::kernelSelect(srsChEstDynDescr_t*      pCpuDynDesc,
                            uint16_t                  nSrsUes,
                            uint16_t                  nCompBlocks,
                            uint16_t                  nRkhsCompBlocks,
                            cuphySrsChEstLaunchCfg_t* pLaunchCfg,
                            cuphySrsChEstNormalizationLaunchCfg_t* pNormalizationLaunchCfg)
{
    if(m_chEstAlgo == SRS_CH_EST_ALGO_TYPE_MMSE)
    {
        // thread block geometry:
        uint16_t max_nRxAnts      = 0;
        uint8_t  max_nPorts       = 0;
        uint8_t  min_nCombs       = 4;
        int      max_loop_iters   = 0;
        uint8_t  max_n_SRS_cs_max = 0; // max number of cyclic shifts, no more than 12
        int      max_nSrsScBlock  = 0;

        for(int compBlockIdx = 0; compBlockIdx < nCompBlocks; ++compBlockIdx)
        {
            uint16_t  nRxAntSrs       = pCpuDynDesc->compBlockDescrs[compBlockIdx].nRxAntSrs;
            uint16_t  ueGroupIdx      = pCpuDynDesc->compBlockDescrs[compBlockIdx].ueGroupIdx;
            uint8_t   nAntPorts       = pCpuDynDesc->ueGroupDescrs[ueGroupIdx].nAntPorts;
            uint16_t  firstUeInGrpIdx = pCpuDynDesc->ueGroupDescrs[ueGroupIdx].ueIdxs[0];
            uint8_t   combSize        = pCpuDynDesc->ueDescrs[firstUeInGrpIdx].combSize;
            uint8_t   n_SRS_cs_max    = pCpuDynDesc->ueDescrs[firstUeInGrpIdx].n_SRS_cs_max;

            const int nSrsScBlock = combSize == 4 ? 12 : 24;
            int       loop_iters  = static_cast<int>(nRxAntSrs) * nSrsScBlock * nAntPorts;

            max_nRxAnts      = (nRxAntSrs > max_nRxAnts)         ? nRxAntSrs     : max_nRxAnts;
            max_nPorts       = (nAntPorts > max_nPorts)          ? nAntPorts     : max_nPorts;
            min_nCombs       = (combSize < min_nCombs)           ? combSize      : min_nCombs;
            max_loop_iters   = (loop_iters > max_loop_iters)     ? loop_iters    : max_loop_iters;
            max_n_SRS_cs_max = (n_SRS_cs_max > max_n_SRS_cs_max) ? n_SRS_cs_max  : max_n_SRS_cs_max;
            max_nSrsScBlock  = (nSrsScBlock > max_nSrsScBlock)   ? nSrsScBlock   : max_nSrsScBlock;
        }
        uint16_t max_nSrsSc = min_nCombs == 4 ? 12 : 24;

        // launch geometry (can change!)
        dim3      grdDim(nCompBlocks);
        const int MAX_THREADS_PER_BLOCK = SRS_CHEST_BLOCK_SZ;
        const int nthreads = (max_loop_iters < MAX_THREADS_PER_BLOCK) ? MAX_THREADS_PER_BLOCK/2 : MAX_THREADS_PER_BLOCK;
        dim3      blkDim(nthreads,1);

        // kernel (only one kernel option for now)
        void* kernelFunc = reinterpret_cast<void*>(srsChEstKernel);
       {MemtraceDisableScope md;cudaGetFuncBySymbol(&pLaunchCfg->kernelNodeParamsDriver.func, kernelFunc);}

        // populate kernel parameters
        CUDA_KERNEL_NODE_PARAMS& kernelNodeParamsDriver = pLaunchCfg->kernelNodeParamsDriver;

        kernelNodeParamsDriver.blockDimX = blkDim.x;
        kernelNodeParamsDriver.blockDimY = blkDim.y;
        kernelNodeParamsDriver.blockDimZ = blkDim.z;

        kernelNodeParamsDriver.gridDimX = grdDim.x;
        kernelNodeParamsDriver.gridDimY = grdDim.y;
        kernelNodeParamsDriver.gridDimZ = grdDim.z;

        kernelNodeParamsDriver.extra = nullptr;

        kernelNodeParamsDriver.sharedMemBytes = max_nRxAnts * max_nSrsSc * sizeof(__half2);                              // for sh_rxSrs
        kernelNodeParamsDriver.sharedMemBytes += max_nRxAnts * max_nSrsSc * max_nPorts * sizeof(__half2);                // for sh_Hest
        kernelNodeParamsDriver.sharedMemBytes += 2 * max_nSrsSc * max_nSrsSc * sizeof(__half2);                          // for sh_W_{wide,narrow}
        kernelNodeParamsDriver.sharedMemBytes += max_nPorts * sizeof(float) +                                            // sh_phaseRamp
                                                 max_nPorts * sizeof(__half2) +                                          // sh_avgScCorr
                                                 (13 * 12 /*(max_FOCC_LENGTH+1)*max_FOCC_LENGTH*/) * sizeof(__half2) +   // sh_focc_table
                                                 (max_nPorts * N_PRB_PER_COMP_BLK) * sizeof(float) +                     // sh_avgSignalEnergyPrb
                                                 (max_nPorts * max_nSrsSc) * sizeof(float) +                             // sh_avgSignalEnergySc
                                                 max_nPorts * sizeof(float) +                                            // sh_avgSignalEnergy
                                                 max_nPorts * sizeof(uint32_t) +                                         // sh_ueBlockCntr
                                                 max_nPorts * (SRS_CHEST_BLOCK_SZ / 32/*TILE_SIZE*/) * sizeof(__half2) + // sh_tile_avgScCorr
                                                 (max_nSrsScBlock + 1) * 12 * sizeof(__half2); // sh_phaseTable- used for sin/cos LUT in srsFilterMultiply and step 7;
                                                                                               // the LUT size in srsFilterMultiply is larger or equal to LUT in step 7;
                                                                                               // +1 is extra padding to reduce bank-conflicts
    }
    else
    {
        // launch geometry
        dim3      grdDim(nRkhsCompBlocks);
        const int THREADS_PER_BLOCK = 1024;
        dim3      blkDim(THREADS_PER_BLOCK);

        // kernel
        void* kernelFunc = reinterpret_cast<void*>(srsRkhsChEstKernel);
       {MemtraceDisableScope md;cudaGetFuncBySymbol(&pLaunchCfg->kernelNodeParamsDriver.func, kernelFunc);}

        // populate kernel parameters
        CUDA_KERNEL_NODE_PARAMS& kernelNodeParamsDriver = pLaunchCfg->kernelNodeParamsDriver;

        kernelNodeParamsDriver.blockDimX = blkDim.x;
        kernelNodeParamsDriver.blockDimY = blkDim.y;
        kernelNodeParamsDriver.blockDimZ = blkDim.z;

        kernelNodeParamsDriver.gridDimX = grdDim.x;
        kernelNodeParamsDriver.gridDimY = grdDim.y;
        kernelNodeParamsDriver.gridDimZ = grdDim.z;

        kernelNodeParamsDriver.extra          = nullptr;
        kernelNodeParamsDriver.sharedMemBytes = 0;
    }
    
    if(m_chEstToL2NormalizationAlgo==1)
    {
        // launch geometry for srsChEstNormalizationKernel kernel
        dim3  grdDim(nSrsUes);
        dim3  blkDim(128);
        void* kernelFunc = reinterpret_cast<void*>(srsChEstNormalizationKernel);
       {MemtraceDisableScope md;cudaGetFuncBySymbol(&pNormalizationLaunchCfg->kernelNodeParamsDriver.func, kernelFunc);}
        CUDA_KERNEL_NODE_PARAMS& kernelNodeParamsDriver = pNormalizationLaunchCfg->kernelNodeParamsDriver;
        kernelNodeParamsDriver.blockDimX = blkDim.x;
        kernelNodeParamsDriver.blockDimY = blkDim.y;
        kernelNodeParamsDriver.blockDimZ = blkDim.z;
        kernelNodeParamsDriver.gridDimX = grdDim.x;
        kernelNodeParamsDriver.gridDimY = grdDim.y;
        kernelNodeParamsDriver.gridDimZ = grdDim.z;
        kernelNodeParamsDriver.extra = nullptr;
        kernelNodeParamsDriver.sharedMemBytes = 0;
    }
}

cuphyStatus_t srsChEst::setup(uint16_t                      nSrsUes,
                              cuphyUeSrsPrm_t*              h_srsUePrms,
                              uint16_t                      nCells,
                              cuphyTensorPrm_t*             pTDataRx,
                              cuphySrsCellPrms_t*           h_srsCellPrms,
                              float*                        d_rbSnrBuff,
                              uint32_t*                     h_rbSnrBuffOffsets,
                              cuphySrsReport_t*             d_pSrsReports,
                              cuphySrsChEstBuffInfo_t*      h_chEstBuffInfo,
                              void**                        d_addrsChEstToL2Buff,
                              cuphySrsChEstToL2_t*          h_chEstToL2,
                              void*                         d_workspace,
                              bool                          enableCpuToGpuDescrAsyncCpy,
                              srsChEstDynDescr_t*           pCpuDynDesc,
                              void*                         pGpuDynDesc,
                              cuphySrsChEstLaunchCfg_t*     pLaunchCfg,
                              cuphySrsChEstNormalizationLaunchCfg_t*     pNormalizationLaunchCfg,
                              cudaStream_t                  strm)
{
   if((nCells > MAX_N_SRS_CELL) || (nSrsUes > CUPHY_SRS_MAX_N_USERS)) return CUPHY_STATUS_INVALID_ARGUMENT;
   uint16_t           nCompBlocks          = 0;
   uint16_t           nUeGroups            = 0;
   uint16_t           nRkhsCompBlocks      = 0;
   constexpr uint16_t nPrbsPerComputeBlock = 4;

   pCpuDynDesc->nSrsUes                    = nSrsUes;

   __half2* d_workspace_half2 = static_cast<__half2*>(d_workspace);

   for(int ueIdx = 0; ueIdx < nSrsUes; ++ueIdx)
   {
       ueDescr_t&            ueDescr  = pCpuDynDesc->ueDescrs[ueIdx];
       cuphyUeSrsPrm_t&      ueSrsPrm = h_srsUePrms[ueIdx];
       cuphySrsCellPrms_t&   cellPrm  = h_srsCellPrms[ueSrsPrm.cellIdx];

       // ue descriptor parmaters to be populated:
       uint8_t  (&repSymIdxs)[MAX_N_HOPS][MAX_N_REPS]                  = ueDescr.repSymIdxs;
       uint16_t (&hopStartPrbs)[MAX_N_HOPS]                            = ueDescr.hopStartPrbs;
       uint8_t  (&nRepPerHop)[MAX_N_HOPS]                              = ueDescr.nRepPerHop;
       uint16_t& nPrbsPerHop                                           = ueDescr.nPrbsPerHop;
       uint8_t  (&u)[MAX_N_SYM]                                        = ueDescr.u;
       float    (&q)[MAX_N_SYM]                                        = ueDescr.q;
       float&    alphaCommon                                           = ueDescr.alphaCommon;
       uint8_t&  n_SRS_cs_max                                          = ueDescr.n_SRS_cs_max;
       uint8_t&  lowPaprTableIdx                                       = ueDescr.lowPaprTableIdx;
       uint16_t& lowPaprPrime                                          = ueDescr.lowPaprPrime;
       uint8_t&  nPorts                                                = ueDescr.nPorts;
       uint8_t&  nPortsPerComb                                         = ueDescr.nPortsPerComb;
       uint8_t  (&portToFoccMap)[MAX_N_COMB_PER_UE][MAX_N_ANT_PORTS]   = ueDescr.portToFoccMap;
       uint8_t&  combSize                                              = ueDescr.combSize;
       uint8_t  (&combOffsets)[MAX_N_COMB_PER_UE]                      = ueDescr.combOffsets;
       uint8_t&  nCombScPerPrb                                         = ueDescr.nCombScPerPrb;
       uint8_t  (&portToUeAntMap)[MAX_N_COMB_PER_UE][MAX_N_ANT_PORTS]  = ueDescr.portToUeAntMap;
       uint8_t  (&portToL2OutUeAntMap)[MAX_N_COMB_PER_UE][MAX_N_ANT_PORTS]  = ueDescr.portToL2OutUeAntMap;
       float*&                      pUeRbSnr                           = ueDescr.pUeRbSnr;
       uint8_t&                     cellIdx                            = ueDescr.cellIdx;
       uint8_t&                     prgSize                            = ueDescr.prgSize;
       cuphySrsReport_t*&           pUeSrsReport                       = ueDescr.pUeSrsReport;
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
       tensor_ref_any<CUPHY_C_32F>& tChEstBuff                         = ueDescr.tChEstBuff;
       tensor_ref_any<CUPHY_C_32F>& tChEstToL2                         = ueDescr.tChEstToL2;
#else
       tensor_ref_any<CUPHY_C_16F>& tChEstBuff                         = ueDescr.tChEstBuff;
       tensor_ref_any<CUPHY_C_16I>& tChEstToL2                         = ueDescr.tChEstToL2;
#endif
       uint16_t&                    chEstBuffStartPrbGrp               = ueDescr.chEstBuffStartPrbGrp;
       uint32_t&                    ueBlockCntr                        = ueDescr.ueBlockCntr;
       uint32_t&                    ueNumBlocks                        = ueDescr.ueNumBlocks;

       ueNumBlocks = 0;
       ueBlockCntr = 0;

       ueDescr.tmpWidebandNoiseEnergy  = 0.0f;
       ueDescr.tmpWidebandSignalEnergy = 0.0f;
       ueDescr.tmpWidebandScCorr       = __floats2half2_rn(0.f, 0.f);
       ueDescr.tmpWidebandCsCorrUse    = 0;
       ueDescr.tmpWidebandCsCorrNotUse = 0;

       // some parameters can be directly copied:
       cellIdx  = ueSrsPrm.cellIdx;
       combSize = ueSrsPrm.combSize;
       prgSize  = ueSrsPrm.prgSize;

       // comb parameters:
       nCombScPerPrb   = (ueSrsPrm.combSize == 2) ? 6 : 3;
       n_SRS_cs_max    = (ueSrsPrm.combSize == 2) ? 8 : 12;

       // hop prb size:
       nPrbsPerHop         = SRS_BW_TABLE[ueSrsPrm.configIdx][2*ueSrsPrm.bandwidthIdx];
       uint16_t M_sc_b_SRS = nPrbsPerHop * nCombScPerPrb;

       // compute SRS sequence group u and sequence number v:
       uint8_t  v[MAX_N_SYM];
       for(int symIdx = 0; symIdx < ueSrsPrm.nSyms; ++symIdx)
       {
           v[symIdx] = 0;
           u[symIdx] = ueSrsPrm.sequenceId % 30;
       }
       if(ueSrsPrm.groupOrSequenceHopping == 1)
       {
           uint32_t c  = seqCpuSrs::gold32n_CPU(ueSrsPrm.sequenceId, 8 * (cellPrm.slotNum * N_SYM_PER_SLOT + ueSrsPrm.startSym));
           for(int symIdx = 0; symIdx < ueSrsPrm.nSyms; ++symIdx)
           {
               uint8_t f_gh = ((c >> 8*symIdx) & LOWER_BYTE_BMSK) % 30;
               u[symIdx]    = (f_gh + ueSrsPrm.sequenceId) % 30;
           }
       }
       if((ueSrsPrm.groupOrSequenceHopping == 2) && (M_sc_b_SRS >= (N_SC_PER_PRB * 6)))
       {
           uint32_t c = seqCpuSrs::gold32n_CPU(ueSrsPrm.sequenceId, cellPrm.slotNum * N_SYM_PER_SLOT + ueSrsPrm.startSym);
           for(int symIdx = 0; symIdx < ueSrsPrm.nSyms; ++symIdx)
           {
               v[symIdx] = static_cast<uint8_t>((c >> symIdx) & 1);
           }
       }

       // determine if user gets multiple combs:
       uint8_t nCombs = 1;
       nPortsPerComb  = ueSrsPrm.nAntPorts;
       if ((ueSrsPrm.cyclicShift >= n_SRS_cs_max / 2) && (ueSrsPrm.nAntPorts == 4))
       {
           nCombs        = 2;
           nPortsPerComb = 2;
       }
       nPorts = nCombs * nPortsPerComb;

       // cyclic shifts:
       alphaCommon = 0;
       for(int combIdx = 0; combIdx < nCombs; ++combIdx)
       {
           for(int portIdx = 0; portIdx < nPortsPerComb; ++portIdx)
           {
               portToFoccMap[combIdx][portIdx] = (ueSrsPrm.cyclicShift + portIdx * n_SRS_cs_max / nPortsPerComb + combIdx * n_SRS_cs_max / 4) % n_SRS_cs_max;
           }
       }

       // port to antenna port
       for(int combIdx = 0; combIdx < nCombs; ++combIdx)
       {
           for(int portIdx = 0; portIdx < nPortsPerComb; ++portIdx)
           {
               portToUeAntMap[combIdx][portIdx] = ueSrsPrm.srsAntPortToUeAntMap[portIdx*nCombs + combIdx];
               portToL2OutUeAntMap[combIdx][portIdx] = portIdx*nCombs + combIdx;
           }
       }


       // comb offsets:
       for(int combIdx = 0; combIdx < nCombs; ++combIdx)
       {
           combOffsets[combIdx] = (ueSrsPrm.combOffset + combIdx * combSize / 2) % combSize;
       }

       // hop starting Prbs
       uint16_t hopStartPrbs0[MAX_N_SYM];
       uint8_t  nHops0         = ueSrsPrm.nSyms / ueSrsPrm.nRepetitions;
       uint16_t nSlotsPerFrame = 10 * (1 << cellPrm.mu);
       uint16_t m_SRS_b;

       for(int hopIdx = 0; hopIdx < nHops0; hopIdx++)
       {
           hopStartPrbs0[hopIdx] = ueSrsPrm.frequencyShift;
           uint16_t Nb, nb;
           for(int b = 0; b <= ueSrsPrm.bandwidthIdx; ++b)
           {
               Nb      = SRS_BW_TABLE[ueSrsPrm.configIdx][2*b + 1];
               m_SRS_b = SRS_BW_TABLE[ueSrsPrm.configIdx][2*b];
               nb      = ((4 * ueSrsPrm.frequencyPosition) / m_SRS_b) % Nb;

               if((b > ueSrsPrm.frequencyHopping) && (ueSrsPrm.frequencyHopping < ueSrsPrm.bandwidthIdx))
               {
                   uint16_t n_SRS;
                   if(ueSrsPrm.resourceType == 0)
                   {
                       n_SRS = hopIdx;
                   }else
                   {
                       uint16_t slotIdx = nSlotsPerFrame * cellPrm.frameNum + cellPrm.slotNum - ueSrsPrm.Toffset;
                       if((slotIdx % ueSrsPrm.Tsrs) == 0)
                       {
                           n_SRS = (slotIdx / ueSrsPrm.Tsrs) * (ueSrsPrm.nSyms / ueSrsPrm.nRepetitions) + hopIdx;
                       }

                   }

                   uint16_t PI_bm1 = 1;
                   for(int b_prime = ueSrsPrm.frequencyHopping + 1; b_prime < b; ++b_prime)
                   {
                       PI_bm1 = PI_bm1 * SRS_BW_TABLE[ueSrsPrm.configIdx][2*b_prime + 1];
                   }
                   uint16_t PI_b = PI_bm1 * Nb;
                   uint16_t Fb;
                   if((Nb % 2) == 0)
                   {
                       Fb = (Nb / 2) * ((n_SRS % PI_b) / PI_bm1) + (n_SRS % PI_b) / (2 * PI_bm1);
                   }else
                   {
                       Fb = (Nb / 2) * (n_SRS / PI_bm1);
                   }
                   nb = (Fb + 4 * ueSrsPrm.frequencyPosition / m_SRS_b) % Nb;
               }
               hopStartPrbs0[hopIdx] += m_SRS_b * nb;
           }
       }

       // low PAPR sequence parameters:
       uint16_t nSubcarriers = m_SRS_b * nCombScPerPrb;
       lowPaprTableIdx = 255;
       lowPaprPrime    = 0;

       if(nSubcarriers == 12)
       {
           lowPaprTableIdx = 0;
       }else
       {
           if(nSubcarriers == 24)
           {
               lowPaprTableIdx = 1;
           }else
           {
               for(int primeIdx = 1; primeIdx < N_PRIMES; ++primeIdx)
               {
                   if(PRIMES_TABLE[primeIdx] > nSubcarriers)
                   {
                       lowPaprPrime = PRIMES_TABLE[primeIdx - 1];
                       break;
                   }
               }
           }
       }

       for(int symIdx = 0; symIdx < ueSrsPrm.nSyms; ++symIdx)
       {
           float qBar = static_cast<float>(lowPaprPrime) * static_cast<float>(u[symIdx] + 1) / static_cast<float>(31);
           if((static_cast<uint32_t>(floor(2*qBar)) % 2) == 0)
           {
               q[symIdx] = floor(qBar + 0.5) + v[symIdx];
           }else
           {
               q[symIdx] = floor(qBar + 0.5) - v[symIdx];
           }
       }

       // combine hops with the same start PRB
       uint8_t nHops   = 1;
       nRepPerHop[0]   = ueSrsPrm.nRepetitions;
       hopStartPrbs[0] = hopStartPrbs0[0];
       for(int repIdx = 0; repIdx < ueSrsPrm.nRepetitions; ++repIdx)
       {
           repSymIdxs[0][repIdx] = ueSrsPrm.startSym - cellPrm.srsStartSym + repIdx;
       }

       for(int hopIdx0 = 1; hopIdx0 < nHops0; hopIdx0++)
       {
           bool newHopFlag = true;
           for(int hopIdx = 0; hopIdx < nHops; ++hopIdx)
           {
               if(hopStartPrbs0[hopIdx0] == hopStartPrbs[hopIdx])
               {
                   for(int repIdx = 0; repIdx < ueSrsPrm.nRepetitions; ++repIdx)
                   {
                       repSymIdxs[hopIdx][nRepPerHop[hopIdx] + repIdx] = ueSrsPrm.startSym - cellPrm.srsStartSym + hopIdx0 * ueSrsPrm.nRepetitions + repIdx;
                   }
                   nRepPerHop[hopIdx] += ueSrsPrm.nRepetitions;
                   newHopFlag          = false;
                   break;
               }
           }

           if(newHopFlag)
           {
               for(int repIdx = 0; repIdx <  ueSrsPrm.nRepetitions; ++repIdx)
               {
                   repSymIdxs[nHops][repIdx] = ueSrsPrm.startSym - cellPrm.srsStartSym + hopIdx0 * ueSrsPrm.nRepetitions + repIdx;
               }
               nRepPerHop[nHops]   = ueSrsPrm.nRepetitions;
               hopStartPrbs[nHops] = hopStartPrbs0[nHops];
               nHops += 1;
           }
       }

       // ues output parameters:
       uint16_t chEstBuffIdx                    = ueSrsPrm.chEstBuffIdx;
       cuphySrsChEstBuffInfo_t& ueChEstBuffInfo = h_chEstBuffInfo[chEstBuffIdx];

       tensor_pair tPairUeChEstBuffer (static_cast<const tensor_desc&>(*(ueChEstBuffInfo.tChEstBuffer.desc)), ueChEstBuffInfo.tChEstBuffer.pAddr);
       const tensor_layout_any& tUeChEstBufferLayout = tPairUeChEstBuffer.first.get().layout();
       void*                    tUeChEstBufferAddr   = tPairUeChEstBuffer.second;
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
       tChEstBuff = std::move(tensor_ref_any<CUPHY_C_32F>(tUeChEstBufferAddr, tUeChEstBufferLayout.dimensions.begin(), tUeChEstBufferLayout.strides.begin()));
#else
       tChEstBuff = std::move(tensor_ref_any<CUPHY_C_16F>(tUeChEstBufferAddr, tUeChEstBufferLayout.dimensions.begin(), tUeChEstBufferLayout.strides.begin()));
#endif

       chEstBuffStartPrbGrp = ueChEstBuffInfo.startPrbGrp;
       pUeSrsReport         = d_pSrsReports + ueIdx;
       pUeRbSnr             = d_rbSnrBuff + h_rbSnrBuffOffsets[ueIdx];

       h_chEstToL2[ueIdx].prbGrpSize = ueSrsPrm.prgSize; // populate prgSize from API
       h_chEstToL2[ueIdx].nPrbGrps   = nHops * nPrbsPerHop / h_chEstToL2[ueIdx].prbGrpSize;
       uint16_t& nPrbGrps   = h_chEstToL2[ueIdx].nPrbGrps;
         
//         ueChEstBuffInfo.startValidPrg = static_cast<uint16_t>(floor(hopStartPrbs[0] / h_chEstToL2[ueIdx].prbGrpSize));
//         ueChEstBuffInfo.nValidPrg     = h_chEstToL2[ueIdx].nPrbGrps;

        if(m_chEstToL2NormalizationAlgo==1)
        {
            ueDescr.nPrbGrpsL2 = h_chEstToL2[ueIdx].nPrbGrps;
            ueDescr.nRxAntSrsL2 = cellPrm.nRxAntSrs;
            ueDescr.nAntPortsL2 = ueSrsPrm.nAntPorts;
            //TODO for the further optimization
            uint16_t (&prgIdxMappingL2)[CUPHY_SRS_MAX_N_PRGS_SUPPORTED] = ueDescr.prgIdxMappingL2;
            for(int mappingIdx = 0; mappingIdx < CUPHY_SRS_MAX_N_PRGS_SUPPORTED; mappingIdx++)
            {
                prgIdxMappingL2[mappingIdx] = 0;
            }
            uint8_t (&portIdxMappingL2)[MAX_N_ANT_PORTS] = ueDescr.portIdxMappingL2;
            for(int mappingIdx = 0; mappingIdx < MAX_N_ANT_PORTS; mappingIdx++)
            {
                portIdxMappingL2[mappingIdx] = 0;
            }
        }

         std::array<int, CUPHY_DIM_MAX> srsChEstToL2Dim;
         srsChEstToL2Dim.fill(1);
         srsChEstToL2Dim[0] = nPrbGrps;
         srsChEstToL2Dim[1] = cellPrm.nRxAntSrs;
         srsChEstToL2Dim[2] = ueSrsPrm.nAntPorts;

         std::array<int, CUPHY_DIM_MAX> srsChEstToL2Str;
         srsChEstToL2Str.fill(nPrbGrps * cellPrm.nRxAntSrs * ueSrsPrm.nAntPorts);
         srsChEstToL2Str[0] = 1;
         srsChEstToL2Str[1] = nPrbGrps;
         srsChEstToL2Str[2] = nPrbGrps * cellPrm.nRxAntSrs;
#ifdef ASIM_CUPHY_SRS_OUTPUT_FP32
         tChEstToL2 = std::move(tensor_ref_any<CUPHY_C_32F>(d_addrsChEstToL2Buff[ueIdx], srsChEstToL2Dim.begin(), srsChEstToL2Str.begin()));
#else
         tChEstToL2 = std::move(tensor_ref_any<CUPHY_C_16I>(d_addrsChEstToL2Buff[ueIdx], srsChEstToL2Dim.begin(), srsChEstToL2Str.begin()));
#endif

       // allocate compute blocks for the user:
       if(m_chEstAlgo == SRS_CH_EST_ALGO_TYPE_MMSE)
       {
            for(int hopIdx = 0; hopIdx < nHops; ++hopIdx)
            {
                for(int combIdx = 0; combIdx < nCombs; ++combIdx)
                {
                    // check if user belongs to an existing compute block:
                    bool newUeGroupFlag = true;

                    for(int ueGroupIdx = 0; ueGroupIdx < nUeGroups; ++ueGroupIdx)
                    {
                        ueGroupDescr_t& propUeGroupBlockDesc = pCpuDynDesc->ueGroupDescrs[ueGroupIdx];

                        uint16_t   firstUeInBlockIdx     = propUeGroupBlockDesc.ueIdxs[0];
                        uint8_t    firstUeInBlockHopIdx  = propUeGroupBlockDesc.ueHopIdxs[0];
                        uint8_t    firstUeInBlockCombIdx = propUeGroupBlockDesc.ueCombIdxs[0];
                        ueDescr_t& firstUeInBlockDescr   = pCpuDynDesc->ueDescrs[firstUeInBlockIdx];

                        bool cellIdx_check         = (cellIdx              == firstUeInBlockDescr.cellIdx);
                        bool nPrbsPerHop_check     = (nPrbsPerHop          == firstUeInBlockDescr.nPrbsPerHop);
                        bool ueStartSrsSym_check   = (repSymIdxs[0][0]     == firstUeInBlockDescr.repSymIdxs[0][0]);
                        bool hopStartPrb_check     = (hopStartPrbs[hopIdx] == firstUeInBlockDescr.hopStartPrbs[firstUeInBlockHopIdx]);
                        bool nRepPerHop_check      = (nRepPerHop[hopIdx]   == firstUeInBlockDescr.nRepPerHop[firstUeInBlockHopIdx]);
                        bool alphaCommon_check     = (alphaCommon          == firstUeInBlockDescr.alphaCommon);
                        bool n_SRS_cs_max_check    = (n_SRS_cs_max         == firstUeInBlockDescr.n_SRS_cs_max);
                        bool lowPaprTableIdx_check = (lowPaprTableIdx      == firstUeInBlockDescr.lowPaprTableIdx);
                        bool lowPaprPrime_check    = (lowPaprPrime         == firstUeInBlockDescr.lowPaprPrime);
                        bool combSize_check        = (combSize             == firstUeInBlockDescr.combSize);
                        bool combOffset_check      = (combOffsets[combIdx] == firstUeInBlockDescr.combOffsets[firstUeInBlockCombIdx]);
                        bool prgSize_check         = (prgSize              == firstUeInBlockDescr.prgSize);

                        bool u_check = true;
                        for(int i = 0; i < 4; ++i)
                        {
                            if(u[i] != firstUeInBlockDescr.u[i])
                            {
                                u_check = false;
                                break;
                            }
                        }

                        bool q_check = true;
                        for(int i = 0; i < 4; ++i)
                        {
                            if(q[i] != firstUeInBlockDescr.q[i])
                            {
                                u_check = false;
                                break;
                            }
                        }

                        if(cellIdx_check && nPrbsPerHop_check && ueStartSrsSym_check && hopStartPrb_check && nRepPerHop_check && u_check && q_check && alphaCommon_check && n_SRS_cs_max_check && lowPaprTableIdx_check && lowPaprPrime_check && combSize_check && combOffset_check && prgSize_check)
                        {
                            newUeGroupFlag = false;

                            propUeGroupBlockDesc.ueIdxs[propUeGroupBlockDesc.nUes]      = ueIdx;
                            propUeGroupBlockDesc.ueCombIdxs[propUeGroupBlockDesc.nUes]  = combIdx;
                            propUeGroupBlockDesc.ueHopIdxs[propUeGroupBlockDesc.nUes]   = hopIdx;
                            for(int portIdx = 0; portIdx < nPortsPerComb; ++portIdx)
                            {
                                propUeGroupBlockDesc.blockPortToUePortMap[propUeGroupBlockDesc.nAntPorts + portIdx]   = portIdx;
                                propUeGroupBlockDesc.portToUeIdxWithinBlock[portIdx + propUeGroupBlockDesc.nAntPorts] = propUeGroupBlockDesc.nUes;
                                propUeGroupBlockDesc.portToFoccMap[propUeGroupBlockDesc.nAntPorts + portIdx]          = portToFoccMap[combIdx][portIdx];
                            }
                            propUeGroupBlockDesc.nUes      += 1;
                            propUeGroupBlockDesc.nAntPorts += nPortsPerComb;
                            break;
                        }
                    }

                    // If no matching compute block found, create a new one:
                    if(newUeGroupFlag)
                    {
                        ueGroupDescr_t& newUeGroupDesc  = pCpuDynDesc->ueGroupDescrs[nUeGroups];

                        newUeGroupDesc.ueIdxs[0]     = ueIdx;
                        newUeGroupDesc.ueCombIdxs[0] = combIdx;
                        newUeGroupDesc.ueHopIdxs[0]  = hopIdx;
                        for(int portIdx = 0; portIdx < nPortsPerComb; ++portIdx)
                        {
                            newUeGroupDesc.portToUeIdxWithinBlock[portIdx] = 0;
                            newUeGroupDesc.portToFoccMap[portIdx]          = portToFoccMap[combIdx][portIdx];
                            newUeGroupDesc.blockPortToUePortMap[portIdx]   = portIdx;
                        }
                        newUeGroupDesc.nUes          = 1;
                        newUeGroupDesc.nAntPorts     = nPortsPerComb;
                        nUeGroups                   += 1;
                    }
                }
            }
       }else // allocate RKHS compute blocks
       {
            uint8_t nPol = 2;
            for(uint8_t combIdx = 0; combIdx < nCombs; ++combIdx)
            {
                for(uint8_t portIdx = 0; portIdx < nPorts; ++portIdx)
                {
                    for(uint8_t polIdx = 0; polIdx < nPol; ++polIdx)
                    {
                        pCpuDynDesc->rkhsCompBlockDescrs[nRkhsCompBlocks].combIdx = combIdx;
                        pCpuDynDesc->rkhsCompBlockDescrs[nRkhsCompBlocks].portIdx = portIdx;
                        pCpuDynDesc->rkhsCompBlockDescrs[nRkhsCompBlocks].polIdx  = polIdx;
                        pCpuDynDesc->rkhsCompBlockDescrs[nRkhsCompBlocks].ueIdx   = ueIdx;

                        const int freqProj_d0 = RKHS_NUM_CP_INTS;
                        const int freqProj_d1 = RKHS_NUM_EIGS_PER_DIM;
                        const int freqProj_d2 = RKHS_NUM_VER_ANTS;
                        const int freqProj_d3 = RKHS_NUM_HOR_ANTS;
                        const int freqProjCoeffsDim[4] = {freqProj_d0, freqProj_d1, freqProj_d2, freqProj_d3};

                        const int freqProj_s0 = 1;
                        const int freqProj_s1 = RKHS_NUM_CP_INTS;
                        const int freqProj_s2 = RKHS_NUM_CP_INTS * RKHS_NUM_EIGS_PER_DIM;
                        const int freqProj_s3 = RKHS_NUM_CP_INTS * RKHS_NUM_EIGS_PER_DIM * RKHS_NUM_VER_ANTS;
                        const int freqProjCoeffsStride[4] = {freqProj_s0, freqProj_s1, freqProj_s2, freqProj_s3};

                        pCpuDynDesc->rkhsCompBlockDescrs[nRkhsCompBlocks].tFreqProjCoeffs = std::move(tensor_ref<CUPHY_C_16F, 4>(d_workspace_half2, freqProjCoeffsDim, freqProjCoeffsStride));

                        constexpr uint32_t freqProj_size = RKHS_NUM_EIGS_PER_DIM * RKHS_NUM_VER_ANTS * RKHS_NUM_HOR_ANTS * RKHS_NUM_CP_INTS;
                        d_workspace_half2 += freqProj_size;

                        const int hammingProj_d0 = RKHS_NOISE_REGION_LENGTH;
                        const int hammingProj_d1 = RKHS_NUM_VER_ANTS;
                        const int hammingProj_d2 = RKHS_NUM_HOR_ANTS;
                        const int hammingProjCoeffsDim[3] = {hammingProj_d0, hammingProj_d1, hammingProj_d2};

                        const int hammingProj_s0 = 1;
                        const int hammingProj_s1 = RKHS_NOISE_REGION_LENGTH;
                        const int hammingProj_s2 = RKHS_NOISE_REGION_LENGTH * RKHS_NUM_VER_ANTS;
                        const int hammingProjCoeffsStride[3] = {hammingProj_s0, hammingProj_s1, hammingProj_s2};

                        pCpuDynDesc->rkhsCompBlockDescrs[nRkhsCompBlocks].tHammingProjCoeffs = std::move(tensor_ref<CUPHY_C_16F, 3>(d_workspace_half2, hammingProjCoeffsDim, hammingProjCoeffsStride));

                        constexpr uint32_t hammingProj_size = RKHS_NOISE_REGION_LENGTH * RKHS_NUM_VER_ANTS * RKHS_NUM_HOR_ANTS;
                        d_workspace_half2 += hammingProj_size;

                        ++nRkhsCompBlocks;
                        ++ueNumBlocks;
                    }
                }
            }
       }
   }

   // Divide ueGroups into compute blocks:
   for(int ueGroupIdx = 0; ueGroupIdx < nUeGroups; ++ueGroupIdx)
   {
        // extract parameters common to users in group:
        ueGroupDescr_t& ueGroupDescr         = pCpuDynDesc->ueGroupDescrs[ueGroupIdx];
        uint16_t        firstUeInBlockIdx    = ueGroupDescr.ueIdxs[0];
        uint8_t         firstUeInBlockHopIdx = ueGroupDescr.ueHopIdxs[0];

        ueDescr_t&  firstUeDescr   = pCpuDynDesc->ueDescrs[firstUeInBlockIdx];
        uint16_t    startPrb       = firstUeDescr.hopStartPrbs[firstUeInBlockHopIdx];
        uint16_t    nPrbs          = firstUeDescr.nPrbsPerHop;
        uint16_t    nRxAntSrs      = h_srsCellPrms[firstUeDescr.cellIdx].nRxAntSrs;

        // break RX antennas into different compute blocks:
        uint16_t maxNumAntsPerBlock;
        uint16_t nRxAntBlocks;
        if((nRxAntSrs > 16) && (ueGroupDescr.nAntPorts > 4))
        {
            maxNumAntsPerBlock = 16;
            nRxAntBlocks       = (nRxAntSrs + maxNumAntsPerBlock - 1) / maxNumAntsPerBlock;
        }else
        {
            maxNumAntsPerBlock = nRxAntSrs;
            nRxAntBlocks       = 1;
        }

        // break frequency allocation into different blocks:
        uint16_t nPrbsBlocks = nPrbs / nPrbsPerComputeBlock;

        // Populate compute blocks:
        uint16_t nBlocksForThisUeGroup = 0;
        for(int freqBlockIdx = 0; freqBlockIdx < nPrbsBlocks; ++freqBlockIdx)
        {
            uint16_t blockStartPrb = startPrb + nPrbsPerComputeBlock * freqBlockIdx;
            uint16_t blockStartAnt = 0;

            for(int antBlockIdx = 0; antBlockIdx < nRxAntBlocks; ++antBlockIdx)
            {
                compBlockDescr_t& compBlockDescr = pCpuDynDesc->compBlockDescrs[nCompBlocks];
                compBlockDescr.ueGroupIdx        = ueGroupIdx;
                compBlockDescr.blockStartPrb     = blockStartPrb;
                compBlockDescr.nRxAntSrs         = min(maxNumAntsPerBlock, nRxAntSrs - blockStartAnt);
                compBlockDescr.blockStartAnt     = blockStartAnt;

                nCompBlocks           += 1;
                nBlocksForThisUeGroup += 1;
                blockStartAnt         += maxNumAntsPerBlock;
            }
        }

        // Propogate nBlocksForThisUeGroup to ueDescrs:
        uint16_t  nUes = ueGroupDescr.nUes;
        for(int ueIdxWithinBlock = 0; ueIdxWithinBlock < nUes; ++ueIdxWithinBlock)
        {
            uint16_t    ueIdx    = ueGroupDescr.ueIdxs[ueIdxWithinBlock];
            ueDescr_t&  ueDescr  = pCpuDynDesc->ueDescrs[ueIdx];
            ueDescr.ueNumBlocks += nBlocksForThisUeGroup;
        }
    }

   // populate cell descriptors:
   for(int cellIdx = 0; cellIdx < nCells; ++cellIdx)
   {
       pCpuDynDesc->cellDescrs[cellIdx].mu     = h_srsCellPrms[cellIdx].mu;
       pCpuDynDesc->cellDescrs[cellIdx].nRxAntSrs = h_srsCellPrms[cellIdx].nRxAntSrs;

       tensor_pair tPairDataRx (static_cast<const tensor_desc&>(*(pTDataRx[cellIdx].desc)), pTDataRx[cellIdx].pAddr);
       const tensor_layout_any& tDataRxLayout = tPairDataRx.first.get().layout();
       void*                    tDataRxAddr   = tPairDataRx.second;
       pCpuDynDesc->cellDescrs[cellIdx].tDataRx = std::move(tensor_ref_any<CUPHY_C_16F>(tDataRxAddr, tDataRxLayout.dimensions.begin(), tDataRxLayout.strides.begin()));
   }

   srsChEstKernelArgs_t& kernelArgs = m_kernelArgs;
   kernelArgs.pDynDescr = reinterpret_cast<srsChEstDynDescr_t*>(pGpuDynDesc);

   // optional descriptor copy to GPU memory
   if(enableCpuToGpuDescrAsyncCpy)
   {
       cudaMemcpyAsync(pGpuDynDesc, pCpuDynDesc, sizeof(srsChEstDynDescr_t), cudaMemcpyHostToDevice, strm);
   }

    // rkhs descriptor
    if(m_chEstAlgo == SRS_CH_EST_ALGO_TYPE_RKHS)
    {
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_twiddle32, twiddle32, sizeof(twiddle32), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_fourier32PermuteIdx, fourier32PermuteIdx, sizeof(fourier32PermuteIdx), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_fourier8PermuteIdx, fourier8PermuteIdx, sizeof(fourier8PermuteIdx), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_fourier4PermuteIdx, fourier4PermuteIdx, sizeof(fourier4PermuteIdx), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_rkhsEigValesNorm, rkhsEigValesNorm, sizeof(rkhsEigValesNorm), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_rkhsEigVales, rkhsEigVales, sizeof(rkhsEigVales), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_rkhsEigValesAntNorm, rkhsEigValesAntNorm, sizeof(rkhsEigValesAntNorm), 0, cudaMemcpyHostToDevice, strm));
        CUDA_CHECK(cudaMemcpyToSymbolAsync(d_hammingWindow, hammingWindow, sizeof(hammingWindow), 0, cudaMemcpyHostToDevice, strm));
    }

   // select kernel (includes launch geometry). Populate launchCfg.
   kernelSelect(pCpuDynDesc, nSrsUes, nCompBlocks, nRkhsCompBlocks, pLaunchCfg, pNormalizationLaunchCfg);
   pLaunchCfg->kernelArgs[0] = &kernelArgs.pStatDescr;
   pLaunchCfg->kernelArgs[1] = &kernelArgs.pDynDescr;
   pLaunchCfg->kernelNodeParamsDriver.kernelParams = &(pLaunchCfg->kernelArgs[0]);
   
   if(m_chEstToL2NormalizationAlgo==1)
   {
       pNormalizationLaunchCfg->kernelArgs[0] = &kernelArgs.pDynDescr;
       pNormalizationLaunchCfg->kernelNodeParamsDriver.kernelParams = &(pNormalizationLaunchCfg->kernelArgs[0]);
   }
   return CUPHY_STATUS_SUCCESS;
}


void tensorPrm_to_tensorRef(cuphyTensorPrm_t& tensorPrm, tensor_ref_any<CUPHY_C_16F>& tRef)
{
   tensor_pair tPair(static_cast<const tensor_desc&>(*(tensorPrm.desc)), tensorPrm.pAddr);
   const tensor_layout_any& tLayout = tPair.first.get().layout();
   void*                    tAddr   = tPair.second;
   tRef = std::move(tensor_ref_any<CUPHY_C_16F>(tAddr, tLayout.dimensions.begin(), tLayout.strides.begin()));
}

void tensorPrm_to_tensorRef(cuphyTensorPrm_t& tensorPrm, tensor_ref_any<CUPHY_R_16F>& tRef)
{
   tensor_pair tPair(static_cast<const tensor_desc&>(*(tensorPrm.desc)), tensorPrm.pAddr);
   const tensor_layout_any& tLayout = tPair.first.get().layout();
   void*                    tAddr   = tPair.second;
   tRef = std::move(tensor_ref_any<CUPHY_R_16F>(tAddr, tLayout.dimensions.begin(), tLayout.strides.begin()));
}


void tensorPrm_to_tensorRef(cuphyTensorPrm_t& tensorPrm, tensor_ref_any<CUPHY_R_8U>& tRef)
{
   tensor_pair tPair(static_cast<const tensor_desc&>(*(tensorPrm.desc)), tensorPrm.pAddr);
   const tensor_layout_any& tLayout = tPair.first.get().layout();
   void*                    tAddr   = tPair.second;
   tRef = std::move(tensor_ref_any<CUPHY_R_8U>(tAddr, tLayout.dimensions.begin(), tLayout.strides.begin()));
}

void srsChEst::init(cuphySrsFilterPrms_t*   pSrsFilterPrms,
                    cuphySrsRkhsPrms_t*     pRkhsPrms,
                    cuphySrsChEstAlgoType_t chEstAlgo,
                    uint8_t                 chEstToL2NormalizationAlgo,
                    float                   chEstToL2ConstantScaler,
                    uint8_t                 enableDelayOffsetCorrection,
                    bool                    enableCpuToGpuDescrAsyncCpy,
                    srsChEstStatDescr_t*    pCpuStatDesc,
                    void*                   pGpuStatDesc,
                    cudaStream_t            strm)
{
    m_chEstAlgo = chEstAlgo;
    m_chEstToL2NormalizationAlgo = chEstToL2NormalizationAlgo;

   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmFocc_table      , pCpuStatDesc->tFocc_table);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmFocc_comb2_table, pCpuStatDesc->tFocc_comb2_table);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmFocc_comb4_table, pCpuStatDesc->tFocc_comb4_table);

   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts1_wide, pCpuStatDesc->tW_comb2_nPorts1_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts2_wide, pCpuStatDesc->tW_comb2_nPorts2_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts4_wide, pCpuStatDesc->tW_comb2_nPorts4_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts8_wide, pCpuStatDesc->tW_comb2_nPorts8_wide);

   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts1_wide, pCpuStatDesc->tW_comb4_nPorts1_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts2_wide, pCpuStatDesc->tW_comb4_nPorts2_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts4_wide, pCpuStatDesc->tW_comb4_nPorts4_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts6_wide, pCpuStatDesc->tW_comb4_nPorts6_wide);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts12_wide, pCpuStatDesc->tW_comb4_nPorts12_wide);

   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts1_narrow, pCpuStatDesc->tW_comb2_nPorts1_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts2_narrow, pCpuStatDesc->tW_comb2_nPorts2_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts4_narrow, pCpuStatDesc->tW_comb2_nPorts4_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb2_nPorts8_narrow, pCpuStatDesc->tW_comb2_nPorts8_narrow);

   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts1_narrow, pCpuStatDesc->tW_comb4_nPorts1_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts2_narrow, pCpuStatDesc->tW_comb4_nPorts2_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts4_narrow, pCpuStatDesc->tW_comb4_nPorts4_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts6_narrow, pCpuStatDesc->tW_comb4_nPorts6_narrow);
   tensorPrm_to_tensorRef(pSrsFilterPrms->tPrmW_comb4_nPorts12_narrow, pCpuStatDesc->tW_comb4_nPorts12_narrow);

   pCpuStatDesc->noisEstDebias_comb2_nPorts1 = pSrsFilterPrms->noisEstDebias_comb2_nPorts1;
   pCpuStatDesc->noisEstDebias_comb2_nPorts2 = pSrsFilterPrms->noisEstDebias_comb2_nPorts2;
   pCpuStatDesc->noisEstDebias_comb2_nPorts4 = pSrsFilterPrms->noisEstDebias_comb2_nPorts4;
   pCpuStatDesc->noisEstDebias_comb2_nPorts8 = pSrsFilterPrms->noisEstDebias_comb2_nPorts8;

   pCpuStatDesc->noisEstDebias_comb4_nPorts1  = pSrsFilterPrms->noisEstDebias_comb4_nPorts1;
   pCpuStatDesc->noisEstDebias_comb4_nPorts2  = pSrsFilterPrms->noisEstDebias_comb4_nPorts2;
   pCpuStatDesc->noisEstDebias_comb4_nPorts4  = pSrsFilterPrms->noisEstDebias_comb4_nPorts4;
   pCpuStatDesc->noisEstDebias_comb4_nPorts6  = pSrsFilterPrms->noisEstDebias_comb4_nPorts6;
   pCpuStatDesc->noisEstDebias_comb4_nPorts12 = pSrsFilterPrms->noisEstDebias_comb4_nPorts12;

    if(chEstAlgo == SRS_CH_EST_ALGO_TYPE_RKHS)
    {
        for(int i = 0; i < NUM_RKHS_GRIDS; ++i)
        {
            tensorPrm_to_tensorRef(pRkhsPrms->pRkhsGridPrms[i].eigenVecs   , pCpuStatDesc->rkhsGridDescs[i].tEigenVecs);
            tensorPrm_to_tensorRef(pRkhsPrms->pRkhsGridPrms[i].eigenValues , pCpuStatDesc->rkhsGridDescs[i].tEigenValues);
            tensorPrm_to_tensorRef(pRkhsPrms->pRkhsGridPrms[i].eigenCorr   , pCpuStatDesc->rkhsGridDescs[i].tEigenCorr);

            // copyTensorPrm2Info(pRkhsPrms->pRkhsGridPrms[i].eigenVecs   , pCpuStatDesc->rkhsGridDescs[i].tEigenVecs);
            // copyTensorPrm2Info(pRkhsPrms->pRkhsGridPrms[i].eigenValues , pCpuStatDesc->rkhsGridDescs[i].tEigenValues);
            // copyTensorPrm2Info(pRkhsPrms->pRkhsGridPrms[i].eigenCorr   , pCpuStatDesc->rkhsGridDescs[i].tEigenCorr);
        }

       tensorPrm_to_tensorRef(pRkhsPrms->pRkhsGridPrms[2].secondStageTwiddleFactors , pCpuStatDesc->rkhsGridDescs[2].tSecondStageTwiddleFactors);
       tensorPrm_to_tensorRef(pRkhsPrms->pRkhsGridPrms[2].secondStageFourierPerm    , pCpuStatDesc->rkhsGridDescs[2].tSecondStageFourierPerm);
    }

   pCpuStatDesc->chEstToL2NormalizationAlgo = chEstToL2NormalizationAlgo;
   pCpuStatDesc->chEstToL2ConstantScaler = chEstToL2ConstantScaler;
   pCpuStatDesc->enableDelayOffsetCorrection = enableDelayOffsetCorrection;

   srsChEstKernelArgs_t& kernelArgs = m_kernelArgs;
   kernelArgs.pStatDescr = reinterpret_cast<srsChEstStatDescr_t*>(pGpuStatDesc);

   if(enableCpuToGpuDescrAsyncCpy)
   {
       cudaMemcpyAsync(pGpuStatDesc, pCpuStatDesc, sizeof(srsChEstStatDescr_t), cudaMemcpyHostToDevice, strm);
   }
}
