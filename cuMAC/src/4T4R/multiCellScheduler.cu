/*
 * SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "cumac.h"

// cuMAC namespace
namespace cumac {

//#define SCHEDULER_KERNEL_TIME_MEASURE_ 
#ifdef SCHEDULER_KERNEL_TIME_MEASURE_
constexpr uint16_t numRunSchKnlTimeMsr = 1000;
#endif

#define dir 0


static __device__ __constant__ uint16_t pow2NArr[64][128] = {{2,2,4,4,8,8,8,8,16,16,16,16,16,16,16,16,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128},
{2,4,8,8,16,16,16,16,32,32,32,32,32,32,32,32,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256},
{4,8,16,16,16,32,32,32,32,32,64,64,64,64,64,64,64,64,64,64,64,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512},
{4,8,16,16,32,32,32,32,64,64,64,64,64,64,64,64,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512},
{8,16,16,32,32,32,64,64,64,64,64,64,128,128,128,128,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024},
{8,16,32,32,32,64,64,64,64,64,128,128,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024},
{8,16,32,32,64,64,64,64,64,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024},
{8,16,32,32,64,64,64,64,128,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024},
{16,32,32,64,64,64,64,128,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,32,64,64,64,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,64,64,64,128,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,64,64,64,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,64,64,128,128,128,128,128,256,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,64,64,128,128,128,128,128,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,64,64,128,128,128,128,256,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{16,32,64,64,128,128,128,128,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048},
{32,64,64,128,128,128,128,256,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,64,128,128,128,128,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,64,128,128,128,256,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,64,128,128,128,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,64,128,128,128,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,128,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,128,256,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,128,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,128,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,256,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,256,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,256,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{32,64,128,128,256,256,256,256,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096},
{64,128,128,256,256,256,256,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192},
{64,128,128,256,256,256,256,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,256,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,256,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192},
{64,128,256,256,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,2048,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,4096,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192,8192}};

multiCellScheduler::multiCellScheduler(cumacCellGrpPrms* cellGrpPrms)
{
  Asim = 0;

  DL = cellGrpPrms->dlSchInd;

  enableHarq = cellGrpPrms->harqEnabledInd;

  // allocate memory for dynamic descriptors
  pCpuDynDesc = std::make_unique<mcDynDescr_t>();
  CUDA_CHECK_ERR(cudaMalloc((void **)&pGpuDynDesc, sizeof(mcDynDescr_t)));

  pLaunchCfg = std::make_unique<launchCfg_t>();
  numCompleteBlk_h.resize(1);
  numCompleteBlk_h[0] = 0;

  CUDA_CHECK_ERR(cudaMalloc((void **)&numCompleteBlk_d, sizeof(int)));

  // set default to column-major channel matrix access
  columnMajor = 1;
  
  // determine number of SMs in the device
  if (Asim == 0) {
     int idevice;
     CUDA_CHECK_ERR(cudaGetDevice(&idevice));

     cudaDeviceProp devProps;
     CUDA_CHECK_ERR(cudaGetDeviceProperties(&devProps, idevice));

     numSM = static_cast<uint16_t>(devProps.multiProcessorCount);
  } else {
     numSM = 0;
  }

  printf("numSM: %d\n", numSM);
}

multiCellScheduler::multiCellScheduler(cumacCellGrpPrms* cellGrpPrms, uint8_t in_Asim)
{
  Asim = in_Asim;

  DL = cellGrpPrms->dlSchInd;

  enableHarq = cellGrpPrms->harqEnabledInd;

  // allocate memory for dynamic descriptors
  pCpuDynDesc = std::make_unique<mcDynDescr_t>();
  CUDA_CHECK_ERR(cudaMalloc((void **)&pGpuDynDesc, sizeof(mcDynDescr_t)));

  pLaunchCfg = std::make_unique<launchCfg_t>();
  numCompleteBlk_h.resize(1);
  numCompleteBlk_h[0] = 0;

  CUDA_CHECK_ERR(cudaMalloc((void **)&numCompleteBlk_d, sizeof(int)));

  // set default to column-major channel matrix access
  columnMajor = 1;

  if (Asim == 1) numSM = 0;
}

multiCellScheduler::~multiCellScheduler()
{
  CUDA_CHECK_ERR(cudaFree(pGpuDynDesc));
  CUDA_CHECK_ERR(cudaFree(numCompleteBlk_d));
}

inline __device__ void bitonicSort(float* valueArr, uint16_t* idArr, uint16_t n)
  {
    for (int size = 2; size < n; size*=2) {
        int d=dir^((threadIdx.x & (size / 2)) != 0);
       
        for (int stride = size / 2; stride > 0; stride/=2) {
           __syncthreads(); 

           if(threadIdx.x<n/2) {
              int pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));

              float t;
              int t_id;

              if (((valueArr[pos] > valueArr[pos + stride]) || (valueArr[pos] == valueArr[pos + stride] && idArr[pos] < idArr[pos + stride])) == d) {
                  t = valueArr[pos];
                  valueArr[pos] = valueArr[pos + stride];
                  valueArr[pos + stride] = t;
                  t_id = idArr[pos];
                  idArr[pos] = idArr[pos + stride];
                  idArr[pos + stride] = t_id;
              }
           }
        }
    }
    
    for (int stride = n / 2; stride > 0; stride/=2) {
        __syncthreads(); 
        if(threadIdx.x<n/2) {
           int pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));

           float t;
           int t_id;

           if (((valueArr[pos] > valueArr[pos + stride]) || (valueArr[pos] == valueArr[pos + stride] && idArr[pos] < idArr[pos + stride])) == dir) {
               t = valueArr[pos];
               valueArr[pos] = valueArr[pos + stride];
               valueArr[pos + stride] = t;
             
               t_id = idArr[pos];
               idArr[pos] = idArr[pos + stride];
               idArr[pos + stride] = t_id;
           }
        }
    }

    __syncthreads(); 
 }



inline __device__ void findUeMaxBand ( int totNumAssocUeFound, int nBand, uint16_t pow2NArr[64][128], float *unsorted_pfMetricArr, uint16_t *tempBand, int *globalPeakBand, int *thisUeFound )
{
    // Parallel reduction of max [metric] and associated sub-band for each UE.
    // All 'not yet found' UEs are reduced simultaneously.
    // This has the added benefit of only using Log2(nBands) synchronizations vs. totNumAssocUeFound x that.
    // This requres that the # of threads be at least 1/2 * Pow2N(nBands) * #UE

  
    int niter = pow2NArr[0][nBand-1]/2;
    int iue = threadIdx.x / niter;
    int tid = threadIdx.x % niter;
    int bandmax = tid;
    float maxmetric;

    if ( (tid < niter) && (iue < totNumAssocUeFound) ) {
      if ( ! thisUeFound[iue] ) {
	maxmetric = unsorted_pfMetricArr[bandmax+nBand*iue];
	if ( tid + niter <  nBand ) {
	  tempBand[(tid+niter)+nBand*iue] = tid+niter; 
	}
      }
    }

    // ensure tempBand is completely configured
    __syncthreads();
       
    while ( niter ) {
      
      if ( ( tid < niter ) && ( iue < totNumAssocUeFound ) ) {                             
	if ( ! thisUeFound[iue] ) {                                                       // don't bother reducing UEs for which the peak has already been found
	  
	  // thread is in range
	  if ( (tid + niter) < nBand ) {
	    int testband = tempBand[ (tid+niter)+nBand*iue ];
	    float testmetric = unsorted_pfMetricArr[testband+nBand*iue];
	    if ( testmetric > maxmetric ) {
	      bandmax = testband;
	      maxmetric = testmetric;
	    }
	  }
	
	  if ( tid >= niter/2 ) {
	    tempBand [tid+nBand*iue] = bandmax;
	  }
	  
	}	
      }
      
      niter = niter >> 1 ;

      // ensure tempBand is complete
      __syncthreads();
    
    }

    if ( (tid==0) && (iue<totNumAssocUeFound) ) {                                  
      if ( ! thisUeFound[iue] ) {                                     // don't bother updating UEs for which the peak has already been found
	globalPeakBand[iue] = tempBand[nBand*iue];
      }
    }
    
    __syncthreads();

}


inline __device__ void findUENeighbors ( int16_t  *lowerNeighbor, int16_t *upperNeighbor, int totNumAssocUeFound, int *foundPeakBand, int *globalPeakBand )
{
  // find the neighbors with established peaks for all UEs.
  // parallel over number of UEs 

  if ( threadIdx.x < totNumAssocUeFound ) {

      // initialize neighbors to no neighbors
      lowerNeighbor[threadIdx.x] = -1;
      upperNeighbor[threadIdx.x] = -1;
      
      // get my band
      int myband = globalPeakBand[threadIdx.x];

      // find my neighbors
      for ( int iue=0; iue<totNumAssocUeFound; iue++ ) {

	// don't compare with self
	if ( iue != threadIdx.x ) {

	  // only find neighbors that have already been defined as peaks
	  if ( foundPeakBand[iue] ) {

	    // check for updated lower neighbor
	    if ( globalPeakBand[iue] <= myband) {
	      if ( lowerNeighbor[threadIdx.x] == -1 ) {
		lowerNeighbor[threadIdx.x] = iue; 
	      }
	      else {
		if ( globalPeakBand[iue] > globalPeakBand[lowerNeighbor[threadIdx.x]] ) {
		  lowerNeighbor[threadIdx.x] = iue; 
		}
	      }	     
	    }	    
	    
	    // check for updated upper neighbor 	      
	    if ( globalPeakBand[iue] >= myband) {
	      if ( upperNeighbor[threadIdx.x] == -1 ) {
		upperNeighbor[threadIdx.x] = iue; 
	      }
	      else {
		if ( globalPeakBand[iue] < globalPeakBand[upperNeighbor[threadIdx.x]] ) {
		  upperNeighbor[threadIdx.x] = iue; 
		}
	      }	     
	    }
	  } 
	}
      }
    }
}

inline __device__ void prefixMin ( int iue, float *unsorted_pfMetricArr2, int nBand, int mypeak )
{
  // Compute the prefix-mins for UE = iue.
  // The mins are to the left and right of the peak subband defined by mypeak
  
  // PARALLEL Prefix-MIN	  
  float length = nBand;
  int position = threadIdx.x;
  int direction = 0;
  
  if ( position < mypeak ) {
    // corresponds to the low side
    direction = -1;
    position = position + 1;
  }
  else {
    // corresponds to the high side
    direction = 1;
  }
  
  // While we haven't yet done log2(length_ steps 
  while ( length >  .5 ) { /// Todo:  need to think - but this can probably be replaced with > 1)
    
    // So long a sthe result is in the valid range
    if ( position+direction < nBand && position + direction >= 0 ) {
      
      // find the min for the current two elements
      unsorted_pfMetricArr2[ (position+direction)+nBand*iue] = min (
								    unsorted_pfMetricArr2[ (position+direction)+nBand*iue],
								    unsorted_pfMetricArr2[ (position)+nBand*iue]
								    );      
      direction *= 2;
      
    }
    
    length *= .5;
    __syncthreads();
    
  }
  
}


//---------------------------- DL kernels ----------------------------------
static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_svdMmseIrc(mcDynDescr_t* pDynDescr) { // SVD precoding, MMSE-IRC receiver
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint32_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
  uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory
  __shared__ cuComplex  DInvMat[1024];
  __shared__ cuComplex  CMat[1024];
  __shared__ cuComplex  CInvMat[1024];
  __shared__ uint8_t    colIdx[1024];
  __shared__ uint8_t    rowIdx[1024];
  __shared__ uint16_t   CMatIdxTemp[1024];
  __shared__ uint16_t   CMatIdx[1024];
  __shared__ uint8_t    colIdx2[1024];
  __shared__ uint8_t    rowIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp2[1024];
  __shared__ uint16_t   CMatIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp3[1024];
  __shared__ uint16_t   CMatIdx3[1024];
  __shared__ int16_t    ueIdxArr[1024];
  __shared__ float      pfMetric[1024];

  colIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  rowIdx[threadIdx.x] = eIdx - colIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  colIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  rowIdx2[threadIdx.x] = eIdx - colIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;
  
  __shared__ int nAssocUeFound;

  // SCR - Grid-stride loop over prbs*cells
  const uint16_t nThrdBlk = pDynDescr->nCell * pDynDescr->nPrbGrp;
  for (uint16_t blkIdx = blockIdx.x; blkIdx < nThrdBlk; blkIdx += gridDim.x) {
    uint16_t rbgIdx = floor(static_cast<float>(blkIdx)/pDynDescr->nCell);
    uint16_t cIdx   = pDynDescr->cellId[blkIdx - rbgIdx*pDynDescr->nCell];
  
    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;

    bool cnt = true;
  
    while (cnt) {
        if (threadIdx.x == 0)
            nAssocUeFound = 0;
        __syncthreads();

        uIdx = -1;
  
        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();
  
        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]].x = 0;
            CMat[CMatIdx[threadIdx.x]].y = 0;
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
                uint32_t hInterfMatStart = rbgIdx*nUeCellBsUeAntPrd+ uIdx*nCellBsUeAntPrd + l*nBsUeAntPrd;
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    cuComplex tmp1 = pDynDescr->estH_fr[hInterfMatStart + rowIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    cuComplex tmp2 = pDynDescr->estH_fr[hInterfMatStart + colIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                    CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            } else {
                CInvMat[CMatIdx[threadIdx.x]].x = 0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]+col_i*pDynDescr->nUeAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];
                    
                    CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads();
        }
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nUeAntSqrd; j++) {
                printf("CMat.x = %f, CMat.y = %f, CInvMat.x = %f, CInvMat.y = %f\n", CMat[j].x, CMat[j].y,CInvMat[j].x, CInvMat[j].y);
            }
        }
#endif

        // compute H*V
        // reuse DInvMat for storing H*V
        uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;
        uint32_t vMatStart = uIdx*pDynDescr->nPrbGrp*nBsAntSqrd + rbgIdx*nBsAntSqrd;

        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            DInvMat[CMatIdx2[threadIdx.x]].x = 0;
            DInvMat[CMatIdx2[threadIdx.x]].y = 0;

            for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                cuComplex tmp1 = pDynDescr->estH_fr[hMatStart + j*pDynDescr->nUeAnt + rowIdx[threadIdx.x]];
                cuComplex tmp2 = pDynDescr->prdMat[vMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt +j];
                DInvMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                DInvMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }
        }
        __syncthreads();
    
        // compute (H*V)^H*C^-1
        // reuse CMat for storing (H*V)^H*C^-1
        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]].x = 0;
            CMat[CMatIdx2[threadIdx.x]].y = 0;
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = DInvMat[CMatIdxTemp2[threadIdx.x]+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }
        }
        __syncthreads();
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nUeAntSqrd; j++) {
                printf("CMat.x = %f, CMat.y = %f\n", CMat[j].x, CMat[j].y);
            }
        }
#endif
        // compute (H*V)^H*C^-1*(H*V) + I
        // reuse CInvMat for storing (H*V)^H*C^-1*(H*V) + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j*pDynDescr->nBsAnt+rowIdx2[threadIdx.x]];
                cuComplex tmp2 = DInvMat[CMatIdxTemp2[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        if (uIdx >= 0) {
            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nBsAntSqrd; j++) {
                printf("CInvMat.x = %f, CInvMat.y = %f\n", CInvMat[j].x, CInvMat[j].y);
            }
        }
#endif
        // compute ((H*V)^H*C^-1*(H*V) + I)^-1
        // use DInvMat for storing ((H*V)^H*C^-1*(H*V) + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]+col_i*pDynDescr->nBsAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nBsAntSqrd; j++) {
                printf("CInvMat.x = %f, CInvMat.y = %f, DInvMat.x = %f, DInvMat.y = %f\n", CInvMat[j].x, CInvMat[j].y,DInvMat[j].x, DInvMat[j].y);
            }
        }
#endif

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = uIdx;
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        __syncthreads(); 
#ifdef MCSCHEDULER_DEBUG_    
        if (blockIdx.x == 0 && eIdx == 0) {
            printf("assocUeIdxInBlk = %d, pfMetric = %f, ueIdxArr = %d\n", assocUeIdxInBlk, pfMetric[assocUeIdxInBlk], ueIdxArr[assocUeIdxInBlk]);
        }
#endif
    }

  // select UE
    if (threadIdx.x == 0) {
        float   maxv = 0;
        int16_t maxi = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (ueIdxArr[j] < 0)
                break;
            if (pfMetric[j] > maxv) {
                maxv = pfMetric[j];
                maxi = ueIdxArr[j];
            }
        }
        pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = maxi;
        //printf("cIdx = %d, pDynDescr->allocSol = %d\n", cIdx, pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx]);
    }
  }
} 

static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_noPrdMmseIrc(mcDynDescr_t* pDynDescr) { // no precoding, MMSE-IRC receiver
  // determine indices
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint32_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
  uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory
  __shared__ cuComplex  DInvMat[1024];
  __shared__ cuComplex  CMat[1024];
  __shared__ cuComplex  CInvMat[1024];
  __shared__ uint8_t    colIdx[1024];
  __shared__ uint8_t    rowIdx[1024];
  __shared__ uint16_t   CMatIdxTemp[1024];
  __shared__ uint16_t   CMatIdx[1024];
  __shared__ uint8_t    colIdx2[1024];
  __shared__ uint8_t    rowIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp2[1024];
  __shared__ uint16_t   CMatIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp3[1024];
  __shared__ uint16_t   CMatIdx3[1024];
  __shared__ int16_t    ueIdxArr[1024];
  __shared__ float      pfMetric[1024];

  colIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  rowIdx[threadIdx.x] = eIdx - colIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  colIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  rowIdx2[threadIdx.x] = eIdx - colIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;

  __shared__ int nAssocUeFound;

   // SCR - Grid-stride loop over prbs*cells
  const uint16_t nThrdBlk = pDynDescr->nCell * pDynDescr->nPrbGrp;
  for (uint16_t blkIdx = blockIdx.x; blkIdx < nThrdBlk; blkIdx += gridDim.x) {
    uint16_t rbgIdx = floor(static_cast<float>(blkIdx)/pDynDescr->nCell);
    uint16_t cIdx   = pDynDescr->cellId[blkIdx - rbgIdx*pDynDescr->nCell];

    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;

    bool cnt = true;
  
    while (cnt) {
        if (threadIdx.x == 0)
            nAssocUeFound = 0;
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]].x = 0;
            CMat[CMatIdx[threadIdx.x]].y = 0;
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
                uint32_t hInterfMatStart = rbgIdx*nUeCellBsUeAntPrd+ uIdx*nCellBsUeAntPrd + l*nBsUeAntPrd;
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    cuComplex tmp1 = pDynDescr->estH_fr[hInterfMatStart + rowIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    cuComplex tmp2 = pDynDescr->estH_fr[hInterfMatStart + colIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                    CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            } else {
                CInvMat[CMatIdx[threadIdx.x]].x = 0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]+col_i*pDynDescr->nUeAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads();
        }
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nUeAntSqrd; j++) {
            printf("CMat.x = %f, CMat.y = %f, CInvMat.x = %f, CInvMat.y = %f\n", CMat[j].x, CMat[j].y,CInvMat[j].x, CInvMat[j].y);
            }
        }
#endif
        // compute H^H*C^-1
        // reuse CMat for storing H^H*C^-1
        uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;

        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]].x = 0;
            CMat[CMatIdx2[threadIdx.x]].y = 0;
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = pDynDescr->estH_fr[hMatStart+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }
        }
        __syncthreads();
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nUeAntSqrd; j++) {
                printf("CMat.x = %f, CMat.y = %f\n", CMat[j].x, CMat[j].y);
            }
        }
#endif
        // compute H^H*C^-1*H + I
        // reuse CInvMat for storing H^H*C^-1*H + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j*pDynDescr->nBsAnt+rowIdx2[threadIdx.x]];
                cuComplex tmp2 = pDynDescr->estH_fr[hMatStart+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }

            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nBsAntSqrd; j++) {
                printf("CInvMat.x = %f, CInvMat.y = %f\n", CInvMat[j].x, CInvMat[j].y);
            }
        }
#endif
        // compute (H^H*C^-1*H + I)^-1
        // use DInvMat for storing (H^H*C^-1*H + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]+col_i*pDynDescr->nBsAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }
#ifdef MCSCHEDULER_DEBUG_
        if (assocUeIdxInBlk == 0 && uIdx >= 0 && eIdx == 0) {
            for (int j = 0; j<nBsAntSqrd; j++) {
                printf("CInvMat.x = %f, CInvMat.y = %f, DInvMat.x = %f, DInvMat.y = %f\n", CInvMat[j].x, CInvMat[j].y,DInvMat[j].x, DInvMat[j].y);
            }
        }
#endif

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = uIdx;
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        __syncthreads(); 
#ifdef MCSCHEDULER_DEBUG_    
        if (blockIdx.x == 0 && eIdx == 0) {
            printf("assocUeIdxInBlk = %d, pfMetric = %f, ueIdxArr = %d\n", assocUeIdxInBlk, pfMetric[assocUeIdxInBlk], ueIdxArr[assocUeIdxInBlk]);
        }
#endif
    }
  
    // select UE
    if (threadIdx.x == 0) {
        float   maxv = 0;
        int16_t maxi = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (ueIdxArr[j] < 0)
                break;
            if (pfMetric[j] > maxv) {
                maxv = pfMetric[j];
                maxi = ueIdxArr[j];
            }
        }
        pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = maxi;
        // printf("cIdx = %d, pDynDescr->allocSol = %d, maxv = %f\n", cIdx, pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx], maxv);
    }
  }
}

static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void lwPfSchedulerKernel_noPrdSinrLoad(mcDynDescr_t* pDynDescr)
{
    uint32_t assocUeIdxInBlk = threadIdx.x;
    int32_t  uIdx;
  
    __shared__ uint32_t cellAssocShrd[1024];
    __shared__ int32_t ueIdxArr[1024];
    __shared__ float   pfMetric[1024];
  
    // SCR - Grid-stride loop over prbs*cells
    const uint32_t nThrdBlk = pDynDescr->nCell * pDynDescr->nPrbGrp;
    for (uint32_t blkIdx = blockIdx.x; blkIdx < nThrdBlk; blkIdx += gridDim.x) {
        uint32_t rbgIdx = blkIdx / pDynDescr->nCell;
        uint32_t cIdx   = pDynDescr->cellId[blkIdx % pDynDescr->nCell];
  
        uIdx = -1;
    
        ueIdxArr[threadIdx.x] = -1;
        pfMetric[threadIdx.x] = 0;
  
        for (int p = threadIdx.x; p < pDynDescr->nUe; p += blockDim.x) {
            cellAssocShrd[p] = pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + p];
        }
        __syncthreads();
  
        int32_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (cellAssocShrd[j] == 1) {
                assocUeRank += 1;
                if (assocUeRank == assocUeIdxInBlk) {
                    uIdx = j;
                    break;
                }
            }
        }
        
        if (uIdx >= 0) {
            for (int lIdx = 0; lIdx < pDynDescr->nUeAnt; lIdx++) {
                float sinrTemp = pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + lIdx];
  
                pfMetric[threadIdx.x] += pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp + 1.0)));
            }
    
            pfMetric[threadIdx.x] = pow(pfMetric[threadIdx.x], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[threadIdx.x] = uIdx;
        }
        __syncthreads();
  
        // parallel reduction to calculate average SINR per UE
        uint16_t h = blockDim.x;
        uint16_t s = ceilf(h*0.5f);
  
        float pfTemp;
        int32_t ueIdTemp;
  
  #pragma unroll
        while(s > 1) {
            if(threadIdx.x < (h - s)) {
                if (pfMetric[threadIdx.x] < pfMetric[threadIdx.x + s]) {
                    pfTemp = pfMetric[threadIdx.x];
                    ueIdTemp = ueIdxArr[threadIdx.x];
  
                    pfMetric[threadIdx.x] = pfMetric[threadIdx.x + s];
                    ueIdxArr[threadIdx.x] = ueIdxArr[threadIdx.x + s];
  
                    pfMetric[threadIdx.x + s] = pfTemp;
                    ueIdxArr[threadIdx.x + s] = ueIdTemp;
                }
            }
            h = s; 
            s = ceilf(h*0.5f);
  
            __syncthreads();
        }
  
        if (threadIdx.x == 0) {
            if (pfMetric[threadIdx.x] < pfMetric[threadIdx.x + 1]) {
                pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = static_cast<int16_t>(ueIdxArr[threadIdx.x + 1]);
            } else {
                pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = static_cast<int16_t>(ueIdxArr[threadIdx.x]);
            }
        }
        __syncthreads();
    }
}

static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void lwPfSchedulerKernel_noPrdSinrCompute(mcDynDescr_t* pDynDescr)
{
  // determine indices
  uint32_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint32_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint32_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
  uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
  uint32_t assocUeIdxInBlk      = threadIdx.x / nBsAntSqrd;
  uint32_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int32_t  uIdx;
  uint32_t eIdx = threadIdx.x % nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory
  __shared__ cuComplex  DInvMat[1024];
  __shared__ cuComplex  CInvMat[1024];
  __shared__ uint32_t   colIdx2[1024];
  __shared__ uint32_t   rowIdx2[1024];
  __shared__ uint32_t   CMatIdxTemp3[1024];
  __shared__ uint32_t   CMatIdx3[1024];
  __shared__ int32_t    ueIdxArr[1024];
  __shared__ float      pfMetric[1024];

  __shared__ uint32_t cellAssocShrd[1024];

  colIdx2[threadIdx.x] = eIdx / pDynDescr->nBsAnt;
  rowIdx2[threadIdx.x] = eIdx % pDynDescr->nBsAnt;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;

  __shared__ int nAssocUeFound;

   // SCR - Grid-stride loop over prbs*cells
  const uint32_t nThrdBlk = pDynDescr->nCell * pDynDescr->nPrbGrp;
  for (uint32_t blkIdx = blockIdx.x; blkIdx < nThrdBlk; blkIdx += gridDim.x) {
    uint32_t rbgIdx = blkIdx / pDynDescr->nCell;
    uint32_t cIdx   = pDynDescr->cellId[blkIdx % pDynDescr->nCell];

    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;

    for (int p = threadIdx.x; p < pDynDescr->nUe; p += blockDim.x) {
        cellAssocShrd[p] = pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + p];
    }

    bool cnt = true;
  
    while (cnt) {
        if (threadIdx.x == 0)
            nAssocUeFound = 0;
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (cellAssocShrd[j] == 1) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        // compute H^H*H + sigmaSqrd*I
        // use CInvMat for storing H^H*H + sigmaSqrd*I
        uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;

        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = pDynDescr->estH_fr[hMatStart+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                cuComplex tmp2 = pDynDescr->estH_fr[hMatStart+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }

            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute (H^H*H + sigmaSqrd*I)^-1
        // use DInvMat for storing (H^H*H + sigmaSqrd*I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]+col_i*pDynDescr->nBsAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            double sinrTemp = 1.0/pDynDescr->sigmaSqrd/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            float dataRate = pDynDescr->W*static_cast<float>(log2(sinrTemp));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], dataRate);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = uIdx;
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        __syncthreads(); 
    }
  
    // parallel reduction to calculate average SINR per UE
    uint16_t h = pDynDescr->numUeSchdPerCellTTI;
    uint16_t s = ceilf(h*0.5f);

    float pfTemp;
    int32_t ueIdTemp;

#pragma unroll
    while(s > 1) {
        if(threadIdx.x < (h - s)) {
            if (pfMetric[threadIdx.x] < pfMetric[threadIdx.x + s]) {
                pfTemp = pfMetric[threadIdx.x];
                ueIdTemp = ueIdxArr[threadIdx.x];

                pfMetric[threadIdx.x] = pfMetric[threadIdx.x + s];
                ueIdxArr[threadIdx.x] = ueIdxArr[threadIdx.x + s];

                pfMetric[threadIdx.x + s] = pfTemp;
                ueIdxArr[threadIdx.x + s] = ueIdTemp;
            }
        }
        h = s; 
        s = ceilf(h*0.5f);

        __syncthreads();
    }

    if (threadIdx.x == 0) {
        if (pfMetric[threadIdx.x] < pfMetric[threadIdx.x + 1]) {
            pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = static_cast<int16_t>(ueIdxArr[threadIdx.x + 1]);
        } else {
            pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = static_cast<int16_t>(ueIdxArr[threadIdx.x]);
        }
    }
    __syncthreads();
  }
}

static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_type1_NoPrdMmseIrc_cm(mcDynDescr_t* pDynDescr)
{
  // determine indices
  uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
  uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint16_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
  uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory                                                  
  __shared__ __align__(16) uint8_t sharedPool[46*VSIZE];

  /*shared*/ cuComplex  *DInvMat      = (cuComplex*) sharedPool;               // 8  8   
  /*shared*/ cuComplex  *CMat         = DInvMat + VSIZE;                       // 8  16  
  /*shared*/ cuComplex  *CInvMat      = CMat + VSIZE;                          // 8  24  
  /*shared*/ float      *pfMetric     = (float*) (CInvMat + VSIZE);            // 4  28  
  /*shared*/ int16_t    *ueIdxArr     = (int16_t*) (pfMetric + VSIZE);         // 2  30  
  /*shared*/ uint16_t   *CMatIdxTemp  = (uint16_t*) (ueIdxArr + VSIZE);        // 2  32  
  /*shared*/ uint16_t   *CMatIdx      = (CMatIdxTemp + VSIZE);                 // 2  34  
  /*shared*/ uint16_t   *CMatIdxTemp2 = CMatIdx + VSIZE;                       // 2  36  
  /*shared*/ uint16_t   *CMatIdx2     = CMatIdxTemp2 + VSIZE;                  // 2  38  
  /*shared*/ uint16_t   *CMatIdxTemp3 = CMatIdx2 + VSIZE;                      // 2  40  
  /*shared*/ uint16_t   *CMatIdx3     = CMatIdxTemp3 + VSIZE;                  // 2  42  
  /*shared*/ uint8_t    *colIdx       = (uint8_t*) (CMatIdx3 + VSIZE);         // 1  43  
  /*shared*/ uint8_t    *rowIdx       = colIdx + VSIZE;                        // 1  44  
  /*shared*/ uint8_t    *colIdx2      = rowIdx + VSIZE;                        // 1  45  
  /*shared*/ uint8_t    *rowIdx2      = colIdx2 + VSIZE;                       // 1  46

  int16_t* allocSolS = (int16_t*) colIdx2;

  colIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  rowIdx[threadIdx.x] = eIdx - colIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  colIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  rowIdx2[threadIdx.x] = eIdx - colIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  ueIdxArr[threadIdx.x] = -1;
  pfMetric[threadIdx.x] = 0;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;

  __shared__ int nAssocUeFound;
  uint16_t totNumAssocUeFound = 0;
  bool cnt = true;
  
  while (cnt) {
        if (threadIdx.x == 0) {
	  nAssocUeFound = 0;
        }
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]].x = 0;
            CMat[CMatIdx[threadIdx.x]].y = 0;
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
                uint32_t hInterfMatStart = rbgIdx*nUeCellBsUeAntPrd+ uIdx*nCellBsUeAntPrd + l*nBsUeAntPrd;
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    cuComplex tmp1 = pDynDescr->estH_fr[hInterfMatStart + rowIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    cuComplex tmp2 = pDynDescr->estH_fr[hInterfMatStart + colIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                    CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            } else {
                CInvMat[CMatIdx[threadIdx.x]].x = 0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]+col_i*pDynDescr->nUeAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads();
        }

        // compute H^H*C^-1
        // reuse CMat for storing H^H*C^-1
        uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;
        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]].x = 0;
            CMat[CMatIdx2[threadIdx.x]].y = 0;
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = pDynDescr->estH_fr[hMatStart+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        // compute H^H*C^-1*H + I
        // reuse CInvMat for storing H^H*C^-1*H + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j*pDynDescr->nBsAnt+rowIdx2[threadIdx.x]];
                cuComplex tmp2 = pDynDescr->estH_fr[hMatStart+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }

            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute (H^H*C^-1*H + I)^-1
        // use DInvMat for storing (H^H*C^-1*H + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]+col_i*pDynDescr->nBsAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;

            if (rbgIdx == 0) {
                pDynDescr->allocSol[uIdx*2] = -1;
                pDynDescr->allocSol[uIdx*2+1] = -1;
                allocSolS[uIdx*2] = -1;
                allocSolS[uIdx*2+1] = -1;
            }
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        totNumAssocUeFound += nAssocUeFound;
        __syncthreads(); 
  }
  
  // transfer computed PF metrics from shared memory to global memory
  uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
  uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
  uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
  
  for (int r = 0; r<nRound; r++) {
        uint16_t entry = r*blockDim.x + threadIdx.x;
        if (entry < totNumAssocUeFound) {
            pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
            pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
        }
  }
  __syncthreads();
  if (threadIdx.x == 0) {
        atomicAdd(pDynDescr->numCompleteBlk, 1);
  }

  // proceed when all thread blocks complete compute tasks
  if (totNumAssocUeFound == 0) {
        return;
  }
  
  // first sort computed PF metrices across all PRBs and all UEs
  uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;
  
  //assert ( pfSize < 4*VSIZE );              // ensure that pfMetricArr will fit in the overloaded DInvMat
  //assert ( 2*totNumAssocUeFound < VSIZE );  // ensure that the numer of Ue will fit in the overloaded CMatIdx

  // perform consecutive PRB allocation by a single thread block per cell
  if (rbgIdx == 0) {
      unsigned int ns = 8;
      if (threadIdx.x == 0) {
          while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
              __nanosleep(ns);
              if (ns < 256) {
                  ns *= 2;
              }
          }
      }
  }
  
  __syncthreads();

  if ( rbgIdx == 0 ) {

    //
    // PARALLEL RIDING PEAKS ---------------------------------------------------------------------------------------
    //
    // 1. 'EASY PEAKS' : quick scan for subbaand for each UE corresponding to max matric - if this is the max metric at this subband, then this is a peak.
    // 2. 'DIFFICULT PEAKS' : iterate through UEs which no peak assigned by max metric - compare to current 'neighbor' peaks to determine if each is a peak.
    // 3. 'FILL GAPS' : once all peaks are found, assign subbands in the 'gaps' between peaks to one of the UEs corresponding to the bounding peaks efficiently.
    //
    // Uses a 'prefix-min' to efficiently perform steps 2. and 3.

    // convenience
    int nBand = pDynDescr->nPrbGrp;

    // Rather than allocting new arrays in SMEM, just re-use previously allocated shared memory.
    // All of the variables below are __shared__.  Zero new shared memory is allocated.
    // Sort of annoying getting all the offsets correct - but this means that any problem which would previously fit in shared, will still fit in shared.

    float* unsorted_pfMetricArr = (float*) sharedPool; // DInvMat;           // Vector that holds the metrics / per user / per subband.  This is the raw data.                                                                                  
    float* pfMetric_prefixMin   = unsorted_pfMetricArr + nBand*totNumAssocUeFound;
    uint16_t* tuid = (uint16_t*) (pfMetric_prefixMin + nBand*totNumAssocUeFound);
    uint16_t *tuid2 = tuid + nBand*totNumAssocUeFound; // CMatIdxTemp;                            // Vector holds the UE which represents the max metric for each subband.  Useful for the 'Easy Peaks' portion.                                

    float   *globalMax             = (float*)(tuid2 + nBand*totNumAssocUeFound); // pfMetric + 1;                                        // vector, max metric for each UE                                                                      
    float   &highestRemainingUeMax = globalMax[totNumAssocUeFound];  // pfMetric[0];                                         // scalar, just an SMEM cache of the higest max metric of any UE for which the peak has NOT been defined.          
    int     *thisUeFound           = (int *) (globalMax+totNumAssocUeFound+1);              // vector, code denoting that a peak has been found for this UE                                                                                     
    int     *foundPeakBand         = thisUeFound + totNumAssocUeFound;                    // vector, band for which the peak has been found for this UE                                                                                         
    int     *globalMaxBand         = foundPeakBand + totNumAssocUeFound;                  // vector, band where max metric occurs for each UE                                                                                                   
    int     *lowBand               = globalMaxBand + totNumAssocUeFound;                  // vector, the lower bound to the sub-band range for this UE                                                                                          
    int     *highBand              = lowBand + totNumAssocUeFound;                        // vector, the upper bound to the sub-band range for this UE                                                                                          
    int     &unassignedNotAllZero  = highBand[totNumAssocUeFound];                        // scalar, flag indicating all remaining metrics for all UEs which assigned peaks are/are not zero.                                                   
    int     &totalPeaksFound       = highBand[totNumAssocUeFound+1];                      // scalar, count of found peaks.                                                                                                                      
    int16_t *upperNeighbor         = (int16_t *) (highBand+totNumAssocUeFound+2);         // vector, the UE which forms the upper neighbor (found peak) of the current UE                                                                       
    int16_t *lowerNeighbor         = upperNeighbor + totNumAssocUeFound;                  // vector, the UE which forms the lower neighbor (found peak) of the current UE                                                                       
    
    // SETUP
    if ( threadIdx.x == 0 ) {
      unassignedNotAllZero = 1;
      highestRemainingUeMax = 0;
      totalPeaksFound=0;
    }

    // copy metrics into shared - parallel, full block
    for ( int idx=threadIdx.x; idx<pfSize; idx+=blockDim.x ) {

      // When copying metrics into unsorted_pfMetricArr* here, reorder them so that metrics for each UE are contiguous.
      // This is more expensive, requiring the computation of iband and iue, but it is expected that this will avoid
      // potentially very bad SMEM bank conflicts for the case of, say, totNumAssocUeFound=16 or 32.
      // Benchmarking didn't show a performance difference.

      int iband = idx/totNumAssocUeFound;
      int iue = idx - totNumAssocUeFound*iband;
      
      unsorted_pfMetricArr [nBand*iue+iband] = pDynDescr->pfMetricArr[pfStartCell+idx];
      pfMetric_prefixMin[nBand*iue+iband] = unsorted_pfMetricArr [nBand*iue+iband];

      // initialize some vectors
      if ( idx < totNumAssocUeFound ) {
	thisUeFound[idx] = 0;
	globalMax[idx] = 0;
      }

    }
    
    // ensure setup/initialization is complete
    __syncthreads();


    // PARALLEL RIDING PEAKS ALGORITHM - Step 1:  EASY PEAKS -----------------------------------------------------------------------------------------------

    // parallel computation of Ue correspsonding to max metric for each subband
    // block stride loop - serial search within each subband
    for ( int iband=threadIdx.x; iband<nBand; iband+=blockDim.x ) {
      float maxmetric = unsorted_pfMetricArr[iband];
      int maxue = 0;
      for ( int iue=1; iue<totNumAssocUeFound; iue++ ) {
	if ( unsorted_pfMetricArr[iband+iue*nBand] > maxmetric ) {
	  maxmetric = unsorted_pfMetricArr[iband+nBand*iue];
	  maxue = iue;
	}	     
      }
      tuid[iband] = maxue;
    }
    
    // find subband corresponding to max metric for all UEs.  parallel reduction over all UEs simultaneously
    findUeMaxBand ( totNumAssocUeFound, nBand, pow2NArr, unsorted_pfMetricArr, tuid2, globalMaxBand, thisUeFound );

    // Each thread checks if that UEs global peak is really a peak. - parallel over UEs
    if ( threadIdx.x < totNumAssocUeFound ) {

      if ( tuid[globalMaxBand[threadIdx.x]] == threadIdx.x ) {

	// flag that new peaks have been found.
	thisUeFound[threadIdx.x] = 1;
	foundPeakBand[threadIdx.x] = globalMaxBand[threadIdx.x];
	atomicAdd(&totalPeaksFound,1);

	for ( int i=0; i<totNumAssocUeFound; i++ ) {
	  if ( i != threadIdx.x ) {
	    // zero other bands at this peak. ( -1 is just as good )
	    unsorted_pfMetricArr [ globalMaxBand[threadIdx.x] + nBand*i ] = -1.0;
	  }
	  else {
	    // note the max 
	    globalMax[threadIdx.x] = unsorted_pfMetricArr[ globalMaxBand[threadIdx.x] + nBand*i ];
	  }
	}
	
      }

    }

    __syncthreads();

    // Compute PrefixMins for all UEs with found peaks.
    // Required for both 'difficult peaks' and 'fill gaps', so makes sense to do here.
    for ( int iue=0; iue<totNumAssocUeFound; iue++ ) {      
      if ( thisUeFound[iue] ) {
	// parallel prefix - custom - simultaneousl prefix min min to left/right of peak
	prefixMin ( iue, pfMetric_prefixMin, nBand, globalMaxBand[iue] );
      }
    }


    // PARALLEL RIDING PEAKS ALGORITHM - Step 2:  DIFFICULT PEAKS ------------------------------------------------------------------------------------------

    // Only perform step 2 - find difficult peaks - if all the peaks weren't obvious.
    if ( totalPeaksFound != totNumAssocUeFound ) {

      // Re-find all maxes - parallel reduction, because when finding the easy peaks, some metrics for the not-found UEs would have been zeroed.
      // OPTIMIZATION - could keep trak of whether the zeroed metrics corresponded to peaks and only re-reduce those whose existing peaks had been impacted.
      findUeMaxBand ( totNumAssocUeFound, nBand, pow2NArr, unsorted_pfMetricArr, tuid, globalMaxBand, thisUeFound );
    
      // find the neighbors with established peaks for all UEs. - parallel over #UEs
      findUENeighbors ( lowerNeighbor, upperNeighbor, totNumAssocUeFound, thisUeFound, globalMaxBand );

      // While there are still UEs that might have peaks - because not all metrics for the remaining UEs have been set to -1.
      while (unassignedNotAllZero) {

	__syncthreads();

	// SERIAL search for the highest peak from the remaining UEs
	if (threadIdx.x == 0 ) {
	  highestRemainingUeMax = 0.0;
	  for ( int iue=0; iue<totNumAssocUeFound; iue++ ) {
	    if ( !thisUeFound[iue] ) {
	      float testmetric = unsorted_pfMetricArr[ globalMaxBand[iue]+nBand*iue];
	      highestRemainingUeMax = max(testmetric, highestRemainingUeMax);
	      globalMax[iue] = testmetric;
	    }
	  }
	  unassignedNotAllZero = 0;
	}

	// ensure serial search complete
	__syncthreads();
	
	// Finds the UE which matches the highest remaining peak.  simple serial hack.
	for ( int iue=0; iue<totNumAssocUeFound; iue++) {

	  if ( !thisUeFound[iue] ) {
	    
	    if ( (globalMax[iue] == highestRemainingUeMax) && (highestRemainingUeMax > 0) ) {
	      
	      int lowUE, highUE;
	      float minlowmetric, minhighmetric;
	      
	      // set flag indicating that there is more to do in the while loop
	      if ( threadIdx.x == 0 ) {
		unassignedNotAllZero = 1;
	      }

	      lowUE = lowerNeighbor[iue];
	      highUE = upperNeighbor[iue];

	      // find min metric of the Ue to each side in the interval
	      if ( lowUE > -1 ) {
		minlowmetric = pfMetric_prefixMin[globalMaxBand[iue]+nBand*lowUE];
	      }
	      else {
		minlowmetric = 0;
	      }
	      if ( highUE > -1 ) {
		minhighmetric = pfMetric_prefixMin[globalMaxBand[iue]+nBand*highUE];
	      }
	      else {
		minhighmetric = 0;
	      }
	    
	      // IF - Peak > both mins, then this is a new peak
	      if ( globalMax[iue] > minlowmetric && globalMax[iue] > minhighmetric ) {  
	      
		if ( threadIdx.x == 0 ) {
		  // Mark as a peak
		  thisUeFound[iue] = 2;  // jump straight to 2.
		  foundPeakBand[iue] = globalMaxBand[iue];
		}
	      
		// zero all other UEs for this peak - PARALLEL over UEs
		// note that this invalidates the globalMax (metric) for all unassigned peaks.
		if ( threadIdx.x < totNumAssocUeFound ) {
		  if ( threadIdx.x != iue ) {
		    unsorted_pfMetricArr[ globalMaxBand[iue]+nBand*threadIdx.x ] = -1;
		  }
		}

		// Since a peak has been found, compute the prefix mins - needed for further difficult peaks and gap filling
		prefixMin ( iue, pfMetric_prefixMin, nBand, globalMaxBand[iue] );

	      }
	      else {

		if ( ( (lowUE > -1) && (minlowmetric > globalMax[iue]) ) &&  ( (highUE > -1) && (minhighmetric > globalMax[iue]) ) ) {
		  // lower than both peaks - so zero the entire range
		  if ( threadIdx.x >= foundPeakBand[lowUE] && threadIdx.x <= foundPeakBand[highUE] )  {
		    unsorted_pfMetricArr[threadIdx.x+nBand*iue] = -1;		    
		  }
		}

		// Else zero this UEs metrics over the interval for which the min is greater than the peak. (could be both)
		else if ( (lowUE > -1) && (minlowmetric > globalMax[iue]) ) {
		  // zero the low range - PARALLEL over nBand
		  if ( threadIdx.x >= foundPeakBand[lowUE] && threadIdx.x <= globalMaxBand[iue] )  {
		    unsorted_pfMetricArr[threadIdx.x+nBand*iue] = -1;
		  }
		}
		else if ( (highUE > -1) && (minhighmetric > globalMax[iue]) ) {
		  // zero the high range - PARALLEL over nBand
		  if ( threadIdx.x >= globalMaxBand[iue] && threadIdx.x <= foundPeakBand[highUE] ) {	   
		    unsorted_pfMetricArr[threadIdx.x+nBand*iue] = -1;
		  }
		}
	      }
	      break;	    
	    }
	  }
	}
	
	__syncthreads();

	// Re-find all maxes - since metrics have been zeroed.
	// todo - only re-find the maxes for the UEs that have updated.
	findUeMaxBand ( totNumAssocUeFound, nBand, pow2NArr, unsorted_pfMetricArr, tuid, globalMaxBand, thisUeFound );

	findUENeighbors ( lowerNeighbor, upperNeighbor, totNumAssocUeFound, thisUeFound, globalMaxBand );

      } 

    }
    else {
      // all the peaks were easy, but still need to find neighbors
      findUENeighbors ( lowerNeighbor, upperNeighbor, totNumAssocUeFound, thisUeFound, globalMaxBand );
    }


    // PARALLEL RIDING PEAKS ALGORITHM - Step 3:  FILL GAPS ------------------------------------------------------------------------------------------------

    // PARALLEL over UEs.
    if ( threadIdx.x < totNumAssocUeFound ) {

      int iue = threadIdx.x;
      
      if ( thisUeFound[iue] ) {
	
	// initialize high/low
	if ( thisUeFound[iue] ) {
	  lowBand[iue] = foundPeakBand[iue];
	  highBand[iue] = foundPeakBand[iue];
	}

      }

    }

    // each thread can update it's upper neighbor's lowBand - so need to sync all threads before proceeding.
    __syncthreads();
    
    if ( threadIdx.x < totNumAssocUeFound ) {

      int iue = threadIdx.x;
      
      if ( thisUeFound[iue] ) {

	// Adjacent peaks have already been found
	int lowUE = lowerNeighbor[iue];
	int highUE = upperNeighbor[iue];
	
	// If on bottom fill lower
	if ( lowUE == -1 ) {
	  lowBand[iue] = 0;
	}
	
	// If on top fill upper
	if ( highUE == -1 ) {
	  highBand[iue] = nBand-1;
	}

	// else fill upper gap
	else {

	  // bisection-search for gap transition
	  // low-band is the subband of the 'lower' peak
	  int isblow = foundPeakBand[iue];
	  int isbhi = foundPeakBand[highUE];
	  while ( (isbhi - isblow) > 1 ) {
	    
	    int isbtry = (isblow+isbhi)/2;
	    if ( pfMetric_prefixMin[isbtry+nBand*iue] > pfMetric_prefixMin[isbtry+nBand*highUE]) {
	      isblow = isbtry;
	    }
	    else {
	      isbhi=isbtry;
	    }
	    
	  }

	  highBand[iue] = isblow;
	  lowBand[highUE] = isbhi;

	}
	
      }  // if thisUeFound 
      
    }


    // each thread can update it's upper neighbor's lowBand - so need to sync all threads before proceeding.
    __syncthreads();
    
    // output results
    if ( threadIdx.x < totNumAssocUeFound ) {
      int iue = threadIdx.x;
      if ( thisUeFound[iue] ) {
	int actualUe = pDynDescr->pfIdArr[pfStartCell+iue]/pDynDescr->nPrbGrp;
	pDynDescr->allocSol[2*actualUe] = lowBand[iue];
	pDynDescr->allocSol[2*actualUe+1] = highBand[iue]+1;
      }
    }
        
  }

}


static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_type1_svdPrdMmseIrc_cm(mcDynDescr_t* pDynDescr)
{
    // determine indices
    uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
    uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
    uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
    uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
    uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
    uint16_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
    uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
    uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
    uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
    int16_t  uIdx;
    uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix
  
    // setup data arrays in shared memory
    __shared__ cuComplex  DInvMat[2*VSIZE];                   // DInvMat will be overloaded to hold a unsorted copy of pfMetricArr.  But 
    /*shared*/ cuComplex  *CMat = DInvMat+VSIZE;              // pfMetricArr is possibly larger than VSIZE, so combining DInvMat and CMat so that pfMetricArr will fit.
    __shared__ cuComplex  CInvMat[VSIZE];                     // CMat just becomes a pointer to the middle of DInvMat.  It is still shared, because DInvMat is shared.
    __shared__ uint8_t    colIdx[VSIZE];
    __shared__ uint8_t    rowIdx[VSIZE];
    __shared__ uint16_t   CMatIdxTemp[VSIZE];
    __shared__ uint16_t   CMatIdx[VSIZE];
    __shared__ uint8_t    colIdx2[10*VSIZE];
    /*shared*/ uint8_t    *rowIdx2 = colIdx2 + VSIZE;
    /*shared*/ uint16_t   *CMatIdxTemp2 = (uint16_t*) colIdx2 + VSIZE;
    /*shared*/ uint16_t   *CMatIdx2 = (uint16_t*) colIdx2 + 2*VSIZE;
    /*shared*/ uint16_t   *CMatIdxTemp3 = (uint16_t*) colIdx2 + 3*VSIZE;
    /*shared*/ uint16_t   *CMatIdx3 = (uint16_t*) colIdx2 + 4*VSIZE;
    __shared__ int16_t    ueIdxArr[VSIZE];
    __shared__ float      pfMetric[VSIZE];

    float* unsorted_pfMetricArr = (float*) DInvMat;           // Array that holds the metrics / per user / per band.  Used to fill in 'gaps' between contiguous band assignments.
    int16_t* allocSolS = (int16_t*) colIdx2;
    uint16_t* tuid = CMatIdx;                                 // Vector mapping user ids to threads.  Overloads CMatIdx.
  
    colIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
    rowIdx[threadIdx.x] = eIdx - colIdx[threadIdx.x]*pDynDescr->nUeAnt;
    CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
    CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;
  
    colIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
    rowIdx2[threadIdx.x] = eIdx - colIdx2[threadIdx.x]*pDynDescr->nBsAnt;
    CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
    CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;
  
    CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
    CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;
  
    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;
  
    cuComplex c_coeff;
    cuComplex c_inv_coeff;
    cuComplex d_coeff;
    float     d_multp;
    cuComplex p_coeff;
    cuComplex p_inv_coeff;
    cuComplex l_coeff;
  
    __shared__ int nAssocUeFound;
    __shared__ uint16_t nPeaksFound;
    __shared__ uint16_t nAllocated;
    uint16_t totNumAssocUeFound = 0;
    bool cnt = true;
    
    while (cnt) {
          if (threadIdx.x == 0) {
              nAssocUeFound = 0;
              nPeaksFound = 0;
              nAllocated = 0;
          }
          __syncthreads();
  
          uIdx = -1;
  
          int16_t assocUeRank = -1;
          for (int j = 0; j<pDynDescr->nUe; j++) {
              if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                  assocUeRank += 1;
                  if (assocUeRank == realAssocUeIdxInBlk) {
                      uIdx = j;
                      if (eIdx == 0) {
                          atomicAdd(&nAssocUeFound, 1);
                      }
                      break;
                  }
              }
          }
          __syncthreads();
  
          if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
              cnt = false;
          }
  
          // compute C matrix
          if (uIdx >= 0 && eIdx < nUeAntSqrd) {
              CMat[CMatIdx[threadIdx.x]].x = 0;
              CMat[CMatIdx[threadIdx.x]].y = 0;
              for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                  uint16_t l = pDynDescr->cellId[lIdx];
  
                  if (l == cIdx) {
                      continue;
                  }
                  uint32_t hInterfMatStart = rbgIdx*nUeCellBsUeAntPrd+ uIdx*nCellBsUeAntPrd + l*nBsUeAntPrd;
            
                  for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                      cuComplex tmp1 = pDynDescr->estH_fr[hInterfMatStart + rowIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                      cuComplex tmp2 = pDynDescr->estH_fr[hInterfMatStart + colIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                      CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                      CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                  }
              }
              if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                  CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                  CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                  CInvMat[CMatIdx[threadIdx.x]].y = 0;
              } else {
                  CInvMat[CMatIdx[threadIdx.x]].x = 0;
                  CInvMat[CMatIdx[threadIdx.x]].y = 0;
              }
          }
          __syncthreads();
  
          // compute inverse of C matrix
          // use CInvMat for storing inverse of C matrix
          for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
              if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                  if (rowIdx[threadIdx.x] == col_i) {
                      d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                      d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                      c_coeff = CMat[CMatIdx[threadIdx.x]];
                      c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];
  
                      CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                      CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                      CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                      CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                  } else {
                      l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]+col_i*pDynDescr->nUeAnt];
                  }
              }
              __syncthreads(); 
  
              if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                  if (rowIdx[threadIdx.x] != col_i) {
                      p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                      p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                      c_coeff = CMat[CMatIdx[threadIdx.x]];
                      c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];
  
                      CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                      CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                      CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                      CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                  }
              }
              __syncthreads();
          }
  
          // compute H*V
          // reuse DInvMat for storing H*V
          uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;
          uint32_t vMatStart = uIdx*pDynDescr->nPrbGrp*nBsAntSqrd + rbgIdx*nBsAntSqrd;

          if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
              DInvMat[CMatIdx2[threadIdx.x]].x = 0;
              DInvMat[CMatIdx2[threadIdx.x]].y = 0;

              for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                  cuComplex tmp1 = pDynDescr->estH_fr[hMatStart + j*pDynDescr->nUeAnt + rowIdx[threadIdx.x]];
                  cuComplex tmp2 = pDynDescr->prdMat[vMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt +j];
                  DInvMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                  DInvMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
              }
          }
          __syncthreads();

          // compute (H*V)^H*C^-1
          // reuse CMat for storing (H*V)^H*C^-1
          if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
              CMat[CMatIdx2[threadIdx.x]].x = 0;
              CMat[CMatIdx2[threadIdx.x]].y = 0;
        
              for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                  cuComplex tmp1 = DInvMat[CMatIdxTemp2[threadIdx.x]+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                  cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                  CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                  CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
              }
          }
          __syncthreads();

          // compute (H*V)^H*C^-1*(H*V) + I
          // reuse CInvMat for storing (H*V)^H*C^-1*(H*V) + I
          if (uIdx >= 0) {
              CInvMat[CMatIdx3[threadIdx.x]].x = 0;
              CInvMat[CMatIdx3[threadIdx.x]].y = 0;

              for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                  cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j*pDynDescr->nBsAnt+rowIdx2[threadIdx.x]];
                  cuComplex tmp2 = DInvMat[CMatIdxTemp2[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                  CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                  CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
              }
          }
          __syncthreads();

          if (uIdx >= 0) {
              if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                  CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                  DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                  DInvMat[CMatIdx3[threadIdx.x]].y = 0;
              } else {
                  DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                  DInvMat[CMatIdx3[threadIdx.x]].y = 0;
              }
          }
          __syncthreads();
  
          // compute ((H*V)^H*C^-1*(H*V) + I)^-1
          // use DInvMat for storing ((H*V)^H*C^-1*(H*V) + I)^-1
          for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
              if (uIdx >= 0) {
                  if (rowIdx2[threadIdx.x] == col_i) {
                      d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                      d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                      c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                      c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];
  
                      CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                      CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                      DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                      DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                  } else {
                      l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]+col_i*pDynDescr->nBsAnt];
                  }
              }
              __syncthreads(); 
  
              if (uIdx >= 0) {
                  if (rowIdx2[threadIdx.x] != col_i) {
                      p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                      p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                      c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                      c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];
  
                      CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                      CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                      DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                      DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                  }
              }
              __syncthreads(); 
          }

          if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
              float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
              pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
              sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
              atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
          }
          __syncthreads(); 

          if (uIdx >= 0 && eIdx == 0) {
              pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
              ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;
  
              if (rbgIdx == 0) {
                  pDynDescr->allocSol[uIdx*2] = -1;
                  pDynDescr->allocSol[uIdx*2+1] = -1;
                  allocSolS[uIdx*2] = -1;
                  allocSolS[uIdx*2+1] = -1;
              }
          }
          if (cnt){
              realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
          }
          totNumAssocUeFound += nAssocUeFound;
          __syncthreads(); 
    }
    
    // transfer computed PF metrics from shared memory to global memory
    uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
    uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
    uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
    
    for (int r = 0; r<nRound; r++) {
          uint16_t entry = r*blockDim.x + threadIdx.x;
          if (entry < totNumAssocUeFound) {
              pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
              pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
          }
    }
    __syncthreads();
    if (threadIdx.x == 0) {
          atomicAdd(pDynDescr->numCompleteBlk, 1);
    }
  
    // proceed when all thread blocks complete compute tasks
    if (totNumAssocUeFound == 0) {
          return;
    }

    // first sort computed PF metrices across all PRBs and all UEs
    uint16_t pow2N = 0;
    if (totNumAssocUeFound > 0) {
        pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
    }
    uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;
  
    //assert ( pfSize < 4*VSIZE );              // ensure that pfMetricArr will fit in the overloaded DInvMat
    //assert ( 2*totNumAssocUeFound < VSIZE );  // ensure that the numer of Ue will fit in the overloaded CMatIdx
    
    // perform consecutive PRB allocation by a single thread block per cell
    if (rbgIdx == 0) {
        unsigned int ns = 8;
        if (threadIdx.x == 0) {
            while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
                __nanosleep(ns);
                if (ns < 256) {
                    ns *= 2;
                }
            }
        }
    }
    
    __syncthreads();
    
    if (rbgIdx == 0) {
          nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
          for (int r = 0; r<nRound; r++) {
              uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
              if (entry < pow2N) {
                  pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                  pDynDescr->pfIdArr[pfStartCell + entry] = 0;
              }
          }
  
          // initialize S array
          // Reuse colIdx array in shared memory for S array
          if (threadIdx.x < pDynDescr->nPrbGrp) {
              colIdx[threadIdx.x] = 1;
          } 

          // copy unsorted pfMetricArr into shared 
          for ( int idx=threadIdx.x; idx<pfSize; idx+=blockDim.x ) {
              unsorted_pfMetricArr[idx] = pDynDescr->pfMetricArr[pfStartCell+idx] ;
          }
  
          // sort all PF metrics for each cell
          bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization
  
          // sequential riding peaks algorithm
          // used in the optimized case to find the peaks for each Ue
          if (threadIdx.x == 0) {
              uint16_t k = 0;
  
              while(nAllocated < pDynDescr->nPrbGrp) {
                  if (k == pfSize) {
                      break;
                  }
  
                  if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                      k++;
                      continue;
                  }
  
                  uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;
  
                  if (colIdx[c] == 0) {
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      k++;
                      continue;
                  }
  
                  uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;
  
                  if (allocSolS[2*i] == -1) {
                      pDynDescr->allocSol[2*i] = c;
                      pDynDescr->allocSol[2*i+1] = c + 1;
                      allocSolS[2*i] = c;
                      allocSolS[2*i+1] = c + 1;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                      tuid[2*nPeaksFound] = i;                         // map the Ue id to a threadId (used later)
                      tuid[2*nPeaksFound+1] = i - cIdx*pDynDescr->numUeSchdPerCellTTI;    // map the 0-based Ue index to a threadId.  (used to index into the gains in shared memory)
                      nPeaksFound++;
                      // once we've found all the peaks, exit the (slow) sequential portion of the algorithm
                      if (nPeaksFound >= totNumAssocUeFound) {
                          break;
                      }
                  } else if (c == (allocSolS[2*i] - 1)) {
                      pDynDescr->allocSol[2*i] = c;
                      allocSolS[2*i] = c;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else if (c == allocSolS[2*i+1]) {
                      pDynDescr->allocSol[2*i+1] = c + 1;
                      allocSolS[2*i+1] = c + 1;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else {
                      k++;
                  }   
              }
          } // threadIdx.x == 0 
    } // rbgIdx == 0

    // ensure threads don't proceed until all peaks have been found.
    __syncthreads();

    // exit criterion
    if (nAllocated == pDynDescr->nPrbGrp) {
       return;
    }

    if (rbgIdx ==  0) {
        // Parallelize over Ues.
        if (threadIdx.x < nPeaksFound) {
            int16_t neighbor_low_high;
            int16_t neighbor_low_id;
            int16_t neighbor_high_low;
            int16_t neighbor_high_id;
  
            // Find the upper and lower (in band) neighbors to each peak.
            uint16_t myLow = allocSolS[2*tuid[2*threadIdx.x]];
            uint16_t myHighPlusOne = allocSolS[2*tuid[2*threadIdx.x]+1];
            
            neighbor_low_high = -1;
            neighbor_low_id = -1;
            neighbor_high_low = pDynDescr->nPrbGrp;
            neighbor_high_id = totNumAssocUeFound;
            
            for (uint16_t ineighbor=0; ineighbor < nPeaksFound; ineighbor++) {
                // don't look at yourself
                if (threadIdx.x != ineighbor) {
                    
                    // check for lower that is higher than the current low
                    if (allocSolS[2*tuid[2*ineighbor]+1]-1 >= neighbor_low_high && allocSolS[2*tuid[2*ineighbor]+1] <= myLow) {
                        neighbor_low_high = allocSolS[2*tuid[2*ineighbor]+1]-1;
                        neighbor_low_id = ineighbor;
                    }
                    
                    if (allocSolS[2*tuid[2*ineighbor]] < neighbor_high_low && allocSolS[2*tuid[2*ineighbor]] >= myHighPlusOne) {
                        neighbor_high_low = allocSolS[2*tuid[2*ineighbor]];
                        neighbor_high_id = ineighbor;
                    }
                }
            }
            
            // fill in the upper and lower ends of the bands
            if (neighbor_low_id == - 1) {
                // lowest peak to zero
                pDynDescr->allocSol[2*tuid[2*threadIdx.x]] = 0;
            }
            
            if (neighbor_high_id == totNumAssocUeFound) {
                // highest peak to nPrbGrp
                pDynDescr->allocSol[2*tuid[2*threadIdx.x]+1] = pDynDescr->nPrbGrp;
            } else if (neighbor_high_id < totNumAssocUeFound) {
              // Fill in the gaps.
              // Gaps will be filled from a peak to next highest peak.
              // (But don't sweep high for the top peak - that's already been done.)
                if (myHighPlusOne  < neighbor_high_low) {
                    double myGain = unsorted_pfMetricArr[(tuid[2*threadIdx.x+1]) + totNumAssocUeFound * myHighPlusOne];
                    double neighborGain = unsorted_pfMetricArr[(tuid[2*neighbor_high_id+1]) + totNumAssocUeFound * (neighbor_high_low-1)];                  
                    
                    // While there is a gap between this peaks higher adjacent bands and the lowest band of the next higher peak
                    while (myHighPlusOne < neighbor_high_low) {
                        // CAUTION: when myGain == neighborGain, the band could concievably be assigned to either Ue.
                        // It has not been resolved that this algorithm assigns such cases to the same Ue as the CPU algorithm.
                        // assert (myGain != neighborGain)
                        if (myGain > neighborGain) {
                            myHighPlusOne++;
                            myGain = unsorted_pfMetricArr[ (tuid[2*threadIdx.x+1]) + totNumAssocUeFound * myHighPlusOne ];
                        } else {
                            neighbor_high_low--;
                            neighborGain = unsorted_pfMetricArr[ (tuid[2*neighbor_high_id+1]) + totNumAssocUeFound * (neighbor_high_low-1) ];
                        }
                    }
                    
                    // Send resolved low/high bands to DRAM
                    pDynDescr->allocSol[2*tuid[2*threadIdx.x]+1] = myHighPlusOne;
                    pDynDescr->allocSol[2*tuid[2*neighbor_high_id]] = neighbor_high_low;
                }
            }
        }
    }
}

static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_type1_NoPrdMmseIrc_rm(mcDynDescr_t* pDynDescr)
{
    // determine indices
  uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
  uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint16_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
  uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory
  __shared__ cuComplex  DInvMat[2*VSIZE];                   // DInvMat will be overloaded to hold a unsorted copy of pfMetricArr.  But 
  /*shared*/ cuComplex  *CMat = DInvMat+VSIZE;              // pfMetricArr is possibly larger than VSIZE, so combining DInvMat and CMat so that pfMetricArr will fit.
  __shared__ cuComplex  CInvMat[VSIZE];                     // CMat just becomes a pointer to the middle of DInvMat.  It is still shared, because DInvMat is shared.
  __shared__ uint8_t    colIdx[VSIZE];
  __shared__ uint8_t    rowIdx[VSIZE];
  __shared__ uint16_t   CMatIdxTemp[VSIZE];
  __shared__ uint16_t   CMatIdx[VSIZE];
  __shared__ uint8_t    colIdx2[10*VSIZE];
  /*shared*/ uint8_t    *rowIdx2 = colIdx2 + VSIZE;
  /*shared*/ uint16_t   *CMatIdxTemp2 = (uint16_t*) colIdx2 + VSIZE;
  /*shared*/ uint16_t   *CMatIdx2 = (uint16_t*) colIdx2 + 2*VSIZE;
  /*shared*/ uint16_t   *CMatIdxTemp3 = (uint16_t*) colIdx2 + 3*VSIZE;
  /*shared*/ uint16_t   *CMatIdx3 = (uint16_t*) colIdx2 + 4*VSIZE;
  __shared__ int16_t    ueIdxArr[VSIZE];
  __shared__ float      pfMetric[VSIZE];

  float* unsorted_pfMetricArr = (float*) DInvMat;           // Array that holds the 'gains' / per user / per band.  Used to fill in 'gaps' between contiguous band assignments.
  int16_t* allocSolS = (int16_t*) colIdx2;
  uint16_t* tuid = CMatIdx;                                 // Vector mapping user ids to threads.  Overloads CMatIdx.

  rowIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  colIdx[threadIdx.x] = eIdx - rowIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  rowIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  colIdx2[threadIdx.x] = eIdx - rowIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  ueIdxArr[threadIdx.x] = -1;
  pfMetric[threadIdx.x] = 0;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;

  __shared__ int nAssocUeFound;
  __shared__ uint16_t nPeaksFound;
  __shared__ uint16_t nAllocated;
  uint16_t totNumAssocUeFound = 0;
  bool cnt = true;
  
  while (cnt) {
        if (threadIdx.x == 0) {
            nAssocUeFound = 0;
            nPeaksFound = 0;
            nAllocated = 0;
        }
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]].x = 0;
            CMat[CMatIdx[threadIdx.x]].y = 0;
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
                uint32_t hInterfMatStart = rbgIdx*nUeCellBsUeAntPrd+ uIdx*nCellBsUeAntPrd + l*nBsUeAntPrd;
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    cuComplex tmp1 = pDynDescr->estH_fr[hInterfMatStart + rowIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                    cuComplex tmp2 = pDynDescr->estH_fr[hInterfMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                    CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                    CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            } else {
                CInvMat[CMatIdx[threadIdx.x]].x = 0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]*pDynDescr->nUeAnt+col_i];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+colIdx[threadIdx.x]];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+colIdx[threadIdx.x]];
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads();
        }

        // compute H^H*C^-1
        // reuse CMat for storing H^H*C^-1
        uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;
        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]].x = 0;
            CMat[CMatIdx2[threadIdx.x]].y = 0;
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = pDynDescr->estH_fr[hMatStart+rowIdx[threadIdx.x]+j*pDynDescr->nBsAnt];
                cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx[threadIdx.x]+j*pDynDescr->nUeAnt];
                CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        // compute H^H*C^-1*H + I
        // reuse CInvMat for storing H^H*C^-1*H + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt];
                cuComplex tmp2 = pDynDescr->estH_fr[hMatStart+colIdx2[threadIdx.x]+j*pDynDescr->nBsAnt];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }

            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute (H^H*C^-1*H + I)^-1
        // use DInvMat for storing (H^H*C^-1*H + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]*pDynDescr->nBsAnt+col_i];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+colIdx2[threadIdx.x]];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+colIdx2[threadIdx.x]];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;

            if (rbgIdx == 0) {
                pDynDescr->allocSol[uIdx*2] = -1;
                pDynDescr->allocSol[uIdx*2+1] = -1;
                allocSolS[uIdx*2] = -1;
                allocSolS[uIdx*2+1] = -1;
            }
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        totNumAssocUeFound += nAssocUeFound;
        __syncthreads(); 
  }
  
  // transfer computed PF metrics from shared memory to global memory
  uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
  uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
  uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
  
  for (int r = 0; r<nRound; r++) {
        uint16_t entry = r*blockDim.x + threadIdx.x;
        if (entry < totNumAssocUeFound) {
            pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
            pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
        }
  }
  __syncthreads();
  if (threadIdx.x == 0) {
        atomicAdd(pDynDescr->numCompleteBlk, 1);
  }

  // proceed when all thread blocks complete compute tasks
  if (totNumAssocUeFound == 0) {
        return;
  }

  // first sort computed PF metrices across all PRBs and all UEs
  uint16_t pow2N = 0;
  if (totNumAssocUeFound > 0) {
        pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
  }
  uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;
  
  //assert ( pfSize < 4*VSIZE );              // ensure that pfMetricArr will fit in the overloaded DInvMat
  //assert ( 2*totNumAssocUeFound < VSIZE );  // ensure that the numer of Ue will fit in the overloaded CMatIdx
  
  // perform consecutive PRB allocation by a single thread block per cell
  if (rbgIdx == 0) {
        unsigned int ns = 8;
        if (threadIdx.x == 0) {
            while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
                __nanosleep(ns);
                if (ns < 256) {
                    ns *= 2;
                }
            }
        }
  }
  __syncthreads();

  if (rbgIdx == 0) {
        nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
        for (int r = 0; r<nRound; r++) {
            uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
            if (entry < pow2N) {
                pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                pDynDescr->pfIdArr[pfStartCell + entry] = 0;
            }
        }

        // initialize S array
        // Reuse colIdx array in shared memory for S array
        if (threadIdx.x < pDynDescr->nPrbGrp) {
            colIdx[threadIdx.x] = 1;
        } 

        // copy unsorted pfMetricArr into shared 
        for ( int idx=threadIdx.x; idx<pfSize; idx+=blockDim.x ) {
            unsorted_pfMetricArr[idx] = pDynDescr->pfMetricArr[pfStartCell+idx] ;
        }

        // sort all PF metrics for each cell
        bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization

        // sequential riding peaks algorithm
        // used in the optimized case to find the peaks for each Ue
        if (threadIdx.x == 0) {
            uint16_t k = 0;

            while(nAllocated < pDynDescr->nPrbGrp) {
                if (k == pfSize) {
                    break;
                }

                if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                    k++;
                    continue;
                }

                uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;

                if (colIdx[c] == 0) {
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    k++;
                    continue;
                }

                uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;

                if (allocSolS[2*i] == -1) {
                    pDynDescr->allocSol[2*i] = c;
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    allocSolS[2*i] = c;
                    allocSolS[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                    tuid[2*nPeaksFound] = i;                         // map the Ue id to a threadId (used later)
                    tuid[2*nPeaksFound+1] = i - cIdx*pDynDescr->numUeSchdPerCellTTI;    // map the 0-based Ue index to a threadId.  (used to index into the gains in shared memory)
                    nPeaksFound++;
                    // once we've found all the peaks, exit the (slow) sequential portion of the algorithm
                    if (nPeaksFound >= totNumAssocUeFound) {
                        break;
                    }
                } else if (c == (allocSolS[2*i] - 1)) {
                    pDynDescr->allocSol[2*i] = c;
                    allocSolS[2*i] = c;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == allocSolS[2*i+1]) {
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    allocSolS[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else {
                    k++;
                }   
            }
        } // threadIdx.x == 0 
  } // rbgIdx == 0

  // ensure threads don't proceed until all peaks have been found.
  __syncthreads();

  // exit criterion
  if (nAllocated == pDynDescr->nPrbGrp) {
     return;
  }

  if (rbgIdx ==  0) {
      // Parallelize over Ues.
      if (threadIdx.x < nPeaksFound) {
          int16_t neighbor_low_high;
          int16_t neighbor_low_id;
          int16_t neighbor_high_low;
          int16_t neighbor_high_id;

          // Find the upper and lower (in band) neighbors to each peak.
          uint16_t myLow = allocSolS[2*tuid[2*threadIdx.x]];
          uint16_t myHighPlusOne = allocSolS[2*tuid[2*threadIdx.x]+1];
          
          neighbor_low_high = -1;
          neighbor_low_id = -1;
          neighbor_high_low = pDynDescr->nPrbGrp;
          neighbor_high_id = totNumAssocUeFound;
          
          for (uint16_t ineighbor=0; ineighbor < nPeaksFound; ineighbor++) {
              // don't look at yourself
              if (threadIdx.x != ineighbor) {
                  
                  // check for lower that is higher than the current low
                  if (allocSolS[2*tuid[2*ineighbor]+1]-1 >= neighbor_low_high && allocSolS[2*tuid[2*ineighbor]+1] <= myLow) {
                      neighbor_low_high = allocSolS[2*tuid[2*ineighbor]+1]-1;
                      neighbor_low_id = ineighbor;
                  }
                  
                  if (allocSolS[2*tuid[2*ineighbor]] < neighbor_high_low && allocSolS[2*tuid[2*ineighbor]] >= myHighPlusOne) {
                      neighbor_high_low = allocSolS[2*tuid[2*ineighbor]];
                      neighbor_high_id = ineighbor;
                  }
              }
          }
          
          // fill in the upper and lower ends of the bands
          if (neighbor_low_id == - 1) {
              // lowest peak to zero
              pDynDescr->allocSol[2*tuid[2*threadIdx.x]] = 0;
          }
          
          if (neighbor_high_id == totNumAssocUeFound) {
              // highest peak to nPrbGrp
              pDynDescr->allocSol[2*tuid[2*threadIdx.x]+1] = pDynDescr->nPrbGrp;
          } else if (neighbor_high_id < totNumAssocUeFound) {
            // Fill in the gaps.
            // Gaps will be filled from a peak to next highest peak.
            // (But don't sweep high for the top peak - that's already been done.)
              if (myHighPlusOne  < neighbor_high_low) {
                  double myGain = unsorted_pfMetricArr[(tuid[2*threadIdx.x+1]) + totNumAssocUeFound * myHighPlusOne];
                  double neighborGain = unsorted_pfMetricArr[(tuid[2*neighbor_high_id+1]) + totNumAssocUeFound * (neighbor_high_low-1)];                  
                  
                  // While there is a gap between this peaks higher adjacent bands and the lowest band of the next higher peak
                  while (myHighPlusOne < neighbor_high_low) {
                      // CAUTION: when myGain == neighborGain, the band could concievably be assigned to either Ue.
                      // It has not been resolved that this algorithm assigns such cases to the same Ue as the CPU algorithm.
                      // assert (myGain != neighborGain)
                      if (myGain > neighborGain) {
                          myHighPlusOne++;
                          myGain = unsorted_pfMetricArr[ (tuid[2*threadIdx.x+1]) + totNumAssocUeFound * myHighPlusOne ];
                      } else {
                          neighbor_high_low--;
                          neighborGain = unsorted_pfMetricArr[ (tuid[2*neighbor_high_id+1]) + totNumAssocUeFound * (neighbor_high_low-1) ];
                      }
                  }
                  
                  // Send resolved low/high bands to DRAM
                  pDynDescr->allocSol[2*tuid[2*threadIdx.x]+1] = myHighPlusOne;
                  pDynDescr->allocSol[2*tuid[2*neighbor_high_id]] = neighbor_high_low;
              }
          }
      }
  }
}

static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_half_noPrdMmseIrc(mcDynDescr_t* pDynDescr)
{
  // determine indices
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint32_t nCellBsUeAntPrd      = pDynDescr->totNumCell*nBsUeAntPrd;
  uint32_t nUeCellBsUeAntPrd    = pDynDescr->nUe*nCellBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix
  __nv_bfloat16 sigmaSqrd_half  = __float2bfloat16(pDynDescr->sigmaSqrd);
  /*
  if (rbgIdx == 0 && cIdx == 0 && threadIdx.x == 0) {
    __nv_bfloat162 a = {1, 2};
    __nv_bfloat162 b = {3, 4};
    __nv_bfloat162 c = {0, 0};
    __nv_bfloat162 d = {0, 0};
    c = __hcmadd(a, b, {0,0}); // com
    d = __hfma2(a, b, d);
    printf("c.x = %f, c.y = %f\n", __bfloat162float(c.x),__bfloat162float(c.y));
    printf("d.x = %f, d.y = %f\n", __bfloat162float(d.x),__bfloat162float(d.y));

    c = {0, 0};
    b.y = __hneg(b.y);
    c = __hcmadd(a, b, c); // com
    printf("c.x = %f, c.y = %f\n", __bfloat162float(c.x),__bfloat162float(c.y));

    c = {0, 0};
    a = __hmul2(a, a);
    printf("sum = %f\n", __bfloat162float(__hadd(a.x, a.y)));
    
    c.x = __hadd(c.x, sigmaSqrd_half);
    printf("c.x = %f, c.y = %f\n", __bfloat162float(c.x),__bfloat162float(c.y));

    c.x = hrcp(c.x);
    printf("c.x = %f, c.y = %f\n", __bfloat162float(c.x),__bfloat162float(c.y));
    
  }
  */
  // setup data arrays in shared memory
  __shared__ __nv_bfloat162     DInvMat[1024];
  __shared__ __nv_bfloat162     CMat[1024];
  __shared__ __nv_bfloat162     CInvMat[1024];
  __shared__ uint8_t            colIdx[1024];
  __shared__ uint8_t            rowIdx[1024];
  __shared__ uint16_t           CMatIdxTemp[1024];
  __shared__ uint16_t           CMatIdx[1024];
  __shared__ uint8_t            colIdx2[1024];
  __shared__ uint8_t            rowIdx2[1024];
  __shared__ uint16_t           CMatIdxTemp2[1024];
  __shared__ uint16_t           CMatIdx2[1024];
  __shared__ uint16_t           CMatIdxTemp3[1024];
  __shared__ uint16_t           CMatIdx3[1024];
  __shared__ int16_t            ueIdxArr[1024];
  __shared__ float              pfMetric[1024];

  colIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  rowIdx[threadIdx.x] = eIdx - colIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  colIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  rowIdx2[threadIdx.x] = eIdx - colIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  __nv_bfloat162 d_coeff;
  __nv_bfloat162 d_coeff_sqr;
  __nv_bfloat16  d_multp;
  __nv_bfloat162 p_coeff;
  __nv_bfloat162 p_inv_coeff;
  __nv_bfloat162 l_coeff;

  __shared__ int nAssocUeFound;

  // SCR - Grid-stride loop over prbs*cells
  const uint16_t nThrdBlk = pDynDescr->nCell * pDynDescr->nPrbGrp;
  for (uint16_t blkIdx = blockIdx.x; blkIdx < nThrdBlk; blkIdx += gridDim.x) {
    uint16_t rbgIdx = floor(static_cast<float>(blkIdx)/pDynDescr->nCell);
    uint16_t cIdx   = pDynDescr->cellId[blkIdx - rbgIdx*pDynDescr->nCell];

    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;

    bool cnt = true;
  
    while (cnt) {
        if (threadIdx.x == 0)
            nAssocUeFound = 0;
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]] = {0, 0};
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
                uint32_t hInterfMatStart = rbgIdx*nUeCellBsUeAntPrd+ uIdx*nCellBsUeAntPrd + l*nBsUeAntPrd;
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    __nv_bfloat162 tmp1 = pDynDescr->estH_fr_half[hInterfMatStart + rowIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    __nv_bfloat162 tmp2 = pDynDescr->estH_fr_half[hInterfMatStart + colIdx[threadIdx.x] + j*pDynDescr->nUeAnt];
                    tmp2.y = __hneg(tmp2.y);
                    CMat[CMatIdx[threadIdx.x]] = __hcmadd(tmp1, tmp2, CMat[CMatIdx[threadIdx.x]]);
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += sigmaSqrd_half;
                CInvMat[CMatIdx[threadIdx.x]] = {1.0, 0};
            } else {
                CInvMat[CMatIdx[threadIdx.x]] = {0, 0};
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];

                    d_coeff_sqr = __hmul2(d_coeff, d_coeff);
                    d_multp = hrcp(d_coeff_sqr.x + d_coeff_sqr.y); 

                    d_coeff.y = __hneg(d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]] = __hmul2(__hcmadd(CMat[CMatIdx[threadIdx.x]], d_coeff, {0,0}), {d_multp, d_multp});
                    CInvMat[CMatIdx[threadIdx.x]] = __hmul2(__hcmadd(CInvMat[CMatIdx[threadIdx.x]], d_coeff, {0,0}), {d_multp, d_multp});
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]+col_i*pDynDescr->nUeAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i+colIdx[threadIdx.x]*pDynDescr->nUeAnt];
                    CMat[CMatIdx[threadIdx.x]] = __hsub2(CMat[CMatIdx[threadIdx.x]], __hcmadd(l_coeff, p_coeff, {0,0}));
                    CInvMat[CMatIdx[threadIdx.x]] = __hsub2(CInvMat[CMatIdx[threadIdx.x]], __hcmadd(l_coeff, p_inv_coeff, {0,0}));
                }
            }
            __syncthreads();
        }

        // compute H^H*C^-1
        // reuse CMat for storing H^H*C^-1
        uint32_t hMatStart = rbgIdx*nUeCellBsUeAntPrd + uIdx*nCellBsUeAntPrd + cIdx*nBsUeAntPrd;

        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]] = {0, 0};
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                __nv_bfloat162 tmp1 = pDynDescr->estH_fr_half[hMatStart+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                __nv_bfloat162 tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];

                tmp1.y = __hneg(tmp1.y);
                CMat[CMatIdx2[threadIdx.x]] = __hcmadd(tmp1, tmp2, CMat[CMatIdx2[threadIdx.x]]);
            }
        }
        __syncthreads();

        // compute H^H*C^-1*H + I
        // reuse CInvMat for storing H^H*C^-1*H + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                __nv_bfloat162 tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j*pDynDescr->nBsAnt+rowIdx2[threadIdx.x]];
                __nv_bfloat162 tmp2 = pDynDescr->estH_fr_half[hMatStart+colIdx2[threadIdx.x]*pDynDescr->nUeAnt+j];
                CInvMat[CMatIdx3[threadIdx.x]] = __hcmadd(tmp1, tmp2, CInvMat[CMatIdx3[threadIdx.x]]);
            }

            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]] = {1.0, 0};
            } else {
                DInvMat[CMatIdx3[threadIdx.x]] = {0, 0};
            }
        }
        __syncthreads();

        // compute (H^H*C^-1*H + I)^-1
        // use DInvMat for storing (H^H*C^-1*H + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];

                    d_coeff_sqr = __hmul2(d_coeff, d_coeff);
                    d_multp = hrcp(d_coeff_sqr.x + d_coeff_sqr.y); 

                    d_coeff.y = __hneg(d_coeff.y);

                    CInvMat[CMatIdx3[threadIdx.x]] = __hmul2(__hcmadd(CInvMat[CMatIdx3[threadIdx.x]], d_coeff, {0,0}), {d_multp, d_multp});
                    DInvMat[CMatIdx3[threadIdx.x]] = __hmul2(__hcmadd(DInvMat[CMatIdx3[threadIdx.x]], d_coeff, {0,0}), {d_multp, d_multp});
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]+col_i*pDynDescr->nBsAnt];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i+colIdx2[threadIdx.x]*pDynDescr->nBsAnt];

                    CInvMat[CMatIdx3[threadIdx.x]] = __hsub2(CInvMat[CMatIdx3[threadIdx.x]], __hcmadd(l_coeff, p_coeff, {0,0}));
                    DInvMat[CMatIdx3[threadIdx.x]] = __hsub2(DInvMat[CMatIdx3[threadIdx.x]], __hcmadd(l_coeff, p_inv_coeff, {0,0}));
                }
            }
            __syncthreads(); 
        }

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = __bfloat162float(hrcp(DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x));
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads();

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = uIdx;
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        __syncthreads(); 
    }
  
    // select UE
    if (threadIdx.x == 0) {
        float   maxv = 0;
        int16_t maxi = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            if (ueIdxArr[j] < 0)
                break;
            if (pfMetric[j] > maxv) {
                maxv = pfMetric[j];
                maxi = ueIdxArr[j];
            }
        }
        pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx] = maxi;
        // printf("cIdx = %d, pDynDescr->allocSol = %d, maxv = %f\n", cIdx, pDynDescr->allocSol[rbgIdx*pDynDescr->totNumCell + cIdx], maxv);
    }
  }
}

/*
static __global__ void multiCellSchedulerKernel_Asim_type1_svdPrdMmseIrc_rm(mcDynDescr_t* pDynDescr)
{
  // determine indices
  uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
  uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint16_t nPrgBsUeAntPrd       = pDynDescr->nPrbGrp*nBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory
  __shared__ cuComplex  DInvMat[1024];
  __shared__ cuComplex  CMat[1024];
  __shared__ cuComplex  CInvMat[1024];
  __shared__ uint8_t    colIdx[1024];
  __shared__ uint8_t    rowIdx[1024];
  __shared__ uint16_t   CMatIdxTemp[1024];
  __shared__ uint16_t   CMatIdx[1024];
  __shared__ uint8_t    colIdx2[1024];
  __shared__ uint8_t    rowIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp2[1024];
  __shared__ uint16_t   CMatIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp3[1024];
  __shared__ uint16_t   CMatIdx3[1024];
  __shared__ int16_t    ueIdxArr[1024];
  __shared__ float      pfMetric[1024];

  rowIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  colIdx[threadIdx.x] = eIdx - rowIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  rowIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  colIdx2[threadIdx.x] = eIdx - rowIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  ueIdxArr[threadIdx.x] = -1;
  pfMetric[threadIdx.x] = 0;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;

  __shared__ int nAssocUeFound;
  uint16_t totNumAssocUeFound = 0;
  bool cnt = true;
  
  while (cnt) {
        if (threadIdx.x == 0)
            nAssocUeFound = 0;
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {

            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        uint32_t hMatStart = uIdx*nPrgBsUeAntPrd + rbgIdx*nBsUeAntPrd;

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]].x = 0;
            CMat[CMatIdx[threadIdx.x]].y = 0;
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    cuComplex tmp1 = pDynDescr->srsEstChan[l][hMatStart + rowIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                    cuComplex tmp2 = pDynDescr->srsEstChan[l][hMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                    CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                    CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            } else {
                CInvMat[CMatIdx[threadIdx.x]].x = 0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]*pDynDescr->nUeAnt+col_i];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+colIdx[threadIdx.x]];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+colIdx[threadIdx.x]];
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads();
        }

        // compute H*V
        // reuse DInvMat for storing H*V
        uint32_t vMatStart = uIdx*pDynDescr->nPrbGrp*nBsAntSqrd + rbgIdx*nBsAntSqrd;

        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            DInvMat[CMatIdx2[threadIdx.x]].x = 0;
            DInvMat[CMatIdx2[threadIdx.x]].y = 0;

            for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                cuComplex tmp1 = pDynDescr->srsEstChan[cIdx][hMatStart + j + rowIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                cuComplex tmp2 = pDynDescr->prdMat_asim[vMatStart + colIdx2[threadIdx.x] + j*pDynDescr->nBsAnt];
                DInvMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                DInvMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        // compute (H*V)^H*C^-1
        // reuse CMat for storing (H*V)^H*C^-1
        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]].x = 0;
            CMat[CMatIdx2[threadIdx.x]].y = 0;
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = DInvMat[CMatIdxTemp2[threadIdx.x]+rowIdx[threadIdx.x]+j*pDynDescr->nBsAnt];
                cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx[threadIdx.x]+j*pDynDescr->nUeAnt];
                CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        // compute (H*V)^H*C^-1*(H*V) + I
        // reuse CInvMat for storing (H*V)^H*C^-1*(H*V) + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt];
                cuComplex tmp2 = DInvMat[CMatIdxTemp2[threadIdx.x]+colIdx2[threadIdx.x]+j*pDynDescr->nBsAnt];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        if (uIdx >= 0) {
            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute ((H*V)^H*C^-1*(H*V) + I)^-1
        // use DInvMat for storing ((H*V)^H*C^-1*(H*V) + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]*pDynDescr->nBsAnt+col_i];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+colIdx2[threadIdx.x]];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+colIdx2[threadIdx.x]];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
            ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;

            if (rbgIdx == 0) {
                pDynDescr->allocSol[uIdx*2] = -1;
                pDynDescr->allocSol[uIdx*2+1] = -1;
            }
        }
        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        totNumAssocUeFound += nAssocUeFound;
        __syncthreads(); 
  }
  
  // transfer computed PF metrics from shared memory to global memory
  uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
  uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
  uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
  
  for (int r = 0; r<nRound; r++) {
        uint16_t entry = r*blockDim.x + threadIdx.x;
        if (entry < totNumAssocUeFound) {
            pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
            pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
        }
  }
  __syncthreads();
  if (threadIdx.x == 0) {
        atomicAdd(pDynDescr->numCompleteBlk, 1);
  }

  // preceed when all thread blocks complete compute tasks
  if (totNumAssocUeFound == 0) {
        return;
  }
  
  // perform consecutive PRB allocation by a single thread block per cell
  if (rbgIdx == 0) {
        unsigned int ns = 8;
        while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
            __nanosleep(ns);
            if (ns < 256) {
                ns *= 2;
            }
        }

        // first sort computed PF metrices across all PRBs and all UEs
        uint16_t pow2N = 0;
        if (totNumAssocUeFound > 0) {
            pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
        }
        uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;

        nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
        for (int r = 0; r<nRound; r++) {
            uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
            if (entry < pow2N) {
                pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                pDynDescr->pfIdArr[pfStartCell + entry] = 0;
            }
        }

        // initialize S array
        // Reuse colIdx array in shared memory for S array
        if (threadIdx.x < pDynDescr->nPrbGrp) {
            colIdx[threadIdx.x] = 1;
        } 

        // sort all PF metrics for each cell
        bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization

        // sequential riding peaks algorithm
        if (threadIdx.x == 0) {
            uint16_t nAllocated = 0;
            uint16_t k = 0;

            while(nAllocated < pDynDescr->nPrbGrp) {
                if (k == pfSize)
                    break;

                if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                    k++;
                    continue;
                }

                uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;

                if (colIdx[c] == 0) {
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    k++;
                    continue;
                }

                uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;

                if (pDynDescr->allocSol[2*i] == -1) {
                    pDynDescr->allocSol[2*i] = c;
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == (pDynDescr->allocSol[2*i] - 1)) {
                    pDynDescr->allocSol[2*i] = c;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == pDynDescr->allocSol[2*i+1]) {
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else {
                    k++;
                }   
            }
        }
  }
}*/

/*
static __global__ void multiCellSchedulerKernel_Asim_type1_svdPrdMmse_rm(mcDynDescr_t* pDynDescr)
{
    // determine indices
    uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
    uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
    uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
    uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
    uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
    uint16_t nPrgBsUeAntPrd       = pDynDescr->nPrbGrp*nBsUeAntPrd;
    uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
    uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
    int16_t  uIdx;
    uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix
  
    // setup data arrays in shared memory
    __shared__ cuComplex  DMat[1024];
    __shared__ cuComplex  CMat[1024];
    __shared__ uint8_t    colIdx[1024];
    __shared__ uint8_t    rowIdx[1024];
    __shared__ uint16_t   CMatIdxTemp[1024];
    __shared__ uint16_t   CMatIdx[1024];
    __shared__ int16_t    ueIdxArr[1024];
    __shared__ float      pfMetric[1024];
  
    rowIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
    colIdx[threadIdx.x] = eIdx - rowIdx[threadIdx.x]*pDynDescr->nUeAnt;
    CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
    CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;
  
    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;
  
    __shared__ int nAssocUeFound;
    uint16_t totNumAssocUeFound = 0;
    bool cnt = true;
    
    while (cnt) {
          if (threadIdx.x == 0)
              nAssocUeFound = 0;
          __syncthreads();
  
          uIdx = -1;
  
          int16_t assocUeRank = -1;
          for (int j = 0; j<pDynDescr->nUe; j++) {
              if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                  assocUeRank += 1;
                  if (assocUeRank == realAssocUeIdxInBlk) {
                      uIdx = j;
                      if (eIdx == 0) {
                          atomicAdd(&nAssocUeFound, 1);
                      }
                      break;
                  }
              }
          }
          __syncthreads();
  
          if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
              cnt = false;
          }
  
          uint32_t hMatStart = uIdx*nPrgBsUeAntPrd + rbgIdx*nBsUeAntPrd;
  
          // compute C matrix
          if (uIdx >= 0 && eIdx < nUeAntSqrd) {
              CMat[CMatIdx[threadIdx.x]].x = 0;
              CMat[CMatIdx[threadIdx.x]].y = 0;
              for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                  uint16_t l = pDynDescr->cellId[lIdx];
  
                  if (l == cIdx) {
                      continue;
                  }
            
                  for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                      cuComplex tmp1 = pDynDescr->srsEstChan[l][hMatStart + rowIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                      cuComplex tmp2 = pDynDescr->srsEstChan[l][hMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                      CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                      CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                  }
              }
              if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                  CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
              }
          }
          __syncthreads();
  
          // compute U^H*C
          // use DMat for storing U^H*C
          uint32_t uMatStart = uIdx*pDynDescr->nPrbGrp*nUeAntSqrd + rbgIdx*nUeAntSqrd;
          if (uIdx >= 0 && eIdx < nUeAntSqrd) {
              DMat[CMatIdx[threadIdx.x]].x = 0;
              DMat[CMatIdx[threadIdx.x]].y = 0;

              for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                  cuComplex tmp1 = pDynDescr->detMat_asim[uMatStart + j*pDynDescr->nUeAnt + rowIdx[threadIdx.x]];
                  cuComplex tmp2 = CMat[CMatIdxTemp[threadIdx.x] + j*pDynDescr->nUeAnt + colIdx[threadIdx.x]];
                  DMat[CMatIdx[threadIdx.x]].x = tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                  DMat[CMatIdx[threadIdx.x]].y = tmp1.x*tmp2.y - tmp2.x*tmp1.y;
              }
          }
          __syncthreads();

          // compute U^H*C*U
          // reuse CMat for storing U^H*C*U
          if (uIdx >= 0 && eIdx < nUeAntSqrd) {
              CMat[CMatIdx[threadIdx.x]].x = 0;
              CMat[CMatIdx[threadIdx.x]].y = 0;
              for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                  cuComplex tmp1 = DMat[CMatIdxTemp[threadIdx.x] + rowIdx[threadIdx.x]*pDynDescr->nUeAnt + j];
                  cuComplex tmp2 = pDynDescr->detMat_asim[uMatStart + j*pDynDescr->nUeAnt + colIdx[threadIdx.x]];
                  CMat[CMatIdx[threadIdx.x]].x = tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                  CMat[CMatIdx[threadIdx.x]].y = tmp1.x*tmp2.y + tmp2.x*tmp1.y;
              }
          }
          __syncthreads();
  
          if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
              float sinrTemp = pow(pDynDescr->sinVal_asim[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx], 2.0)/CMat[CMatIdxTemp[threadIdx.x] + eIdx*pDynDescr->nUeAnt + eIdx].x;
              pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp;
              sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(1.0 + sinrTemp)));
              atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
          }
          __syncthreads(); 
  
          if (uIdx >= 0 && eIdx == 0) {
              pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
              ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;
  
              if (rbgIdx == 0) {
                  pDynDescr->allocSol[uIdx*2] = -1;
                  pDynDescr->allocSol[uIdx*2+1] = -1;
              }
          }
          if (cnt){
              realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
          }
          totNumAssocUeFound += nAssocUeFound;
          __syncthreads(); 
    }
    
    // transfer computed PF metrics from shared memory to global memory
    uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
    uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
    uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
    
    for (int r = 0; r<nRound; r++) {
          uint16_t entry = r*blockDim.x + threadIdx.x;
          if (entry < totNumAssocUeFound) {
              pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
              pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
          }
    }
    __syncthreads();
    if (threadIdx.x == 0) {
          atomicAdd(pDynDescr->numCompleteBlk, 1);
    }
  
    // preceed when all thread blocks complete compute tasks
    if (totNumAssocUeFound == 0) {
          return;
    }
    
    // perform consecutive PRB allocation by a single thread block per cell
    if (rbgIdx == 0) {
          unsigned int ns = 8;
          while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
              __nanosleep(ns);
              if (ns < 256) {
                  ns *= 2;
              }
          }
  
          // first sort computed PF metrices across all PRBs and all UEs
          uint16_t pow2N = 0;
          if (totNumAssocUeFound > 0) {
              pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
          }
          uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;
  
          nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
          for (int r = 0; r<nRound; r++) {
              uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
              if (entry < pow2N) {
                  pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                  pDynDescr->pfIdArr[pfStartCell + entry] = 0;
              }
          }
  
          // initialize S array
          // Reuse colIdx array in shared memory for S array
          if (threadIdx.x < pDynDescr->nPrbGrp) {
              colIdx[threadIdx.x] = 1;
          } 
  
          // sort all PF metrics for each cell
          bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization
  
          // sequential riding peaks algorithm
          if (threadIdx.x == 0) {
              uint16_t nAllocated = 0;
              uint16_t k = 0;
  
              while(nAllocated < pDynDescr->nPrbGrp) {
                  if (k == pfSize)
                      break;
  
                  if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                      k++;
                      continue;
                  }
  
                  uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;
  
                  if (colIdx[c] == 0) {
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      k++;
                      continue;
                  }
  
                  uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;
  
                  if (pDynDescr->allocSol[2*i] == -1) {
                      pDynDescr->allocSol[2*i] = c;
                      pDynDescr->allocSol[2*i+1] = c + 1;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else if (c == (pDynDescr->allocSol[2*i] - 1)) {
                      pDynDescr->allocSol[2*i] = c;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else if (c == pDynDescr->allocSol[2*i+1]) {
                      pDynDescr->allocSol[2*i+1] = c + 1;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else {
                      k++;
                  }   
              }
          }
    }
} */

static __global__ void multiCellSchedulerKernel_Asim_type1_wbSinr(mcDynDescr_t* pDynDescr)
{
    // determine indices
    uint16_t numUePerRnd          = floor(static_cast<float>(blockDim.x)/pDynDescr->nPrbGrp);
    uint16_t cIdx                 = blockIdx.x;
    uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/pDynDescr->nPrbGrp);
    uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
    int16_t  uIdx;
    uint16_t prgIdx = threadIdx.x - assocUeIdxInBlk*pDynDescr->nPrbGrp; // entry index in matrix
  
    // setup data arrays in shared memory
    __shared__ uint16_t   ueIdxArr[2048];
    __shared__ float      pfMetric[2048];
    
    for (int idx = threadIdx.x; idx < 2048; idx += blockDim.x) {
        ueIdxArr[idx] = 0xFFFF;
        pfMetric[idx] = 0;
    }
    
    __shared__ int nAssocUeFound;
    uint16_t totNumAssocUeFound = 0;
    bool cnt = true;
    
    while (cnt) {
          if (threadIdx.x == 0) {
            nAssocUeFound = 0;
          }
          __syncthreads();
  
          uIdx = -1;
          
          if (assocUeIdxInBlk < numUePerRnd) {
            int16_t assocUeRank = -1;
            for (int j = 0; j<pDynDescr->nUe; j++) {
                if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                    assocUeRank += 1;
                    if (assocUeRank == realAssocUeIdxInBlk) {
                        uIdx = j;
                        if (prgIdx == 0) {
                            atomicAdd(&nAssocUeFound, 1);
                        }
                        break;
                    }
                }
            }
          }
          __syncthreads();
  
          if (nAssocUeFound < numUePerRnd) {
              cnt = false;
          }
  
          if (uIdx >= 0) {
            float meanSinValSqr = 0; 
            for (uint8_t counter = 0; counter < pDynDescr->nPrbGrp; counter++) {
                meanSinValSqr += pow(pDynDescr->sinVal_asim[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + counter*pDynDescr->nUeAnt], 2.0);
            }
            meanSinValSqr /= static_cast<float>(pDynDescr->nPrbGrp);

            uint16_t tempId = pDynDescr->nPrbGrp*realAssocUeIdxInBlk + prgIdx;

            if (meanSinValSqr == 0) {
                pfMetric[tempId] = 1.0;
            } else {
                pfMetric[tempId] = pow(pDynDescr->sinVal_asim[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + prgIdx*pDynDescr->nUeAnt], 2.0)/meanSinValSqr;
            }
            ueIdxArr[tempId] = pDynDescr->nPrbGrp*uIdx + prgIdx;
  
              if (prgIdx == 0) {
                  pDynDescr->allocSol[uIdx*2] = -1;
                  pDynDescr->allocSol[uIdx*2+1] = -1;
              }
          }
          if (cnt){
              realAssocUeIdxInBlk += numUePerRnd;
          }
          totNumAssocUeFound += nAssocUeFound;
          __syncthreads(); 
    }

    if (totNumAssocUeFound == 0) {
        return;
    }
    
    uint16_t pow2N = 0;
    if (totNumAssocUeFound > 0) {
        pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
    }
    uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;

    // sort all PF metrics for each cell
    bitonicSort(pfMetric, ueIdxArr, pow2N); // internal synchronization

    __shared__ uint16_t   ueIdxS[2048];
    __shared__ uint8_t    prgIdxS[2048];
    __shared__ int16_t    allocSolS[2048];

    for (int idx = threadIdx.x; idx < 2048; idx += blockDim.x) {
        ueIdxS[idx] = ueIdxArr[idx]/pDynDescr->nPrbGrp;
        prgIdxS[idx] = ueIdxArr[idx] - ueIdxS[idx]*pDynDescr->nPrbGrp;
        allocSolS[idx] = -1;
    }
  
    // riding peaks algorithm
    __shared__ uint16_t nAllocated;
    __shared__ uint16_t k;
    __shared__ int16_t  prgResetId;
    
    if (threadIdx.x == 0) {
        nAllocated = 0;
        k = 0;
    }
    __syncthreads(); 

    while(nAllocated < pDynDescr->nPrbGrp && k < pfSize) {
        __syncthreads(); 

        if (threadIdx.x == 0) {
            prgResetId = -1;

            while(k < pfSize) {
                if (pfMetric[k] == 0) {
                    k++;
                    continue;
                }
                
                if (allocSolS[2*ueIdxS[k]] == -1) {
                    pDynDescr->allocSol[2*ueIdxS[k]] = prgIdxS[k];
                    pDynDescr->allocSol[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    allocSolS[2*ueIdxS[k]] = prgIdxS[k];
                    allocSolS[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    prgResetId = prgIdxS[k];
                    nAllocated++;
                    k = 0;
                    break;
                } else if (prgIdxS[k] == (allocSolS[2*ueIdxS[k]] - 1)) {
                    pDynDescr->allocSol[2*ueIdxS[k]] = prgIdxS[k];
                    allocSolS[2*ueIdxS[k]] = prgIdxS[k];
                    prgResetId = prgIdxS[k];
                    nAllocated++;
                    k = 0;
                    break;
                } else if (prgIdxS[k] == allocSolS[2*ueIdxS[k]+1]) {
                    pDynDescr->allocSol[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    allocSolS[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    prgResetId = prgIdxS[k];
                    nAllocated++;
                    k = 0;
                    break;
                } else {
                    k++;
                }   
            }
        }
        __syncthreads(); 

        if (prgResetId < 0) {
            continue;
        }

        for (int idx = threadIdx.x; idx < pfSize; idx += blockDim.x) {
            if (prgIdxS[idx] == prgResetId) {
                pfMetric[idx] = 0;
            }
        }
        __syncthreads(); 
    }    
}

/*
static __global__ void multiCellSchedulerKernel_Asim_type1_svdPrdMmseIrc_rm_harq(mcDynDescr_t* pDynDescr)
{
       // determine indices
  uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
  uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
  uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
  uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
  uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
  uint16_t nPrgBsUeAntPrd       = pDynDescr->nPrbGrp*nBsUeAntPrd;
  uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
  uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
  int16_t  uIdx;
  uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

  // setup data arrays in shared memory
  __shared__ cuComplex  DInvMat[1024];
  __shared__ cuComplex  CMat[1024];
  __shared__ cuComplex  CInvMat[1024];
  __shared__ uint8_t    colIdx[1024];
  __shared__ uint8_t    rowIdx[1024];
  __shared__ uint16_t   CMatIdxTemp[1024];
  __shared__ uint16_t   CMatIdx[1024];
  __shared__ uint8_t    colIdx2[1024];
  __shared__ uint8_t    rowIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp2[1024];
  __shared__ uint16_t   CMatIdx2[1024];
  __shared__ uint16_t   CMatIdxTemp3[1024];
  __shared__ uint16_t   CMatIdx3[1024];
  __shared__ int16_t    ueIdxArr[1024];
  __shared__ float      pfMetric[1024];

  rowIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
  colIdx[threadIdx.x] = eIdx - rowIdx[threadIdx.x]*pDynDescr->nUeAnt;
  CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
  CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

  rowIdx2[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nBsAnt);
  colIdx2[threadIdx.x] = eIdx - rowIdx2[threadIdx.x]*pDynDescr->nBsAnt;
  CMatIdxTemp2[threadIdx.x] = assocUeIdxInBlk*nBsUeAntPrd;
  CMatIdx2[threadIdx.x] = CMatIdxTemp2[threadIdx.x] + eIdx;

  CMatIdxTemp3[threadIdx.x] = assocUeIdxInBlk*nBsAntSqrd;
  CMatIdx3[threadIdx.x] = CMatIdxTemp3[threadIdx.x] + eIdx;

  ueIdxArr[threadIdx.x] = -1;
  pfMetric[threadIdx.x] = 0;

  cuComplex c_coeff;
  cuComplex c_inv_coeff;
  cuComplex d_coeff;
  float     d_multp;
  cuComplex p_coeff;
  cuComplex p_inv_coeff;
  cuComplex l_coeff;

  __shared__ int nAssocUeFound;
  uint16_t totNumAssocUeFound = 0;
  bool cnt = true;
  
  while (cnt) {
    if (threadIdx.x == 0)
        nAssocUeFound = 0;
    __syncthreads();

    uIdx = -1;

    int16_t assocUeRank = -1;
    for (int j = 0; j<pDynDescr->nUe; j++) {

        if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
            assocUeRank += 1;
            if (assocUeRank == realAssocUeIdxInBlk) {
                uIdx = j;
                if (eIdx == 0) {
                    atomicAdd(&nAssocUeFound, 1);
                }
                break;
            }
        }
    }
    __syncthreads();

    if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
        cnt = false;
    }

    if (pDynDescr->prgMsk[cIdx][rbgIdx] == 1) { // PRG available for allocation
        uint32_t hMatStart = uIdx*nPrgBsUeAntPrd + rbgIdx*nBsUeAntPrd;

        // compute C matrix
        if (uIdx >= 0 && eIdx < nUeAntSqrd) {
            CMat[CMatIdx[threadIdx.x]].x = 0;
            CMat[CMatIdx[threadIdx.x]].y = 0;
            for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
                uint16_t l = pDynDescr->cellId[lIdx];

                if (l == cIdx) {
                    continue;
                }
          
                for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                    cuComplex tmp1 = pDynDescr->srsEstChan[l][hMatStart + rowIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                    cuComplex tmp2 = pDynDescr->srsEstChan[l][hMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                    CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                    CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
                }
            }
            if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
                CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
                CInvMat[CMatIdx[threadIdx.x]].x = 1.0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            } else {
                CInvMat[CMatIdx[threadIdx.x]].x = 0;
                CInvMat[CMatIdx[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute inverse of C matrix
        // use CInvMat for storing inverse of C matrix
        for (int col_i=0; col_i < pDynDescr->nUeAnt; col_i++) {
            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] == col_i) {
                    d_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CMat[CMatIdxTemp[threadIdx.x]+rowIdx[threadIdx.x]*pDynDescr->nUeAnt+col_i];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx < nUeAntSqrd) {
                if (rowIdx[threadIdx.x] != col_i) {
                    p_coeff = CMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+colIdx[threadIdx.x]];
                    p_inv_coeff = CInvMat[CMatIdxTemp[threadIdx.x]+col_i*pDynDescr->nUeAnt+colIdx[threadIdx.x]];
                    c_coeff = CMat[CMatIdx[threadIdx.x]];
                    c_inv_coeff = CInvMat[CMatIdx[threadIdx.x]];

                    CMat[CMatIdx[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CMat[CMatIdx[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    CInvMat[CMatIdx[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    CInvMat[CMatIdx[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads();
        }

        // compute H*V
        // reuse DInvMat for storing H*V
        uint32_t vMatStart = uIdx*pDynDescr->nPrbGrp*nBsAntSqrd + rbgIdx*nBsAntSqrd;

        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            DInvMat[CMatIdx2[threadIdx.x]].x = 0;
            DInvMat[CMatIdx2[threadIdx.x]].y = 0;

            for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                cuComplex tmp1 = pDynDescr->srsEstChan[cIdx][hMatStart + j + rowIdx2[threadIdx.x]*pDynDescr->nBsAnt];
                cuComplex tmp2 = pDynDescr->prdMat_asim[vMatStart + colIdx2[threadIdx.x] + j*pDynDescr->nBsAnt];
                DInvMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                DInvMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        // compute (H*V)^H*C^-1
        // reuse CMat for storing (H*V)^H*C^-1
        if (uIdx >= 0 && eIdx < nBsUeAntPrd) {
            CMat[CMatIdx2[threadIdx.x]].x = 0;
            CMat[CMatIdx2[threadIdx.x]].y = 0;
        
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = DInvMat[CMatIdxTemp2[threadIdx.x]+rowIdx[threadIdx.x]+j*pDynDescr->nBsAnt];
                cuComplex tmp2 = CInvMat[CMatIdxTemp[threadIdx.x]+colIdx[threadIdx.x]+j*pDynDescr->nUeAnt];
                CMat[CMatIdx2[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                CMat[CMatIdx2[threadIdx.x]].y += tmp1.x*tmp2.y - tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        // compute (H*V)^H*C^-1*(H*V) + I
        // reuse CInvMat for storing (H*V)^H*C^-1*(H*V) + I
        if (uIdx >= 0) {
            CInvMat[CMatIdx3[threadIdx.x]].x = 0;
            CInvMat[CMatIdx3[threadIdx.x]].y = 0;
            for (int j = 0; j<pDynDescr->nUeAnt; j++) {
                cuComplex tmp1 = CMat[CMatIdxTemp2[threadIdx.x]+j+rowIdx2[threadIdx.x]*pDynDescr->nUeAnt];
                cuComplex tmp2 = DInvMat[CMatIdxTemp2[threadIdx.x]+colIdx2[threadIdx.x]+j*pDynDescr->nBsAnt];
                CInvMat[CMatIdx3[threadIdx.x]].x += tmp1.x*tmp2.x - tmp1.y*tmp2.y;
                CInvMat[CMatIdx3[threadIdx.x]].y += tmp1.x*tmp2.y + tmp2.x*tmp1.y;
            }
        }
        __syncthreads();

        if (uIdx >= 0) {
            if (colIdx2[threadIdx.x] == rowIdx2[threadIdx.x]) {
                CInvMat[CMatIdx3[threadIdx.x]].x += 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].x = 1.0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            } else {
                DInvMat[CMatIdx3[threadIdx.x]].x = 0;
                DInvMat[CMatIdx3[threadIdx.x]].y = 0;
            }
        }
        __syncthreads();

        // compute ((H*V)^H*C^-1*(H*V) + I)^-1
        // use DInvMat for storing ((H*V)^H*C^-1*(H*V) + I)^-1
        for (int col_i=0; col_i < pDynDescr->nBsAnt; col_i++) {
            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] == col_i) {
                    d_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+col_i];
                    d_multp = 1.0/(d_coeff.x*d_coeff.x + d_coeff.y*d_coeff.y);
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_coeff.x*d_coeff.x + c_coeff.y*d_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_coeff.y*d_coeff.x - c_coeff.x*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].x = d_multp * (c_inv_coeff.x*d_coeff.x + c_inv_coeff.y*d_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = d_multp * (c_inv_coeff.y*d_coeff.x - c_inv_coeff.x*d_coeff.y);
                } else {
                    l_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+rowIdx2[threadIdx.x]*pDynDescr->nBsAnt+col_i];
                }
            }
            __syncthreads(); 

            if (uIdx >= 0) {
                if (rowIdx2[threadIdx.x] != col_i) {
                    p_coeff = CInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+colIdx2[threadIdx.x]];
                    p_inv_coeff = DInvMat[CMatIdxTemp3[threadIdx.x]+col_i*pDynDescr->nBsAnt+colIdx2[threadIdx.x]];
                    c_coeff = CInvMat[CMatIdx3[threadIdx.x]];
                    c_inv_coeff = DInvMat[CMatIdx3[threadIdx.x]];

                    CInvMat[CMatIdx3[threadIdx.x]].x = c_coeff.x - (l_coeff.x*p_coeff.x - l_coeff.y*p_coeff.y);
                    CInvMat[CMatIdx3[threadIdx.x]].y = c_coeff.y - (l_coeff.x*p_coeff.y + l_coeff.y*p_coeff.x);
                    DInvMat[CMatIdx3[threadIdx.x]].x = c_inv_coeff.x - (l_coeff.x*p_inv_coeff.x - l_coeff.y*p_inv_coeff.y);
                    DInvMat[CMatIdx3[threadIdx.x]].y = c_inv_coeff.y - (l_coeff.x*p_inv_coeff.y + l_coeff.y*p_inv_coeff.x);  
                }
            }
            __syncthreads(); 
        }

        if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
            float sinrTemp = 1.0/DInvMat[CMatIdxTemp3[threadIdx.x]+eIdx*pDynDescr->nBsAnt+eIdx].x;
            pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp - 1.0;
            sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(sinrTemp)));
            atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
        }
        __syncthreads(); 

        if (uIdx >= 0 && eIdx == 0) {
            if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
                ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;

                if (rbgIdx == 0) {
                    pDynDescr->allocSol[uIdx*2]     = -1;
                    pDynDescr->allocSol[uIdx*2+1]   = -1;
                }
            } else { // the UE is scheduled for re-transmission
                pfMetric[realAssocUeIdxInBlk] = 0;
                ueIdxArr[realAssocUeIdxInBlk] = 0;

                if (rbgIdx == 0) {
                    pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                    pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
                }
            }
        }
    } else { // PRG not available for allocation
        if (uIdx >= 0 && eIdx == 0) {
            pfMetric[realAssocUeIdxInBlk] = 0;
            ueIdxArr[realAssocUeIdxInBlk] = 0;

            if (rbgIdx == 0) {
                if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                    pDynDescr->allocSol[uIdx*2] = -1;
                    pDynDescr->allocSol[uIdx*2+1] = -1;
                } else { // the UE is scheduled for re-transmission
                    pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                    pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
                }
            }
        }
    }

    if (cnt){
        realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
    }
    totNumAssocUeFound += nAssocUeFound;
    __syncthreads(); 
  }
  
  // transfer computed PF metrics from shared memory to global memory
  uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
  uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
  uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
  
  for (int r = 0; r<nRound; r++) {
        uint16_t entry = r*blockDim.x + threadIdx.x;
        if (entry < totNumAssocUeFound) {
            pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
            pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
        }
  }
  __syncthreads();
  if (threadIdx.x == 0) {
        atomicAdd(pDynDescr->numCompleteBlk, 1);
  }

  // preceed when all thread blocks complete compute tasks
  if (totNumAssocUeFound == 0) {
        return;
  }
  
  // perform consecutive PRB allocation by a single thread block per cell
  if (rbgIdx == 0) {
        unsigned int ns = 8;
        while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
            __nanosleep(ns);
            if (ns < 256) {
                ns *= 2;
            }
        }

        // first sort computed PF metrices across all PRBs and all UEs
        uint16_t pow2N = 0;
        if (totNumAssocUeFound > 0) {
            pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
        }
        uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;

        nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
        for (int r = 0; r<nRound; r++) {
            uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
            if (entry < pow2N) {
                pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                pDynDescr->pfIdArr[pfStartCell + entry] = 0;
            }
        }

        // initialize S array
        // Reuse colIdx array in shared memory for S array
        if (threadIdx.x < pDynDescr->nPrbGrp) {
            colIdx[threadIdx.x] = 1;
        } 

        // sort all PF metrics for each cell
        bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization

        // sequential riding peaks algorithm
        if (threadIdx.x == 0) {
            uint16_t nAllocated = 0;
            uint16_t k = 0;

            while(nAllocated < pDynDescr->nPrbGrp) {
                if (k == pfSize)
                    break;

                if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                    k++;
                    continue;
                }

                uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;

                if (colIdx[c] == 0) {
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    k++;
                    continue;
                }

                uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;

                if (pDynDescr->allocSol[2*i] == -1) {
                    pDynDescr->allocSol[2*i] = c;
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == (pDynDescr->allocSol[2*i] - 1)) {
                    pDynDescr->allocSol[2*i] = c;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == pDynDescr->allocSol[2*i+1]) {
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else {
                    k++;
                }   
            }
        }
  }
} */

/*
static __global__ void multiCellSchedulerKernel_Asim_type1_svdPrdMmse_rm_harq(mcDynDescr_t* pDynDescr)
{
    // determine indices
uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
uint16_t nUeAntSqrd           = pDynDescr->nUeAnt*pDynDescr->nUeAnt;
uint16_t nBsUeAntPrd          = pDynDescr->nBsAnt*pDynDescr->nUeAnt;
uint16_t nPrgBsUeAntPrd       = pDynDescr->nPrbGrp*nBsUeAntPrd;
uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
int16_t  uIdx;
uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

// setup data arrays in shared memory
__shared__ cuComplex  DMat[1024];
__shared__ cuComplex  CMat[1024];
__shared__ uint8_t    colIdx[1024];
__shared__ uint8_t    rowIdx[1024];
__shared__ uint16_t   CMatIdxTemp[1024];
__shared__ uint16_t   CMatIdx[1024];
__shared__ int16_t    ueIdxArr[1024];
__shared__ float      pfMetric[1024];

rowIdx[threadIdx.x] = floor(static_cast<float>(eIdx)/pDynDescr->nUeAnt);
colIdx[threadIdx.x] = eIdx - rowIdx[threadIdx.x]*pDynDescr->nUeAnt;
CMatIdxTemp[threadIdx.x] = assocUeIdxInBlk*nUeAntSqrd;
CMatIdx[threadIdx.x] = CMatIdxTemp[threadIdx.x] + eIdx;

ueIdxArr[threadIdx.x] = -1;
pfMetric[threadIdx.x] = 0;

__shared__ int nAssocUeFound;
uint16_t totNumAssocUeFound = 0;
bool cnt = true;

while (cnt) {
 if (threadIdx.x == 0)
     nAssocUeFound = 0;
 __syncthreads();

 uIdx = -1;

 int16_t assocUeRank = -1;
 for (int j = 0; j<pDynDescr->nUe; j++) {
     if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
         assocUeRank += 1;
         if (assocUeRank == realAssocUeIdxInBlk) {
             uIdx = j;
             if (eIdx == 0) {
                 atomicAdd(&nAssocUeFound, 1);
             }
             break;
         }
     }
 }
 __syncthreads();

 if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
     cnt = false;
 }

 if (pDynDescr->prgMsk[cIdx][rbgIdx] == 1) { // PRG available for allocation
     uint32_t hMatStart = uIdx*nPrgBsUeAntPrd + rbgIdx*nBsUeAntPrd;

     // compute C matrix
     if (uIdx >= 0 && eIdx < nUeAntSqrd) {
         CMat[CMatIdx[threadIdx.x]].x = 0;
         CMat[CMatIdx[threadIdx.x]].y = 0;
         for (uint16_t lIdx = 0; lIdx < pDynDescr->nCell; lIdx++) {
             uint16_t l = pDynDescr->cellId[lIdx];

             if (l == cIdx) {
                 continue;
             }
       
             for (int j = 0; j<pDynDescr->nBsAnt; j++) {
                 cuComplex tmp1 = pDynDescr->srsEstChan[l][hMatStart + rowIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                 cuComplex tmp2 = pDynDescr->srsEstChan[l][hMatStart + colIdx[threadIdx.x]*pDynDescr->nBsAnt + j];
                 CMat[CMatIdx[threadIdx.x]].x += tmp1.x*tmp2.x + tmp1.y*tmp2.y;
                 CMat[CMatIdx[threadIdx.x]].y += tmp2.x*tmp1.y - tmp1.x*tmp2.y;
             }
         }
         if (colIdx[threadIdx.x] == rowIdx[threadIdx.x]) {
             CMat[CMatIdx[threadIdx.x]].x += pDynDescr->sigmaSqrd;
         }
     }
     __syncthreads();

     // compute U^H*C
     // use DMat for storing U^H*C
     uint32_t uMatStart = uIdx*pDynDescr->nPrbGrp*nUeAntSqrd + rbgIdx*nUeAntSqrd;
     if (uIdx >= 0 && eIdx < nUeAntSqrd) {
         DMat[CMatIdx[threadIdx.x]].x = 0;
         DMat[CMatIdx[threadIdx.x]].y = 0;

         for (int j = 0; j<pDynDescr->nUeAnt; j++) {
             cuComplex tmp1 = pDynDescr->detMat_asim[uMatStart + j*pDynDescr->nUeAnt + rowIdx[threadIdx.x]];
             cuComplex tmp2 = CMat[CMatIdxTemp[threadIdx.x] + j*pDynDescr->nUeAnt + colIdx[threadIdx.x]];
             DMat[CMatIdx[threadIdx.x]].x = tmp1.x*tmp2.x + tmp1.y*tmp2.y;
             DMat[CMatIdx[threadIdx.x]].y = tmp1.x*tmp2.y - tmp2.x*tmp1.y;
         }
     }
     __syncthreads();

     // compute U^H*C*U
     // reuse CMat for storing U^H*C*U
     if (uIdx >= 0 && eIdx < nUeAntSqrd) {
         CMat[CMatIdx[threadIdx.x]].x = 0;
         CMat[CMatIdx[threadIdx.x]].y = 0;
         for (int j = 0; j<pDynDescr->nUeAnt; j++) {
             cuComplex tmp1 = DMat[CMatIdxTemp[threadIdx.x] + rowIdx[threadIdx.x]*pDynDescr->nUeAnt + j];
             cuComplex tmp2 = pDynDescr->detMat_asim[uMatStart + j*pDynDescr->nUeAnt + colIdx[threadIdx.x]];
             CMat[CMatIdx[threadIdx.x]].x = tmp1.x*tmp2.x - tmp1.y*tmp2.y;
             CMat[CMatIdx[threadIdx.x]].y = tmp1.x*tmp2.y + tmp2.x*tmp1.y;
         }
     }
     __syncthreads();
    
     if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
         float sinrTemp = pow(pDynDescr->sinVal_asim[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx], 2.0)/CMat[CMatIdxTemp[threadIdx.x] + eIdx*pDynDescr->nUeAnt + eIdx].x;
         pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp;
         sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(1.0 + sinrTemp)));
         atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
     }
     __syncthreads(); 

     if (uIdx >= 0 && eIdx == 0) {
         if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
             pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
             ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;

             if (rbgIdx == 0) {
                 pDynDescr->allocSol[uIdx*2]     = -1;
                 pDynDescr->allocSol[uIdx*2+1]   = -1;
             }
         } else { // the UE is scheduled for re-transmission
             pfMetric[realAssocUeIdxInBlk] = 0;
             ueIdxArr[realAssocUeIdxInBlk] = 0;

             if (rbgIdx == 0) {
                 pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                 pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
             }
         }
     }
 } else { // PRG not available for allocation
     if (uIdx >= 0 && eIdx == 0) {
         pfMetric[realAssocUeIdxInBlk] = 0;
         ueIdxArr[realAssocUeIdxInBlk] = 0;

         if (rbgIdx == 0) {
             if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                 pDynDescr->allocSol[uIdx*2] = -1;
                 pDynDescr->allocSol[uIdx*2+1] = -1;
             } else { // the UE is scheduled for re-transmission
                 pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                 pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
             }
         }
     }
 }

 if (cnt){
     realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
 }
 totNumAssocUeFound += nAssocUeFound;
 __syncthreads(); 
}

// transfer computed PF metrics from shared memory to global memory
uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;

for (int r = 0; r<nRound; r++) {
     uint16_t entry = r*blockDim.x + threadIdx.x;
     if (entry < totNumAssocUeFound) {
         pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
         pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
     }
}
__syncthreads();
if (threadIdx.x == 0) {
     atomicAdd(pDynDescr->numCompleteBlk, 1);
}

// preceed when all thread blocks complete compute tasks
if (totNumAssocUeFound == 0) {
     return;
}

// perform consecutive PRB allocation by a single thread block per cell
if (rbgIdx == 0) {
     unsigned int ns = 8;
     while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
         __nanosleep(ns);
         if (ns < 256) {
             ns *= 2;
         }
     }

     // first sort computed PF metrices across all PRBs and all UEs
     uint16_t pow2N = 0;
     if (totNumAssocUeFound > 0) {
         pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
     }
     uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;

     nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
     for (int r = 0; r<nRound; r++) {
         uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
         if (entry < pow2N) {
             pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
             pDynDescr->pfIdArr[pfStartCell + entry] = 0;
         }
     }

     // initialize S array
     // Reuse colIdx array in shared memory for S array
     if (threadIdx.x < pDynDescr->nPrbGrp) {
         colIdx[threadIdx.x] = 1;
     } 

     // sort all PF metrics for each cell
     bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization

     // sequential riding peaks algorithm
     if (threadIdx.x == 0) {
         uint16_t nAllocated = 0;
         uint16_t k = 0;

         while(nAllocated < pDynDescr->nPrbGrp) {
             if (k == pfSize)
                 break;

             if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                 k++;
                 continue;
             }

             uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;

             if (colIdx[c] == 0) {
                 pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                 k++;
                 continue;
             }

             uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;

             if (pDynDescr->allocSol[2*i] == -1) {
                 pDynDescr->allocSol[2*i] = c;
                 pDynDescr->allocSol[2*i+1] = c + 1;
                 colIdx[c] = 0;
                 pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                 nAllocated++;
                 k = 0;
             } else if (c == (pDynDescr->allocSol[2*i] - 1)) {
                 pDynDescr->allocSol[2*i] = c;
                 colIdx[c] = 0;
                 pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                 nAllocated++;
                 k = 0;
             } else if (c == pDynDescr->allocSol[2*i+1]) {
                 pDynDescr->allocSol[2*i+1] = c + 1;
                 colIdx[c] = 0;
                 pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                 nAllocated++;
                 k = 0;
             } else {
                 k++;
             }   
         }
     }
}
} */

static __global__ void multiCellSchedulerKernel_Asim_type1_wbSinr_harq(mcDynDescr_t* pDynDescr)
{
    // determine indices
    uint16_t numUePerRnd          = floor(static_cast<float>(blockDim.x)/pDynDescr->nPrbGrp);
    uint16_t cIdx                 = blockIdx.x;
    uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/pDynDescr->nPrbGrp);
    uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
    int16_t  uIdx;
    uint16_t prgIdx = threadIdx.x - assocUeIdxInBlk*pDynDescr->nPrbGrp; // entry index in matrix
  
    // setup data arrays in shared memory
    __shared__ uint16_t   ueIdxArr[2048];
    __shared__ float      pfMetric[2048];
    
    for (int idx = threadIdx.x; idx < 2048; idx += blockDim.x) {
        ueIdxArr[idx] = 0xFFFF;
        pfMetric[idx] = 0;
    }
    
    __shared__ int nAssocUeFound;
    uint16_t totNumAssocUeFound = 0;
    bool cnt = true;
    
    while (cnt) {
        if (threadIdx.x == 0) {
            nAssocUeFound = 0;
        }
        __syncthreads();
  
        uIdx = -1;
          
        if (assocUeIdxInBlk < numUePerRnd) {
            int16_t assocUeRank = -1;
            for (int j = 0; j<pDynDescr->nUe; j++) {
                if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                    assocUeRank += 1;
                    if (assocUeRank == realAssocUeIdxInBlk) {
                        uIdx = j;
                        if (prgIdx == 0) {
                            atomicAdd(&nAssocUeFound, 1);
                        }
                        break;
                    }
                }
            }
        }
        __syncthreads();
  
        if (nAssocUeFound < numUePerRnd) {
            cnt = false;
        }

        uint16_t tempId = pDynDescr->nPrbGrp*realAssocUeIdxInBlk + prgIdx;

        if (pDynDescr->prgMsk[cIdx][prgIdx] == 1) { // PRG available for allocation
            if (uIdx >= 0) {
                float meanSinValSqr = 0; 
                for (uint8_t counter = 0; counter < pDynDescr->nPrbGrp; counter++) {
                    meanSinValSqr += pow(pDynDescr->sinVal_asim[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + counter*pDynDescr->nUeAnt], 2.0);
                }
                meanSinValSqr /= static_cast<float>(pDynDescr->nPrbGrp);

                if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                    if (meanSinValSqr == 0) {
                        pfMetric[tempId] = 1.0;
                    } else {
                        pfMetric[tempId] = pow(pDynDescr->sinVal_asim[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + prgIdx*pDynDescr->nUeAnt], 2.0)/meanSinValSqr;
                    }
                    ueIdxArr[tempId] = pDynDescr->nPrbGrp*uIdx + prgIdx;
  
                    if (prgIdx == 0) {
                        pDynDescr->allocSol[uIdx*2] = -1;
                        pDynDescr->allocSol[uIdx*2+1] = -1;
                    }
                } else { // the UE is scheduled for re-transmission
                    pfMetric[tempId] = 0;
                    ueIdxArr[tempId] = 0;

                    if (prgIdx == 0) {
                        pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                        pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
                    }
                }
            }
        } else { // PRG not available for allocation
            if (uIdx >= 0) {
                pfMetric[tempId] = 0;
                ueIdxArr[tempId] = 0;
                
                if (prgIdx == 0) {
                    if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                        pDynDescr->allocSol[uIdx*2] = -1;
                        pDynDescr->allocSol[uIdx*2+1] = -1;
                    } else { // the UE is scheduled for re-transmission
                        pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                        pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
                    }
                }
            }
        }

        if (cnt){
            realAssocUeIdxInBlk += numUePerRnd;
        }
        totNumAssocUeFound += nAssocUeFound;
        __syncthreads(); 
    }

    if (totNumAssocUeFound == 0) {
        return;
    }
    
    uint16_t pow2N = 0;
    if (totNumAssocUeFound > 0) {
        pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
    }
    uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;

    // sort all PF metrics for each cell
    bitonicSort(pfMetric, ueIdxArr, pow2N); // internal synchronization

    __shared__ uint16_t   ueIdxS[2048];
    __shared__ uint8_t    prgIdxS[2048];
    __shared__ int16_t    allocSolS[2048];

    for (int idx = threadIdx.x; idx < 2048; idx += blockDim.x) {
        ueIdxS[idx] = ueIdxArr[idx]/pDynDescr->nPrbGrp;
        prgIdxS[idx] = ueIdxArr[idx] - ueIdxS[idx]*pDynDescr->nPrbGrp;
        allocSolS[idx] = -1;
    }
  
    // riding peaks algorithm
    __shared__ uint16_t nAllocated;
    __shared__ uint16_t k;
    __shared__ int16_t  prgResetId;
    
    if (threadIdx.x == 0) {
        nAllocated = 0;
        k = 0;
    }
    __syncthreads(); 

    while(nAllocated < pDynDescr->nPrbGrp && k < pfSize) {
        __syncthreads(); 

        if (threadIdx.x == 0) {
            prgResetId = -1;

            while(k < pfSize) {
                if (pfMetric[k] == 0) {
                    k++;
                    continue;
                }
                
                if (allocSolS[2*ueIdxS[k]] == -1) {
                    pDynDescr->allocSol[2*ueIdxS[k]] = prgIdxS[k];
                    pDynDescr->allocSol[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    allocSolS[2*ueIdxS[k]] = prgIdxS[k];
                    allocSolS[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    prgResetId = prgIdxS[k];
                    nAllocated++;
                    k = 0;
                    break;
                } else if (prgIdxS[k] == (allocSolS[2*ueIdxS[k]] - 1)) {
                    pDynDescr->allocSol[2*ueIdxS[k]] = prgIdxS[k];
                    allocSolS[2*ueIdxS[k]] = prgIdxS[k];
                    prgResetId = prgIdxS[k];
                    nAllocated++;
                    k = 0;
                    break;
                } else if (prgIdxS[k] == allocSolS[2*ueIdxS[k]+1]) {
                    pDynDescr->allocSol[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    allocSolS[2*ueIdxS[k]+1] = prgIdxS[k] + 1;
                    prgResetId = prgIdxS[k];
                    nAllocated++;
                    k = 0;
                    break;
                } else {
                    k++;
                }   
            }
        }
        __syncthreads(); 

        if (prgResetId < 0) {
            continue;
        }

        for (int idx = threadIdx.x; idx < pfSize; idx += blockDim.x) {
            if (prgIdxS[idx] == prgResetId) {
                pfMetric[idx] = 0;
            }
        }
        __syncthreads(); 
    }  
}

//---------------------------- UL kernels ----------------------------------
static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_type1_svdPrdMmseIrc_harq_UL(mcDynDescr_t* pDynDescr)
{
    // determine indices
    uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
    uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
    uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
    uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
    uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
    int16_t  uIdx;
    uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix

    // setup data arrays in shared memory
    __shared__ uint8_t    colIdx[1024];
    __shared__ int16_t    ueIdxArr[1024];
    __shared__ float      pfMetric[1024];

    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;

    __shared__ int nAssocUeFound;
    uint16_t totNumAssocUeFound = 0;
    bool cnt = true;

    while (cnt) {
        if (threadIdx.x == 0)
            nAssocUeFound = 0;
        __syncthreads();

        uIdx = -1;

        int16_t assocUeRank = -1;
        for (int j = 0; j<pDynDescr->nUe; j++) {
            /*
            if (pDynDescr->setSchdUePerCellTTI[j] == 0xFFFF) {
                continue;
            }
            */

            if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                assocUeRank += 1;
                if (assocUeRank == realAssocUeIdxInBlk) {
                    uIdx = j;
                    if (eIdx == 0) {
                        atomicAdd(&nAssocUeFound, 1);
                    }
                    break;
                }
            }
        }
        __syncthreads();

        if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
            cnt = false;
        }

        if (pDynDescr->prgMsk[cIdx][rbgIdx] == 1) { // PRG available for allocation
            if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
                float sinrTemp = pow(pDynDescr->sinVal[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx], 2.0)/pDynDescr->sigmaSqrd;
                pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp;
                sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(1.0 + sinrTemp)));
                atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
            }
            __syncthreads(); 

            if (uIdx >= 0 && eIdx == 0) {
                if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                    if (pfMetric[realAssocUeIdxInBlk] == 0) {
                        pfMetric[realAssocUeIdxInBlk] = pow(1.0, pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
                    } else {
                        pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
                    }
                    ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;

                    if (rbgIdx == 0) {
                        pDynDescr->allocSol[uIdx*2]     = -1;
                        pDynDescr->allocSol[uIdx*2+1]   = -1;
                    }
                } else { // the UE is scheduled for re-transmission
                    pfMetric[realAssocUeIdxInBlk] = 0;
                    ueIdxArr[realAssocUeIdxInBlk] = 0;

                    if (rbgIdx == 0) {
                        pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                        pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
                    }
                }
            }
        } else { // PRG not available for allocation
            if (uIdx >= 0 && eIdx == 0) {
                pfMetric[realAssocUeIdxInBlk] = 0;
                ueIdxArr[realAssocUeIdxInBlk] = 0;

                if (rbgIdx == 0) {
                    if (pDynDescr->newDataActUe[pDynDescr->setSchdUePerCellTTI[uIdx]] == 1) { // the UE is scheduled for new transmission
                        pDynDescr->allocSol[uIdx*2] = -1;
                        pDynDescr->allocSol[uIdx*2+1] = -1;
                    } else { // the UE is scheduled for re-transmission
                        pDynDescr->allocSol[uIdx*2]     = pDynDescr->allocSolLastTx[uIdx*2];
                        pDynDescr->allocSol[uIdx*2+1]   = pDynDescr->allocSolLastTx[uIdx*2+1];
                    }
                }
            }
        }

        if (cnt){
            realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
        }
        totNumAssocUeFound += nAssocUeFound;
        __syncthreads(); 
    }

    // transfer computed PF metrics from shared memory to global memory
    uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
    uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
    uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;

    for (int r = 0; r<nRound; r++) {
        uint16_t entry = r*blockDim.x + threadIdx.x;
        if (entry < totNumAssocUeFound) {
            pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
            pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
        }
    }
    __syncthreads();
    if (threadIdx.x == 0) {
        atomicAdd(pDynDescr->numCompleteBlk, 1);
    }

    // preceed when all thread blocks complete compute tasks
    if (totNumAssocUeFound == 0) {
        return;
    }

    // perform consecutive PRB allocation by a single thread block per cell
    if (rbgIdx == 0) {
        unsigned int ns = 8;
        while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
            __nanosleep(ns);
            if (ns < 256) {
                ns *= 2;
            }
        }

        // first sort computed PF metrices across all PRBs and all UEs
        uint16_t pow2N = 0;
        if (totNumAssocUeFound > 0) {
            pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
        }
        uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;

        nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
        for (int r = 0; r<nRound; r++) {
            uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
            if (entry < pow2N) {
                pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                pDynDescr->pfIdArr[pfStartCell + entry] = 0;
            }
        }

        // initialize S array
        // Reuse colIdx array in shared memory for S array
        if (threadIdx.x < pDynDescr->nPrbGrp) {
            colIdx[threadIdx.x] = 1;
        } 

        // sort all PF metrics for each cell
        bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization

        // sequential riding peaks algorithm
        if (threadIdx.x == 0) {
            uint16_t nAllocated = 0;
            uint16_t k = 0;

            while(nAllocated < pDynDescr->nPrbGrp) {
                if (k == pfSize)
                    break;

                if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                    k++;
                    continue;
                }

                uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;

                if (colIdx[c] == 0) {
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    k++;
                    continue;
                }

                uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;

                if (pDynDescr->allocSol[2*i] == -1) {
                    pDynDescr->allocSol[2*i] = c;
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == (pDynDescr->allocSol[2*i] - 1)) {
                    pDynDescr->allocSol[2*i] = c;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else if (c == pDynDescr->allocSol[2*i+1]) {
                    pDynDescr->allocSol[2*i+1] = c + 1;
                    colIdx[c] = 0;
                    pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                    nAllocated++;
                    k = 0;
                } else {
                    k++;
                }   
            }
        }
    }
}
    
static __global__ __launch_bounds__ (1024, MinBlkPerSM_) void multiCellSchedulerKernel_type1_svdPrdMmseIrc_UL(mcDynDescr_t* pDynDescr)
{
    // determine indices
    uint16_t rbgIdx               = floor(static_cast<float>(blockIdx.x)/pDynDescr->nCell);
    uint16_t cIdx                 = pDynDescr->cellId[blockIdx.x - rbgIdx*pDynDescr->nCell];
    uint16_t nBsAntSqrd           = pDynDescr->nBsAnt*pDynDescr->nBsAnt;
    uint16_t assocUeIdxInBlk      = floor(static_cast<float>(threadIdx.x)/nBsAntSqrd);
    uint16_t realAssocUeIdxInBlk  = assocUeIdxInBlk;
    int16_t  uIdx;
    uint16_t eIdx = threadIdx.x - assocUeIdxInBlk*nBsAntSqrd; // entry index in matrix
  
    // setup data arrays in shared memory
    __shared__ uint8_t    colIdx[1024];
    __shared__ int16_t    ueIdxArr[1024];
    __shared__ float      pfMetric[1024];
  
    ueIdxArr[threadIdx.x] = -1;
    pfMetric[threadIdx.x] = 0;
  
    __shared__ int nAssocUeFound;
    uint16_t totNumAssocUeFound = 0;
    bool cnt = true;
    
    while (cnt) {
          if (threadIdx.x == 0)
              nAssocUeFound = 0;
          __syncthreads();
  
          uIdx = -1;
  
          int16_t assocUeRank = -1;
          for (int j = 0; j<pDynDescr->nUe; j++) {
              if (pDynDescr->cellAssoc[cIdx*pDynDescr->nUe + j]) {
                  assocUeRank += 1;
                  if (assocUeRank == realAssocUeIdxInBlk) {
                      uIdx = j;
                      if (eIdx == 0) {
                          atomicAdd(&nAssocUeFound, 1);
                      }
                      break;
                  }
              }
          }
          __syncthreads();
  
          if (nAssocUeFound < pDynDescr->nMaxSchdUePerRnd) {
              cnt = false;
          }

          if (uIdx >= 0 && eIdx < pDynDescr->nUeAnt) {
              float sinrTemp = pow(pDynDescr->sinVal[uIdx*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx], 2.0)/pDynDescr->sigmaSqrd;
              pDynDescr->postEqSinr[pDynDescr->setSchdUePerCellTTI[uIdx]*pDynDescr->nPrbGrp*pDynDescr->nUeAnt + rbgIdx*pDynDescr->nUeAnt + eIdx] = sinrTemp;
              sinrTemp = pDynDescr->W*static_cast<float>(log2(static_cast<double>(1.0 + sinrTemp)));
              atomicAdd(&pfMetric[realAssocUeIdxInBlk], sinrTemp);
          }
          __syncthreads(); 

          if (uIdx >= 0 && eIdx == 0) {
              if (pfMetric[realAssocUeIdxInBlk] == 0) {
                  pfMetric[realAssocUeIdxInBlk] = pow(1.0, pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
              } else {
                pfMetric[realAssocUeIdxInBlk] = pow(pfMetric[realAssocUeIdxInBlk], pDynDescr->betaCoeff)/pDynDescr->avgRates[uIdx];
              }
              ueIdxArr[realAssocUeIdxInBlk] = pDynDescr->nPrbGrp*uIdx + rbgIdx;
  
              if (rbgIdx == 0) {
                  pDynDescr->allocSol[uIdx*2] = -1;
                  pDynDescr->allocSol[uIdx*2+1] = -1;
              }
          }
          if (cnt){
              realAssocUeIdxInBlk += pDynDescr->nMaxSchdUePerRnd;
          }
          totNumAssocUeFound += nAssocUeFound;
          __syncthreads(); 
    }
    
    // transfer computed PF metrics from shared memory to global memory
    uint16_t nRound       = (totNumAssocUeFound - 1)/blockDim.x + 1;
    uint32_t pfStartCell  = (blockIdx.x - rbgIdx*pDynDescr->nCell)*pow2NArr[pDynDescr->numUeSchdPerCellTTI-1][pDynDescr->nPrbGrp-1];
    uint32_t pfStart      = pfStartCell + rbgIdx*totNumAssocUeFound;
    
    for (int r = 0; r<nRound; r++) {
          uint16_t entry = r*blockDim.x + threadIdx.x;
          if (entry < totNumAssocUeFound) {
              pDynDescr->pfMetricArr[pfStart + entry] = pfMetric[entry];
              pDynDescr->pfIdArr[pfStart + entry] = ueIdxArr[entry];
          }
    }
    __syncthreads();
    if (threadIdx.x == 0) {
          atomicAdd(pDynDescr->numCompleteBlk, 1);
    }
  
    // preceed when all thread blocks complete compute tasks
    if (totNumAssocUeFound == 0) {
          return;
    }
    
    // perform consecutive PRB allocation by a single thread block per cell
    if (rbgIdx == 0) {
          unsigned int ns = 8;
          while (atomicCAS(pDynDescr->numCompleteBlk, gridDim.x, gridDim.x) < gridDim.x) {
              __nanosleep(ns);
              if (ns < 256) {
                  ns *= 2;
              }
          }
  
          // first sort computed PF metrices across all PRBs and all UEs
          uint16_t pow2N = 0;
          if (totNumAssocUeFound > 0) {
              pow2N = pow2NArr[totNumAssocUeFound-1][pDynDescr->nPrbGrp-1];
          }
          uint16_t pfSize = totNumAssocUeFound*pDynDescr->nPrbGrp;
  
          nRound = (pow2N - pfSize - 1)/blockDim.x + 1;
          for (int r = 0; r<nRound; r++) {
              uint16_t entry = pfSize + r*blockDim.x + threadIdx.x;
              if (entry < pow2N) {
                  pDynDescr->pfMetricArr[pfStartCell + entry] = 0;
                  pDynDescr->pfIdArr[pfStartCell + entry] = 0;
              }
          }
  
          // initialize S array
          // Reuse colIdx array in shared memory for S array
          if (threadIdx.x < pDynDescr->nPrbGrp) {
              colIdx[threadIdx.x] = 1;
          } 
  
          // sort all PF metrics for each cell
          bitonicSort(&pDynDescr->pfMetricArr[pfStartCell], &pDynDescr->pfIdArr[pfStartCell], pow2N); // internal synchronization
  
          // sequential riding peaks algorithm
          if (threadIdx.x == 0) {
              uint16_t nAllocated = 0;
              uint16_t k = 0;
  
              while(nAllocated < pDynDescr->nPrbGrp) {
                  if (k == pfSize)
                      break;
  
                  if (pDynDescr->pfMetricArr[pfStartCell+k] == 0) {
                      k++;
                      continue;
                  }
  
                  uint16_t c = pDynDescr->pfIdArr[pfStartCell+k]%pDynDescr->nPrbGrp;
  
                  if (colIdx[c] == 0) {
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      k++;
                      continue;
                  }
  
                  uint16_t i = pDynDescr->pfIdArr[pfStartCell+k]/pDynDescr->nPrbGrp;
  
                  if (pDynDescr->allocSol[2*i] == -1) {
                      pDynDescr->allocSol[2*i] = c;
                      pDynDescr->allocSol[2*i+1] = c + 1;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else if (c == (pDynDescr->allocSol[2*i] - 1)) {
                      pDynDescr->allocSol[2*i] = c;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else if (c == pDynDescr->allocSol[2*i+1]) {
                      pDynDescr->allocSol[2*i+1] = c + 1;
                      colIdx[c] = 0;
                      pDynDescr->pfMetricArr[pfStartCell+k] = 0;
                      nAllocated++;
                      k = 0;
                  } else {
                      k++;
                  }   
              }
          }
    }
}

void multiCellScheduler::kernelSelect()
{
  void* kernelFunc;
  if (DL == 1) { // for DL
    if (Asim == 1) { // Aerial Sim
        if (columnMajor == 1 || allocType == 0) {
            throw std::runtime_error("Error: For Aerial Sim, multi-cell scheduler is only supported for type-1 allocation and row-major channel access.");
        }

        if (halfPrecision == 1) {
            throw std::runtime_error("Error: For Aerial Sim, half-precision (FP16) multi-cell scheduler kernel is not available yet.");
        }

        if (lightWeight > 0) { // use lightweight kernel
            throw std::runtime_error("Error: lightweight kernel for Aerial Sim is not available yet.");
        }

        if (enableHarq == 1) { // HARQ enabled
            kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_Asim_type1_wbSinr_harq);
        } else {
            kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_Asim_type1_wbSinr);
        }
    } else {
        if (enableHarq == 1) { // HARQ enabled
            throw std::runtime_error("Error: For DL, HARQ-enabled multi-cell scheduler kernel is only supported for Aerial Sim.");
        }

        switch (precodingScheme) {
            case 0: // no precoding
                if (allocType == 1) {
                    if (lightWeight > 0) { // use lightweight kernel
                        throw std::runtime_error("Error: lightweight kernel for type-1 allocation is not available yet.");
                    }

                    if (columnMajor) {
                        kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_type1_NoPrdMmseIrc_cm);
                    } else {
                        kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_type1_NoPrdMmseIrc_rm);
                    }
                } else {
                    if (columnMajor) {
                        if (halfPrecision == 1) { // half-precision
                            if (lightWeight > 0) { // use lightweight kernel
                                throw std::runtime_error("Error: lightweight kernel for half-precision is not available yet.");
                            } else {
                                kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_half_noPrdMmseIrc);
                            }
                        } else { // floating type
                            if (lightWeight == 1) { // use SINR computation based lightweight kernel
                                kernelFunc = reinterpret_cast<void*>(lwPfSchedulerKernel_noPrdSinrCompute);
                            } else if (lightWeight == 2) { // use SINR loading based lightweight kernel
                                kernelFunc = reinterpret_cast<void*>(lwPfSchedulerKernel_noPrdSinrLoad);
                            } else {
                                kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_noPrdMmseIrc);
                            }
                        }
                    } else {
                        throw std::runtime_error("Error: row-major channel matrix access for type-0 allocation not supported");
                    }
                }
                break;
            case 1: // SVD precoding
                if (lightWeight > 0) { // use lightweight kernel
                    throw std::runtime_error("Error: lightweight kernel for SVD precoding is not available yet.");
                }

                if (allocType) {
                    if (columnMajor) {
                        kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_type1_svdPrdMmseIrc_cm);
                    } else {
                        throw std::runtime_error("Error: row-major channel matrix access for type-1 allocation with SVD precoder not supported");
                    }    
                } else {
                    if (columnMajor) {
                        kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_svdMmseIrc);
                    } else {
                        throw std::runtime_error("Error: row-major channel matrix access for type-0 allocation not supported");
                    }
                }
                break;
            default: // default no precoding with allocate type 0 (non-consecutive)
                kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_noPrdMmseIrc);
                break;
        } 
    }
  } else { // for UL
    if (allocType == 0) {
        throw std::runtime_error("Error: For UL, multi-cell scheduler is only supported for type-1 PRB allocation.");
    }

    if (halfPrecision == 1) {
        throw std::runtime_error("Error: For UL, half-precision (FP16) multi-cell scheduler kernel is not available yet.");
    }

    if (lightWeight > 0) {
        throw std::runtime_error("Error: For UL, light-weight scheduler kernel is not available yet.");
    }

    if (Asim == 1) { // Aerial Sim
        if (enableHarq == 1) { // HARQ enabled
            kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_type1_svdPrdMmseIrc_harq_UL);
        } else {
            kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_type1_svdPrdMmseIrc_UL);
        }
    } else {
        if (precodingScheme == 0) {
            throw std::runtime_error("Error: For UL, multi-cell scheduler is only supported for SVD precoding.");
        }

        if (enableHarq == 1) { // HARQ enabled
            throw std::runtime_error("Error: For UL, HARQ-enabled multi-cell scheduler kernel is only supported for Aerial Sim.");
        } else {
            kernelFunc = reinterpret_cast<void*>(multiCellSchedulerKernel_type1_svdPrdMmseIrc_UL);
        }
    }
  }

  CUDA_CHECK_ERR(cudaGetFuncBySymbol(&pLaunchCfg->kernelNodeParamsDriver.func, kernelFunc));

  // launch geometry
  gridDim  = {numThrdBlk, 1, 1};
  blockDim = {numThrdPerBlk, 1, 1};

  // populate kernel parameters
  CUDA_KERNEL_NODE_PARAMS& kernelNodeParamsDriver = pLaunchCfg->kernelNodeParamsDriver;

  kernelNodeParamsDriver.blockDimX = blockDim.x;
  kernelNodeParamsDriver.blockDimY = blockDim.y;
  kernelNodeParamsDriver.blockDimZ = blockDim.z;

  kernelNodeParamsDriver.gridDimX = gridDim.x;
  kernelNodeParamsDriver.gridDimY = gridDim.y;
  kernelNodeParamsDriver.gridDimZ = gridDim.z;

  kernelNodeParamsDriver.extra          = nullptr;
  kernelNodeParamsDriver.sharedMemBytes = 0;
}

// default setup() function
void multiCellScheduler::setup(cumacCellGrpUeStatus*       cellGrpUeStatus,
                               cumacSchdSol*        schdSol,
                               cumacCellGrpPrms*    cellGrpPrms,
                               cumacSimParam*       simParam,
                               uint8_t              in_columnMajor,
                               uint8_t              in_halfPrecision,
                               uint8_t              in_lightWeight,
                               float                in_percSmNumThrdBlk,
                               cudaStream_t         strm)
{
  if (cellGrpPrms->allocType == 0) {
    const size_t allocBytes = static_cast<size_t>(simParam->totNumCell) *
                              static_cast<size_t>(cellGrpPrms->nPrbGrp) *
                              sizeof(int16_t);
    CUDA_CHECK_ERR(cudaMemsetAsync(schdSol->allocSol, 0xFF, allocBytes, strm));
  }

  pCpuDynDesc->setSchdUePerCellTTI  = schdSol->setSchdUePerCellTTI;
  pCpuDynDesc->postEqSinr           = cellGrpPrms->postEqSinr;
  pCpuDynDesc->totNumCell           = simParam->totNumCell; // number of all cells in the network. (not needed if channel buffer only contains channels within coordinated cells)
  pCpuDynDesc->cellId               = cellGrpPrms->cellId;  
  pCpuDynDesc->avgRates             = cellGrpUeStatus->avgRates;
  pCpuDynDesc->allocSol             = schdSol->allocSol;
  pCpuDynDesc->pfMetricArr          = schdSol->pfMetricArr;
  pCpuDynDesc->pfIdArr              = schdSol->pfIdArr;
  pCpuDynDesc->cellAssoc            = cellGrpPrms->cellAssoc;
  pCpuDynDesc->nUe                  = cellGrpPrms->nUe; // total number of UEs
  pCpuDynDesc->nCell                = cellGrpPrms->nCell; // number of coordinated cells
  pCpuDynDesc->nPrbGrp              = cellGrpPrms->nPrbGrp;
  pCpuDynDesc->nBsAnt               = cellGrpPrms->nBsAnt;
  pCpuDynDesc->nUeAnt               = cellGrpPrms->nUeAnt;
  pCpuDynDesc->W                    = cellGrpPrms->W;
  pCpuDynDesc->sigmaSqrd            = cellGrpPrms->sigmaSqrd;
  pCpuDynDesc->numUeSchdPerCellTTI  = cellGrpPrms->numUeSchdPerCellTTI;
  pCpuDynDesc->nMaxSchdUePerRnd     = floor(1024.0/(cellGrpPrms->nBsAnt*cellGrpPrms->nBsAnt));
  pCpuDynDesc->numCompleteBlk       = numCompleteBlk_d;
  allocType                         = cellGrpPrms->allocType;
  precodingScheme                   = cellGrpPrms->precodingScheme;
  pCpuDynDesc->betaCoeff            = cellGrpPrms->betaCoeff;
  pCpuDynDesc->sinVal               = cellGrpPrms->sinVal;
  columnMajor                       = in_columnMajor;
  halfPrecision                     = in_halfPrecision;
  lightWeight                       = in_lightWeight;
  pCpuDynDesc->srsEstChan           = nullptr;
  pCpuDynDesc->prdMat_asim          = nullptr;
  pCpuDynDesc->detMat_asim          = nullptr;
  pCpuDynDesc->sinVal_asim          = nullptr;
  percSmNumThrdBlk                  = in_percSmNumThrdBlk;

  if (percSmNumThrdBlk <= 0) {
    throw std::runtime_error("Error: number of thread blocks for lightweight kernels - percSmNumThrdBlk must be greater than 0");
  }
  
  if (DL == 1) { // DL
    pCpuDynDesc->estH_fr            = cellGrpPrms->estH_fr;
    pCpuDynDesc->estH_fr_half       = cellGrpPrms->estH_fr_half;
    pCpuDynDesc->prdMat             = cellGrpPrms->prdMat;
    pCpuDynDesc->detMat             = cellGrpPrms->detMat;
  } else { // UL
    pCpuDynDesc->estH_fr            = nullptr;
    pCpuDynDesc->estH_fr_half       = nullptr;
    pCpuDynDesc->prdMat             = nullptr;
    pCpuDynDesc->detMat             = nullptr;
  }

  if (enableHarq == 1) { // HARQ enabled
    pCpuDynDesc->newDataActUe       = cellGrpUeStatus->newDataActUe;
    pCpuDynDesc->allocSolLastTx     = cellGrpUeStatus->allocSolLastTx;
    pCpuDynDesc->prgMsk             = cellGrpPrms->prgMsk;
  } else {
    pCpuDynDesc->newDataActUe       = nullptr;
    pCpuDynDesc->allocSolLastTx     = nullptr;
    pCpuDynDesc->prgMsk             = nullptr;
  }

  if (lightWeight == 2) { // call (SINR loading based) light-weight kernel
     numThrdPerBlk = cellGrpPrms->numUeSchdPerCellTTI;
  } else {
     numThrdPerBlk = cellGrpPrms->nBsAnt*cellGrpPrms->nBsAnt*pCpuDynDesc->nMaxSchdUePerRnd;
  }  

  if (allocType == 1) { // type-1 allocation 
     numThrdBlk = cellGrpPrms->nPrbGrp*cellGrpPrms->nCell;
     CUDA_CHECK_ERR(cudaMemcpyAsync(numCompleteBlk_d, numCompleteBlk_h.data(), sizeof(int), cudaMemcpyHostToDevice, strm));
  } else { // type-0 allocation
     if (lightWeight > 0) { // lightweight kernels
        numThrdBlk = percSmNumThrdBlk*numSM;
        numThrdBlk = numThrdBlk > 1 ? numThrdBlk : 1;
     } else {
        numThrdBlk = 2*numSM;
     }
  }
  CUDA_CHECK_ERR(cudaMemcpyAsync(pGpuDynDesc, pCpuDynDesc.get(), sizeof(mcDynDescr_t), cudaMemcpyHostToDevice, strm));

  // select kernel (includes launch geometry). Populate launchCfg.
  kernelSelect();

  pLaunchCfg->kernelArgs[0] = &pGpuDynDesc;
  pLaunchCfg->kernelNodeParamsDriver.kernelParams = &(pLaunchCfg->kernelArgs[0]);
}

// Aerial Sim setup() function
void multiCellScheduler::setup(cumacCellGrpUeStatus*       cellGrpUeStatus,
                               cumacSchdSol*               schdSol,
                               cumacCellGrpPrms*           cellGrpPrms,
                               uint8_t                     in_columnMajor,
                               uint8_t                     in_halfPrecision,
                               cudaStream_t                strm)
{
  if (cellGrpPrms->allocType == 0) {
    const size_t allocBytes = static_cast<size_t>(cellGrpPrms->totNumCell) *
                              static_cast<size_t>(cellGrpPrms->nPrbGrp) *
                              sizeof(int16_t);
    CUDA_CHECK_ERR(cudaMemsetAsync(schdSol->allocSol, 0xFF, allocBytes, strm));
  }

  pCpuDynDesc->setSchdUePerCellTTI  = schdSol->setSchdUePerCellTTI;
  pCpuDynDesc->postEqSinr           = cellGrpPrms->postEqSinr;
  pCpuDynDesc->cellId               = cellGrpPrms->cellId;  
  pCpuDynDesc->avgRates             = cellGrpUeStatus->avgRates;
  pCpuDynDesc->allocSol             = schdSol->allocSol;
  pCpuDynDesc->pfMetricArr          = schdSol->pfMetricArr;
  pCpuDynDesc->pfIdArr              = schdSol->pfIdArr;
  pCpuDynDesc->cellAssoc            = cellGrpPrms->cellAssoc;
  pCpuDynDesc->nUe                  = cellGrpPrms->nUe; // total number of UEs
  pCpuDynDesc->nCell                = cellGrpPrms->nCell; // number of coordinated cells
  pCpuDynDesc->nPrbGrp              = cellGrpPrms->nPrbGrp;
  pCpuDynDesc->nBsAnt               = cellGrpPrms->nBsAnt;
  pCpuDynDesc->nUeAnt               = cellGrpPrms->nUeAnt;
  pCpuDynDesc->W                    = cellGrpPrms->W;
  pCpuDynDesc->sigmaSqrd            = cellGrpPrms->sigmaSqrd;
  pCpuDynDesc->numUeSchdPerCellTTI  = cellGrpPrms->numUeSchdPerCellTTI;
  pCpuDynDesc->nMaxSchdUePerRnd     = floor(1024.0/(cellGrpPrms->nBsAnt*cellGrpPrms->nBsAnt));
  pCpuDynDesc->numCompleteBlk       = numCompleteBlk_d;
  allocType                         = cellGrpPrms->allocType;
  precodingScheme                   = cellGrpPrms->precodingScheme;
  pCpuDynDesc->betaCoeff            = cellGrpPrms->betaCoeff;
  pCpuDynDesc->sinVal_asim          = cellGrpPrms->sinVal_asim;
  columnMajor                       = in_columnMajor;
  halfPrecision                     = in_halfPrecision;
  pCpuDynDesc->estH_fr              = nullptr;
  pCpuDynDesc->estH_fr_half         = nullptr;
  pCpuDynDesc->prdMat               = nullptr;
  pCpuDynDesc->detMat               = nullptr;

  if (DL == 1) { // DL
    pCpuDynDesc->sinVal               = nullptr;
    pCpuDynDesc->srsEstChan       = cellGrpPrms->srsEstChan;
    pCpuDynDesc->prdMat_asim        = cellGrpPrms->prdMat_asim;
    pCpuDynDesc->detMat_asim        = cellGrpPrms->detMat_asim;

    numThrdPerBlk = 1024;
    numThrdBlk    = cellGrpPrms->nCell;
  } else { // UL
    pCpuDynDesc->sinVal             = cellGrpPrms->sinVal_asim;
    pCpuDynDesc->srsEstChan       = nullptr;
    pCpuDynDesc->prdMat_asim        = nullptr;
    pCpuDynDesc->detMat_asim        = nullptr;

    numThrdPerBlk = cellGrpPrms->nBsAnt*cellGrpPrms->nBsAnt*pCpuDynDesc->nMaxSchdUePerRnd;
    numThrdBlk    = cellGrpPrms->nPrbGrp*cellGrpPrms->nCell;
  }

  if (enableHarq == 1) { // HARQ enabled
    pCpuDynDesc->newDataActUe       = cellGrpUeStatus->newDataActUe;
    pCpuDynDesc->allocSolLastTx     = cellGrpUeStatus->allocSolLastTx;
    pCpuDynDesc->prgMsk             = cellGrpPrms->prgMsk;
  } else {
    pCpuDynDesc->newDataActUe       = nullptr;
    pCpuDynDesc->allocSolLastTx     = nullptr;
    pCpuDynDesc->prgMsk             = nullptr;
  }

  if (allocType) {
    CUDA_CHECK_ERR(cudaMemcpyAsync(numCompleteBlk_d, numCompleteBlk_h.data(), sizeof(int), cudaMemcpyHostToDevice, strm));
  }
  CUDA_CHECK_ERR(cudaMemcpyAsync(pGpuDynDesc, pCpuDynDesc.get(), sizeof(mcDynDescr_t), cudaMemcpyHostToDevice, strm));

  // select kernel (includes launch geometry). Populate launchCfg.
  kernelSelect();

  pLaunchCfg->kernelArgs[0] = &pGpuDynDesc;
  pLaunchCfg->kernelNodeParamsDriver.kernelParams = &(pLaunchCfg->kernelArgs[0]);
}

void multiCellScheduler::debugLog()
{
    printf("********************************************\n");
    printf("** GPU multi-cell PF scheduler parameters:\n\n");
    printf("nUe: %d\n", pCpuDynDesc->nUe);
    printf("nCell: %d\n", pCpuDynDesc->nCell);
    printf("totNumCell: %d\n", pCpuDynDesc->totNumCell);
    printf("nPrbGrp: %d\n", pCpuDynDesc->nPrbGrp);
    printf("nBsAnt: %d\n", pCpuDynDesc->nBsAnt);
    printf("nUeAnt: %d\n", pCpuDynDesc->nUeAnt);
    printf("W: %f\n", pCpuDynDesc->W);
    printf("sigmaSqrd: %4.3e\n", pCpuDynDesc->sigmaSqrd);
    printf("numUeSchdPerCellTTI: %d\n", pCpuDynDesc->numUeSchdPerCellTTI);
    printf("nMaxSchdUePerRnd: %d\n", pCpuDynDesc->nMaxSchdUePerRnd);
    printf("allocType: %d\n", allocType);
    printf("precodingScheme: %d\n", precodingScheme);
    printf("betaCoeff: %f\n", pCpuDynDesc->betaCoeff);
    printf("columnMajor: %d\n", columnMajor);

    uint16_t* log_cellId = new uint16_t[pCpuDynDesc->nCell];
    float* log_avgRates = new float[pCpuDynDesc->nUe];
    uint8_t* log_cellAssoc = new uint8_t[pCpuDynDesc->nCell*pCpuDynDesc->nUe];
    cuComplex* log_estH_fr = new cuComplex[pCpuDynDesc->nCell*pCpuDynDesc->nPrbGrp*pCpuDynDesc->nUe*pCpuDynDesc->nUeAnt*pCpuDynDesc->nBsAnt];

    CUDA_CHECK_ERR(cudaMemcpy(log_cellId, pCpuDynDesc->cellId, pCpuDynDesc->nCell * sizeof(uint16_t), cudaMemcpyDeviceToHost));
    CUDA_CHECK_ERR(cudaMemcpy(log_avgRates, pCpuDynDesc->avgRates, pCpuDynDesc->nUe * sizeof(float), cudaMemcpyDeviceToHost));
    CUDA_CHECK_ERR(cudaMemcpy(log_cellAssoc, pCpuDynDesc->cellAssoc, pCpuDynDesc->nCell*pCpuDynDesc->nUe * sizeof(uint8_t), cudaMemcpyDeviceToHost));
    CUDA_CHECK_ERR(cudaMemcpy(log_estH_fr, pCpuDynDesc->estH_fr, pCpuDynDesc->nCell*pCpuDynDesc->nPrbGrp*pCpuDynDesc->nUe*pCpuDynDesc->nUeAnt*pCpuDynDesc->nBsAnt * sizeof(cuComplex), cudaMemcpyDeviceToHost));

    printf("cellId: ");
    for (int cIdx = 0; cIdx < pCpuDynDesc->nCell; cIdx++) {
        printf("%d ", log_cellId[cIdx]);
    }
    printf("\n");

    printf("avgRates: ");
    for (int uIdx = 0; uIdx < pCpuDynDesc->nUe; uIdx++) {
        printf("%4.3e ", log_avgRates[uIdx]);
    }
    printf("\n");

    int* numAssocUePerCell = new int[pCpuDynDesc->nCell];

    printf("cellAssoc: \n");
    for (int cIdx = 0; cIdx < pCpuDynDesc->nCell; cIdx++) {
        numAssocUePerCell[cIdx] = 0;
        printf("cell %d: ", log_cellId[cIdx]);
        for (int uIdx = 0; uIdx < pCpuDynDesc->nUe; uIdx++) {
            if (log_cellAssoc[cIdx*pCpuDynDesc->nUe + uIdx]) {
                numAssocUePerCell[cIdx]++;
                printf("%d ", uIdx);
            }
        }
        printf("\n");
    }
    printf("\n");

    printf("estH_fr: \n");
    for (int cIdx = 0; cIdx < pCpuDynDesc->nCell; cIdx++) {
        printf("cell %d, ", log_cellId[cIdx]);
        for (int uIdx = 0; uIdx < pCpuDynDesc->nUe; uIdx++) {
            if (log_cellAssoc[cIdx*pCpuDynDesc->nUe + uIdx]) {
                printf("UE %d, PRG 0:\n", uIdx);
                if (columnMajor) { // column major
                    for (int rxAnt = 0; rxAnt < pCpuDynDesc->nUeAnt; rxAnt++) {
                        for (int txAnt = 0 ; txAnt < pCpuDynDesc->nBsAnt; txAnt++) {
                            int index = 0;
                            index += uIdx*pCpuDynDesc->totNumCell*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += log_cellId[cIdx]*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += txAnt*pCpuDynDesc->nUeAnt;
                            index += rxAnt;
                            printf("(%4.3e, %4.3e) ", log_estH_fr[index].x, log_estH_fr[index].y);
                        }
                        printf("\n");
                    }
                } else { // row major
                    for (int rxAnt = 0; rxAnt < pCpuDynDesc->nUeAnt; rxAnt++) {
                        for (int txAnt = 0 ; txAnt < pCpuDynDesc->nBsAnt; txAnt++) {
                            int index = 0;
                            index += uIdx*pCpuDynDesc->totNumCell*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += log_cellId[cIdx]*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += rxAnt*pCpuDynDesc->nBsAnt;
                            index += txAnt;
                            printf("(%4.3e, %4.3e) ", log_estH_fr[index].x, log_estH_fr[index].y);
                        }
                        printf("\n");
                    }
                }
/*
                printf("UE %d, PRG %d:\n", uIdx, pCpuDynDesc->nPrbGrp-1);
                if (columnMajor) { // column major
                    for (int rxAnt = 0; rxAnt < pCpuDynDesc->nUeAnt; rxAnt++) {
                        for (int txAnt = 0 ; txAnt < pCpuDynDesc->nBsAnt; txAnt++) {
                            int index = (pCpuDynDesc->nPrbGrp-1)*pCpuDynDesc->nUe*pCpuDynDesc->totNumCell*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += uIdx*pCpuDynDesc->totNumCell*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += log_cellId[cIdx]*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += txAnt*pCpuDynDesc->nUeAnt;
                            index += rxAnt;
                            printf("(%4.3e, %4.3e) ", log_estH_fr[index].x, log_estH_fr[index].y);
                        }
                        printf("\n");
                    }
                } else { // row major
                    for (int rxAnt = 0; rxAnt < pCpuDynDesc->nUeAnt; rxAnt++) {
                        for (int txAnt = 0 ; txAnt < pCpuDynDesc->nBsAnt; txAnt++) {
                            int index = (pCpuDynDesc->nPrbGrp-1)*pCpuDynDesc->nUe*pCpuDynDesc->totNumCell*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += uIdx*pCpuDynDesc->totNumCell*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += log_cellId[cIdx]*pCpuDynDesc->nBsAnt*pCpuDynDesc->nUeAnt;
                            index += rxAnt*pCpuDynDesc->nBsAnt;
                            index += txAnt;
                            printf("(%4.3e, %4.3e) ", log_estH_fr[index].x, log_estH_fr[index].y);
                        }
                        printf("\n");
                    }
                }
*/
                break;
            }
        }
    }
/*
    if (allocType) {
        printf("Sorted PF metrics: \n");
        uint16_t pow2N = pow2NArr_h[pCpuDynDesc->numUeSchdPerCellTTI-1][pCpuDynDesc->nPrbGrp-1];

        float* log_pfMetricArr = new float[pow2N*pCpuDynDesc->nCell];
        uint16_t* log_pfIdArr = new uint16_t[pow2N*pCpuDynDesc->nCell];

        cudaMemcpy(log_pfMetricArr, pCpuDynDesc->pfMetricArr, sizeof(float)*pow2N*pCpuDynDesc->nCell, cudaMemcpyDeviceToHost);
        cudaMemcpy(log_pfIdArr, pCpuDynDesc->pfIdArr, sizeof(uint16_t)*pow2N*pCpuDynDesc->nCell, cudaMemcpyDeviceToHost);

        for (int cIdx = 0; cIdx < pCpuDynDesc->nCell; cIdx++) {
            uint32_t pfStartCell = cIdx*pow2NArr_h[pCpuDynDesc->numUeSchdPerCellTTI-1][pCpuDynDesc->nPrbGrp-1];
            printf("cell %d: ", cIdx);
            for (int idx = 0; idx < pCpuDynDesc->nPrbGrp*numAssocUePerCell[cIdx]; idx++) {
                printf("(%4.3e, %d) ", log_pfMetricArr[pfStartCell+idx], log_pfIdArr[pfStartCell+idx]);
            }
            printf("\n");
        }
        printf("\n");

        delete log_pfMetricArr;
        delete log_pfIdArr;
    }
*/
    printf("** End of logging \n");
    printf("********************************************\n");
    delete log_cellId;
    delete log_avgRates;
    delete log_cellAssoc;
    delete log_estH_fr;
    delete numAssocUePerCell;
}

void multiCellScheduler::run(cudaStream_t strm)
{
  const CUDA_KERNEL_NODE_PARAMS& kernelNodeParamsDriver = pLaunchCfg->kernelNodeParamsDriver;

  #ifdef SCHEDULER_KERNEL_TIME_MEASURE_
  cudaEvent_t start, stop;
  CUDA_CHECK_ERR(cudaEventCreate(&start));
  CUDA_CHECK_ERR(cudaEventCreate(&stop));
  float milliseconds = 0;
  CUDA_CHECK_ERR(cudaEventRecord(start));
  for (int exeIdx = 0; exeIdx < numRunSchKnlTimeMsr; exeIdx++) {
  #endif
  
  CUDA_CHECK_RES(cuLaunchKernel(kernelNodeParamsDriver.func,
                                kernelNodeParamsDriver.gridDimX,
                                kernelNodeParamsDriver.gridDimY, 
                                kernelNodeParamsDriver.gridDimZ,
                                kernelNodeParamsDriver.blockDimX, 
                                kernelNodeParamsDriver.blockDimY, 
                                kernelNodeParamsDriver.blockDimZ,
                                kernelNodeParamsDriver.sharedMemBytes,
                                strm,
                                kernelNodeParamsDriver.kernelParams,
                                kernelNodeParamsDriver.extra)); 
  #ifdef SCHEDULER_KERNEL_TIME_MEASURE_
  }
  CUDA_CHECK_ERR(cudaEventRecord(stop));
  CUDA_CHECK_ERR(cudaEventSynchronize(stop));
  CUDA_CHECK_ERR(cudaEventElapsedTime(&milliseconds, start, stop));
  printf("Multi-cell scheduler ext time = %f ms\n", milliseconds/static_cast<float>(numRunSchKnlTimeMsr));
  #endif                                    
}
}
